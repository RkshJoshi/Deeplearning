{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a6454ae",
   "metadata": {},
   "source": [
    "## Introduction to Regression with neural network in Tensorflow. <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a57fc179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1bfe40e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\rakjoshi\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\rakjoshi\\anaconda3\\lib\\site-packages (from pydot) (2.4.7)\n",
      "Requirement already satisfied: graphviz in c:\\users\\rakjoshi\\anaconda3\\lib\\site-packages (0.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "!pip install graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "83d7298d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x249cd42beb0>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating data to view and fit\n",
    "X =  np.array([-7.0,-4.0,-1.0,2.0,5.0,8.0,11.0,14.0])\n",
    "y =  np.array([3.0,6.0,9.0,12.0,15.0,18.0,21.0,24.0])\n",
    "\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8eb2782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "af2f5d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'Garage', b'Bedroom', b'bathroom'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([646464])>)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a demo tensor for the house info which we were discussing earlier\n",
    "\n",
    "house_info = tf.constant([\"Garage\",\"Bedroom\", \"bathroom\"])\n",
    "house_price = tf.constant([646464])\n",
    "\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "db33c2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0, 3.0)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find the shape of the tensor we have for regression problem\n",
    "X.shape, y.shape\n",
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "607ba8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our numpy array into tensor\n",
    "\n",
    "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
    "y = tf.cast(tf.constant(y),dtype=tf.float32)\n",
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "001599c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8]), TensorShape([8]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shapes of tensors \n",
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "853cf80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x249cd391400>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a7169f",
   "metadata": {},
   "source": [
    "# Steps in modelling in tensorflow <br>\n",
    "1. Creating a model - Define the input and output layers, as well as the hidden layers of a deep learning model. <br>\n",
    "2. Compiling a model - Define the loss function (in other words, the function which tells your model to improve the <br> optimizer and evaluation metrics (What we can use to improve the performance of the model)). <br>\n",
    "3. Fitting the model - letting the model to find patterns between input and output. <br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7ef342f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.9748 - mae: 10.9748\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.8423 - mae: 10.8423\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.7098 - mae: 10.7098\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.5773 - mae: 10.5773\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.4448 - mae: 10.4448\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.3123 - mae: 10.3123\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 10.1798 - mae: 10.1798\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 10.0473 - mae: 10.0473\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.9148 - mae: 9.9148\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 9.7823 - mae: 9.7823\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.6498 - mae: 9.6498\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 9.5173 - mae: 9.5173\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.3848 - mae: 9.3848\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 9.2523 - mae: 9.2523\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 9.1198 - mae: 9.1198\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9873 - mae: 8.9873\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 8.8548 - mae: 8.8548\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 8.7223 - mae: 8.7223\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.5898 - mae: 8.5898\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 8.4573 - mae: 8.4573\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 8.3248 - mae: 8.3248\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 8.1923 - mae: 8.1923\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 8.0598 - mae: 8.0598\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.9273 - mae: 7.9273\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.7948 - mae: 7.7948\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.6623 - mae: 7.6623\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5298 - mae: 7.5298\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.3973 - mae: 7.3973\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.2648 - mae: 7.2648\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.2525 - mae: 7.2525\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.2469 - mae: 7.2469\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.2413 - mae: 7.2413\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.2356 - mae: 7.2356\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2300 - mae: 7.2300\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2188 - mae: 7.2188\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2131 - mae: 7.2131\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.2075 - mae: 7.2075\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.2019 - mae: 7.2019\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.1963 - mae: 7.1963\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.1906 - mae: 7.1906\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1850 - mae: 7.1850\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 7.1794 - mae: 7.1794\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.1738 - mae: 7.1738\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 7.1681 - mae: 7.1681\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.1625 - mae: 7.1625\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.1569 - mae: 7.1569\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1344 - mae: 7.1344\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.1287 - mae: 7.1287\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.1175 - mae: 7.1175\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1119 - mae: 7.1119\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.1063 - mae: 7.1063\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 7.1006 - mae: 7.1006\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.0894 - mae: 7.0894\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.0781 - mae: 7.0781\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0725 - mae: 7.0725\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.0669 - mae: 7.0669\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.0613 - mae: 7.0613\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 7.0556 - mae: 7.0556\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.0500 - mae: 7.0500\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0444 - mae: 7.0444\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.0388 - mae: 7.0388\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.0106 - mae: 7.0106\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.0050 - mae: 7.0050\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.9994 - mae: 6.9994\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9938 - mae: 6.9938\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9825 - mae: 6.9825\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9769 - mae: 6.9769\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9600 - mae: 6.9600\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 6.9544 - mae: 6.9544\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.9488 - mae: 6.9488\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.9431 - mae: 6.9431\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.9375 - mae: 6.9375\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9319 - mae: 6.9319\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9263 - mae: 6.9263\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.9206 - mae: 6.9206\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9094 - mae: 6.9094\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9038 - mae: 6.9038\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.8981 - mae: 6.8981\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.8869 - mae: 6.8869\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8813 - mae: 6.8813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x249ce4f24f0>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random Seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model using the sequential API\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1)])\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=\"SGD\", loss=\"mae\", metrics=[\"mae\"])\n",
    "\n",
    "# model.compile(optimizer=tf.keras.optimizers.SGD(), loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "model.fit(X,y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "da2edebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the value of X and y\n",
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "45366195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000249CE6FA280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[18.083096]], dtype=float32)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making prediction using our model\n",
    "\n",
    "model.predict([10.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fecbf54",
   "metadata": {},
   "source": [
    "### Improving the Tensorflow model <br>\n",
    "We can improve the model by altering the steps we took for creating a model. <br>\n",
    "1. Creating a model -- increase the number of layers, increase the number of hiddent layers and within each activation function can be changed.<br>\n",
    "2. Compiling the model -- Here we might change the optimization function and learning rate to better coverge the model.<br>\n",
    "3. Fitting a model - in this step we can modify the number of epochs which means training for longer so that model can better identify the pattern and adjust the weights accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e0bbd132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000249CE6FA280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[30.158512]], dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c7a94d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 11.2219 - mae: 11.2219\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 11.0894 - mae: 11.0894\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.9569 - mae: 10.9569\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 10.8244 - mae: 10.8244\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 10.6919 - mae: 10.6919\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5594 - mae: 10.5594\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.4269 - mae: 10.4269\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 10.2944 - mae: 10.2944\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.1619 - mae: 10.1619\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 10.0294 - mae: 10.0294\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 9.8969 - mae: 9.8969\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 9.7644 - mae: 9.7644\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6319 - mae: 9.6319\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 9.4994 - mae: 9.4994\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 9.3669 - mae: 9.3669\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2344 - mae: 9.2344\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1019 - mae: 9.1019\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.9694 - mae: 8.9694\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8369 - mae: 8.8369\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 8.7044 - mae: 8.7044\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 8.5719 - mae: 8.5719\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 8.4394 - mae: 8.4394\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3069 - mae: 8.3069\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.1744 - mae: 8.1744\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 8.0419 - mae: 8.0419\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.9094 - mae: 7.9094\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.7769 - mae: 7.7769\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.6444 - mae: 7.6444\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.5119 - mae: 7.5119\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.3794 - mae: 7.3794\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.2750 - mae: 7.2750\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.2694 - mae: 7.2694\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.2638 - mae: 7.2638\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2581 - mae: 7.2581\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 7.2525 - mae: 7.2525\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.2469 - mae: 7.2469\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2412 - mae: 7.2412\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2356 - mae: 7.2356\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.2300 - mae: 7.2300\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.2188 - mae: 7.2188\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2131 - mae: 7.2131\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.2075 - mae: 7.2075\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.2019 - mae: 7.2019\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.1962 - mae: 7.1962\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1906 - mae: 7.1906\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.1850 - mae: 7.1850\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.1794 - mae: 7.1794\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1737 - mae: 7.1737\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 7.1681 - mae: 7.1681\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 7.1625 - mae: 7.1625\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.1569 - mae: 7.1569\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.1344 - mae: 7.1344\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 995us/step - loss: 7.1287 - mae: 7.1287\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.1175 - mae: 7.1175\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1119 - mae: 7.1119\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1062 - mae: 7.1062\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.1006 - mae: 7.1006\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.0894 - mae: 7.0894\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.0781 - mae: 7.0781\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.0725 - mae: 7.0725\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 7.0669 - mae: 7.0669\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0613 - mae: 7.0613\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.0556 - mae: 7.0556\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0500 - mae: 7.0500\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0444 - mae: 7.0444\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.0388 - mae: 7.0388\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.0106 - mae: 7.0106\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.0050 - mae: 7.0050\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9994 - mae: 6.9994\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.9938 - mae: 6.9938\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9825 - mae: 6.9825\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.9769 - mae: 6.9769\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 6.9600 - mae: 6.9600\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9544 - mae: 6.9544\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 6.9488 - mae: 6.9488\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9431 - mae: 6.9431\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9375 - mae: 6.9375\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9319 - mae: 6.9319\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9263 - mae: 6.9263\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 6.9206 - mae: 6.9206\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9094 - mae: 6.9094\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.9038 - mae: 6.9038\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 6.8981 - mae: 6.8981\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.8869 - mae: 6.8869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x249ce738670>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1)])\n",
    "\n",
    "#2. Compile the mode\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.losses.mae, metrics=[\"mae\"] )\n",
    "\n",
    "# fitting the model(We will train the model for longer)\n",
    "\n",
    "model.fit(X,y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "17e855b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000249CE739AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29.739855]], dtype=float32)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "23f048b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.7682 - mae: 11.7682\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 11.0963 - mae: 11.0963\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.4150 - mae: 10.4150\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 9.7212 - mae: 9.7212\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 9.0104 - mae: 9.0104\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.2778 - mae: 8.2778\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.5198 - mae: 7.5198\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.9648 - mae: 6.9648\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0672 - mae: 7.0672\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.3315 - mae: 7.3315\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.4673 - mae: 7.4673\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.5285 - mae: 7.5285\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 7.4011 - mae: 7.4011\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 7.1923 - mae: 7.1923\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.9575 - mae: 6.9575\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6953 - mae: 6.6953\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.4127 - mae: 6.4127\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3048 - mae: 6.3048\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2575 - mae: 6.2575\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.3982 - mae: 6.3982\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.4551 - mae: 6.4551\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 6.4000 - mae: 6.4000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2482 - mae: 6.2482\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 6.0105 - mae: 6.0105\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.7876 - mae: 5.7876\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 5.6809 - mae: 5.6809\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.5715 - mae: 5.5715\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.6122 - mae: 5.6122\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 5.6074 - mae: 5.6074\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.5541 - mae: 5.5541\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.4568 - mae: 5.4568\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 5.3199 - mae: 5.3199\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1477 - mae: 5.1477\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 4.9442 - mae: 4.9442\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 4.8239 - mae: 4.8239\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7389 - mae: 4.7389\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 4.6657 - mae: 4.6657\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 4.5846 - mae: 4.5846\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 4.4027 - mae: 4.4027\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.2653 - mae: 4.2653\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 4.1212 - mae: 4.1212\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9702 - mae: 3.9702\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.8272 - mae: 3.8272\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7041 - mae: 3.7041\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5320 - mae: 3.5320\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 3.3664 - mae: 3.3664\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 3.2116 - mae: 3.2116\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0463 - mae: 3.0463\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 2.8705 - mae: 2.8705\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.6840 - mae: 2.6840\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 994us/step - loss: 2.4868 - mae: 2.4868\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2787 - mae: 2.2787\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0596 - mae: 2.0596\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 1.8293 - mae: 1.8293\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.5876 - mae: 1.5876\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3530 - mae: 1.3530\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 1.0849 - mae: 1.0849\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8224 - mae: 0.8224\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5467 - mae: 0.5467\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.2758 - mae: 0.2758\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1354 - mae: 0.1354\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4494 - mae: 0.4494\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6498 - mae: 0.6498\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6216 - mae: 0.6216\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8036 - mae: 0.8036\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.7995 - mae: 0.7995\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7409 - mae: 0.7409\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7806 - mae: 0.7806\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.6305 - mae: 0.6305\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.5556 - mae: 0.5556\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4306 - mae: 0.4306\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2786 - mae: 0.2786\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1378 - mae: 0.1378\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1193 - mae: 0.1193\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.2777 - mae: 0.2777\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3245 - mae: 0.3245\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4157 - mae: 0.4157\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4319 - mae: 0.4319\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.3391 - mae: 0.3391\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2968 - mae: 0.2968\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2355 - mae: 0.2355\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1633 - mae: 0.1633\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.1339 - mae: 0.1339\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1262 - mae: 0.1262\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1702 - mae: 0.1702\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.2124 - mae: 0.2124\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 0.2288 - mae: 0.2288\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1901 - mae: 0.1901\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.1354 - mae: 0.1354\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1218 - mae: 0.1218\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0382 - mae: 0.0382\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2197 - mae: 0.2197\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2189 - mae: 0.2189\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.1427 - mae: 0.1427\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1168 - mae: 0.1168\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2069 - mae: 0.2069\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1524 - mae: 0.1524\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.2133 - mae: 0.2133\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2329 - mae: 0.2329\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0780 - mae: 0.0780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x249ce9bc5e0>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Testing with additional dense layer in the model\n",
    "\n",
    "# 1. Creating a model\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(50, activation=None),\n",
    "                            tf.keras.layers.Dense(1)\n",
    "                            ])\n",
    "\n",
    "#2. Compiling the mode\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss=\"mae\", metrics=[\"mae\"])\n",
    "\n",
    "# fit the model\n",
    "\n",
    "model.fit(X,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "414d8d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000249CEB0D8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[26.583529]], dtype=float32)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "eb74bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### When it comes to evaluation of model, visualize your model, data and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b6a1b60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.range(-100,100,4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e2abd8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make labels for the dataset\n",
    "y = X+10\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d0d451ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x249ce6f3d30>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVLUlEQVR4nO3df4xlZ33f8fen5oecBGoTD8567c2uqe3GKOoaj6xULkhgEwNKsA0KNZWoW1A2SFgNTWuxxlWEGqEYXINUUUEXxYpTAYbWP7ASEmNjmrRRCOyyi73G3tpr7LI/ul5wXZCwNnj59o85Y+4u987uzD3317nvlzSac59z7zmPnzvz3TOf+/g8qSokSd309ybdAUnS6FjkJanDLPKS1GEWeUnqMIu8JHXYiybdgV5nnHFGbdy4cdLdkKSZsmPHju9V1UK/fVNV5Ddu3Mj27dsn3Q1JmilJnhq0z7hGkjrMIi9JHWaRl6QOs8hLUodZ5CWpw6Zqdo0kzZu7d+7n5nv3cODZ5zjrtFO5/ooLuOqi9a0d3yIvSRNy98793HDnQzz346MA7H/2OW648yGA1gq9cY0kTcjN9+55ocAve+7HR7n53j2tncMiL0kTcuDZ51bVvhbGNZI0Bv2y97NOO5X9fQr6Waed2tp5vZKXpBFbzt73P/scxU+z99f/wwVOffEpxzz31BefwvVXXNDauU+6yCe5NcnTSXb3tL0iyX1JHmu+n96z74YkjyfZk+SK1nosSTNmUPb+1UcP84dv+1XWn3YqAdafdip/+LZfndjsmj8GPgH8SU/bVuArVXVTkq3N4w8kuRC4Bng1cBZwf5Lzq+ookjRnVsrer7pofatF/XgnfSVfVX8FPHNc85XAbc32bcBVPe23V9WRqvoO8DhwyXBdlaTpdvfO/Vx60wNs2vpnXHrTA9y9cz8wOGNvM3sfZNhM/syqOgjQfH9l074e+G7P8/Y1bT8jyZYk25NsP3z48JDdkaTJGJS7371zP9dfccHIs/dBRvXBa/q0Vb8nVtW2qlqsqsWFhb73vJekqbfSnPerLlo/8ux9kGGnUB5Ksq6qDiZZBzzdtO8Dzul53tnAgSHPJUlT60Rz3kedvQ8ybJG/B7gWuKn5/sWe9s8m+RhLH7yeB3x9yHNJ0lSY1Jz3tVjNFMrPAX8DXJBkX5L3sFTc35jkMeCNzWOq6mHgC8C3gb8A3ufMGkldMMk572uRqr5R+UQsLi6Wa7xKmmaX3vRA3yv29c0V/SjvKDlIkh1Vtdhvn7c1kKRVmOSc97WwyEvSALOUvQ/ivWskqY9Zy94HschLUh+TvN9Mm4xrJKmPWcveB7HIS5p7XcjeBzGukTTXupK9D2KRlzTXupK9D2JcI2mudSV7H8QiL2ludDl7H8S4RtJc6Hr2PohFXtJc6Hr2PohxjaS50PXsfRCLvKRO6Ze7X3XR+s5n74MY10jqjGldZ3WSLPKSOmNa11mdpKHjmiQXAJ/vaToX+H3gNOC3gcNN+wer6kvDnk+SBpnWdVYnaegr+araU1Wbq2ozcDHwI+CuZvfHl/dZ4CWN2qB8veu5+0ra/uD1MmBvVT2VpOVDS9JP9fuA9forLuCGOx86JrKZh9x9JW1n8tcAn+t5fF2SB5PcmuT0ls8laU4N+oAVmMvcfSWtLeSd5CXAAeDVVXUoyZnA94AC/gBYV1Xv7vO6LcAWgA0bNlz81FNPtdIfSd210mLaf731DRPo0WSttJB3m1fybwa+WVWHAKrqUFUdraqfAJ8GLun3oqraVlWLVbW4sLDQYnckddWJPmDVT7WZyb+TnqgmybqqOtg8vBrY3eK5JM2JebypWJtauZJP8nPAG4E7e5o/muShJA8Crwf+dRvnkjQ/5vWmYm1q5Uq+qn4E/OJxbe9q49iS5teJbirW7/YFOpb3rpE0teb1pmJtsshLmgpm76PhvWskTZzZ++hY5CVN3Lwu6DEOxjWSJs7sfXQs8pLGyux9vIxrJI2N2fv4WeQljY3Z+/gZ10gaG7P38bPIS2qdi2lPD+MaSa1yMe3pYpGX1CoX054uxjWSWuVi2tPFIi9pzZzzPv2MayStiXPeZ4NFXtKaOOd9NhjXSFoT57zPhlaKfJIngR8CR4Hnq2oxySuAzwMbgSeBd1TV/23jfJLGy+x9drUZ17y+qjZX1WLzeCvwlao6D/hK81jSjDF7n22jzOSvBG5rtm8DrhrhuSSNiNn7bGsrky/gy0kK+M9VtQ04s6oOAlTVwSSv7PfCJFuALQAbNmxoqTuS2mL2PtvaKvKXVtWBppDfl+TRk31h8w/CNoDFxcVqqT+S1sDsvXtaiWuq6kDz/WngLuAS4FCSdQDN96fbOJek0TB776ahi3ySn0/ysuVt4NeB3cA9wLXN064FvjjsuSSNjtl7N7UR15wJ3JVk+Xifraq/SPIN4AtJ3gP8b+C3WjiXpBExe++moYt8VT0B/KM+7d8HLhv2+JLaZ/Y+P7ytgTRnzN7ni0VemjNm7/PFe9dIc8bsfb5Y5KWOcp1VgXGN1Emus6plFnmpg1xnVcuMa6QOcp1VLbPISzPOOe9aiXGNNMOc864TschLM8w57zoR4xpphjnnXSdikZdmhNm71sK4RpoBZu9aK4u8NAPM3rVWxjXSDDB711pZ5KUpY/auNrWx/N85Sb6a5JEkDyf53ab9Q0n2J9nVfL1l+O5K3Wb2rra1kck/D/ybqvoV4NeA9yW5sNn38ara3Hx9qYVzSZ1m9q62tbH830HgYLP9wySPAP7kSWtg9q62tTq7JslG4CLgb5um65I8mOTWJKcPeM2WJNuTbD98+HCb3ZGm1t0793PpTQ+waeufcelND3D3zv3A4Izd7F1r1VqRT/ILwB3A+6vqB8AngVcBm1m60r+l3+uqaltVLVbV4sLCQlvdkaaW93rXOLVS5JO8mKUC/5mquhOgqg5V1dGq+gnwaeCSNs4lzTrv9a5xGjqTTxLgj4BHqupjPe3rmrwe4Gpg97DnkrrAe71rnNqYJ38p8C7goSS7mrYPAu9Mshko4Engd1o4lzRTnPOuSWtjds3/BNJnl1MmNdeWs/flaGY5e3/7xeu5Y8f+YyIbc3eNiveukUbEOe+aBt7WQBoR57xrGljkpRaYvWtaGddIQ/J+M5pmFnlpSGbvmmbGNdKQzN41zSzy0iqYvWvWGNdIJ8nsXbPIIi+dJLN3zSLjGukkmb1rFlnkpT7M3tUVxjXSccze1SUWeek4Zu/qEuMa6Thm7+oSi7zmVr/c/aqL1pu9q1OMazSXXGdV82LkRT7Jm5LsSfJ4kq2jPp90MlxnVfNipHFNklOA/wS8EdgHfCPJPVX17VGeVzoR11nVvBh1Jn8J8HhVPQGQ5HbgSsAir7Fxzrvm2ajjmvXAd3se72vaXpBkS5LtSbYfPnx4xN3RvHHOu+bdqIt8vwW+65gHVduqarGqFhcWFkbcHc0b57xr3o06rtkHnNPz+GzgwIjPKb3AOe+ad6Mu8t8AzkuyCdgPXAP8sxGfU3PK7F36WSONa6rqeeA64F7gEeALVfXwKM+p+WT2LvU38nnyVfWlqjq/ql5VVR8e9fk0n8zepf68rYE6wexd6s8ir5lj9i6dPO9do5li9i6tjkVeM8XsXVod4xrNFLN3aXUs8ppaZu/S8IxrNJXM3qV2WOQ1lczepXYY12gqmb1L7bDIa6JcZ1UaLeMaTYzrrEqjZ5HXxLjOqjR6xjWaGNdZlUbPIq+xcM67NBnGNRo557xLk2OR18g5512anKHimiQ3A78J/B2wF/iXVfVsko0srQS1p3nq16rqvcOcS7PLOe/S5Aybyd8H3FBVzyf5CHAD8IFm396q2jzk8TVjzN6l6TJUXFNVX27WcQX4GnD28F3SrDJ7l6ZPm5n8u4E/73m8KcnOJH+Z5LWDXpRkS5LtSbYfPny4xe5o3Mzepelzwrgmyf3AL/XZdWNVfbF5zo3A88Bnmn0HgQ1V9f0kFwN3J3l1Vf3g+INU1TZgG8Di4mKt7T9D08DsXZo+JyzyVXX5SvuTXAv8BnBZVVXzmiPAkWZ7R5K9wPnA9qF7rKlg9i7NhqHimiRvYumD1rdW1Y962heSnNJsnwucBzwxzLk0PczepdkxbCb/CeBlwH1JdiX5VNP+OuDBJN8C/hvw3qp6ZshzaUqYvUuzY6gplFX1Dwa03wHcMcyxNb3M3qXZ4b1rtCKzd2m2eVsDDWT2Ls0+i7wGMnuXZp9xjQYye5dmn0VerrMqdZhxzZxznVWp2yzyc851VqVuM66Zc66zKnWbV/JzblC+bu4udYNX8nOk3wes119xATfc+dAxkY25u9QdXsnPiUEfsALm7lKHeSU/J1b6gPWvt77Boi51lFfyc+JEH7BK6iav5DvIm4pJWuaVfMd4UzFJvSzyHeNNxST1GiquSfIh4LeBw03TB6vqS82+G4D3AEeBf1VV9w5zLp0cbyomqVcbmfzHq+o/9DYkuRC4Bng1cBZwf5Lzq+povwNobczeJZ3IqOKaK4Hbq+pIVX0HeBy4ZETnmktm75JORhtF/rokDya5NcnpTdt64Ls9z9nXtKklZu+STsYJ45ok9wO/1GfXjcAngT8Aqvl+C/BuIH2eXwOOvwXYArBhw4aT6rTM3iWdnBMW+aq6/GQOlOTTwJ82D/cB5/TsPhs4MOD424BtAIuLi33/IZhnLughaRhDxTVJ1vU8vBrY3WzfA1yT5KVJNgHnAV8f5lzzyAU9JA1r2Nk1H02ymaUo5kngdwCq6uEkXwC+DTwPvM+ZNat3ovvNLD/n+Kt8SVo2VJGvqnetsO/DwIeHOf68c0EPScPy3jVTwjnvkkbB2xpMAee8SxoVi/wUcM67pFExrpkCznmXNCoW+TEze5c0TsY1Y2T2LmncLPJjZPYuadyMa8bI7F3SuFnkR8TsXdI0MK4ZAbN3SdPCIj8CZu+SpoVxzQiYvUuaFhb5IZm9S5pmxjVDMHuXNO0s8kMwe5c07YxrhmD2LmnaWeRPguusSppVw67x+vkku5qvJ5Psato3JnmuZ9+nWuntBLjOqqRZNuzyf/90eTvJLcD/69m9t6o2D3P8aeA6q5JmWStxTZIA7wDe0MbxponrrEqaZW1l8q8FDlXVYz1tm5LsBH4A/Luq+h/9XphkC7AFYMOGDS11Z22c8y6pa06YySe5P8nuPl9X9jztncDneh4fBDZU1UXA7wGfTfLyfsevqm1VtVhViwsLC8P8twzFOe+SuuiEV/JVdflK+5O8CHgbcHHPa44AR5rtHUn2AucD24fq7QidaM67ubukWdRGXHM58GhV7VtuSLIAPFNVR5OcC5wHPNHCuUbGOe+SuqiNIn8Nx0Y1AK8D/n2S54GjwHur6pkWztUKs3dJ82LoIl9V/6JP2x3AHcMeexSWs/flaGY5e3/7xeu5Y8f+YyIbs3dJs27u7l3j/WYkzZO5u62B2bukedLpIm/2LmnedTaucd67JHW4yJu9S1KH4xqzd0nqSJE3e5ek/mY+rjF7l6TBZr7Im71L0mAzH9eYvUvSYDN/JT8oYzd7l6QOFHnXWZWkwWY+rlmOY7zfuyT9rJkv8uA6q5I0yMzHNZKkwSzyktRhFnlJ6jCLvCR1mEVekjosVTXpPrwgyWHgqSEOcQbwvZa606Zp7RfYt7Wyb6s3rf2C2e/bL1fVQr8dU1Xkh5Vke1UtTrofx5vWfoF9Wyv7tnrT2i/odt+MaySpwyzyktRhXSvy2ybdgQGmtV9g39bKvq3etPYLOty3TmXykqRjde1KXpLUwyIvSR02k0U+yW8leTjJT5IsHrfvhiSPJ9mT5Iqe9ouTPNTs+49JMoZ+fj7JrubrySS7mvaNSZ7r2fepUfelT98+lGR/Tx/e0rOv7xiOsW83J3k0yYNJ7kpyWtM+DeP2pmZcHk+yddznP64v5yT5apJHmt+H323aB763Y+7fk83v3K4k25u2VyS5L8ljzffTJ9CvC3rGZleSHyR5/6TGLcmtSZ5OsrunbeA4rfr3s6pm7gv4FeAC4L8Diz3tFwLfAl4KbAL2Aqc0+74O/GMgwJ8Dbx5zn28Bfr/Z3gjsnvAYfgj4t33aB47hGPv268CLmu2PAB+ZhnEDTmnG41zgJc04XTjB/qwDXtNsvwz4X8371/e9nUD/ngTOOK7to8DWZnvr8ns74ff0/wC/PKlxA14HvKb3Z3vQOK3l93Mmr+Sr6pGq2tNn15XA7VV1pKq+AzwOXJJkHfDyqvqbWhqpPwGuGld/m78a3gF8blznHELfMRxnB6rqy1X1fPPwa8DZ4zz/Ci4BHq+qJ6rq74DbWRqviaiqg1X1zWb7h8AjwLQvrHAlcFuzfRtj/D0c4DJgb1UN83/aD6Wq/gp45rjmQeO06t/PmSzyK1gPfLfn8b6mbX2zfXz7uLwWOFRVj/W0bUqyM8lfJnntGPvS67omErm158/BQWM4Ke9m6S+vZZMct2kbmxck2QhcBPxt09TvvR23Ar6cZEeSLU3bmVV1EJb+kQJeOaG+LbuGYy++pmHcYPA4rfpncGqLfJL7k+zu87XSlVO/nL1WaB9XP9/JsT9IB4ENVXUR8HvAZ5O8vI3+rKJvnwReBWxu+nPL8sv6HKr1ebYnM25JbgSeBz7TNI1l3Fbqdp+2ic9BTvILwB3A+6vqBwx+b8ft0qp6DfBm4H1JXjehfvSV5CXAW4H/2jRNy7itZNU/g1O7/F9VXb6Gl+0Dzul5fDZwoGk/u0/70E7UzyQvAt4GXNzzmiPAkWZ7R5K9wPnA9jb6dLJ96+njp4E/bR4OGsNWncS4XQv8BnBZE7GNbdxWMJaxWY0kL2apwH+mqu4EqKpDPft739uxqqoDzfenk9zFUqxwKMm6qjrYxKhPT6JvjTcD31wer2kZt8agcVr1z+DUXsmv0T3ANUlemmQTcB7w9ebPnR8m+bUmH//nwBfH1KfLgUer6oW4KMlCklOa7XObfj4xpv4s92Fdz8OrgeVP9vuO4Zj79ibgA8Bbq+pHPe2THrdvAOcl2dRcBV7D0nhNRPOz/EfAI1X1sZ72Qe/tOPv280letrzN0ofpu1kar2ubp13L+H4P+znmL+xpGLceg8Zp9b+fk/xke4hPo69m6V+0I8Ah4N6efTey9InzHnpm0ACLLL1pe4FP0PzfvmPo6x8D7z2u7e3Awyx9Sv5N4DcnMIb/BXgIeLD5wVl3ojEcY98eZyl33NV8fWqKxu0tLM1i2QvcOO7zH9eXf8LSn+oP9ozVW1Z6b8fYt3Ob9+lbzXt2Y9P+i8BXgMea76+Y0Nj9HPB94O/3tE1k3Fj6h+Yg8OOmrr1npXFa7e+ntzWQpA7rWlwjSephkZekDrPIS1KHWeQlqcMs8pLUYRZ5Seowi7wkddj/B2s8RJZVq1b+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea2d198",
   "metadata": {},
   "source": [
    "### Three dataset are  - <br>\n",
    "1. Training set  - this will be used for training of model (70-80%).<br>\n",
    "2. Validation set -- This dataset will be used for the hyperparameter tuning(10-15%).<br>\n",
    "3. test set -- This dataset is used for the evaluation of model(10-15%). <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5f9be2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "          32,   36,   40,   44,   48,   52,   56])>,\n",
       " <tf.Tensor: shape=(10,), dtype=int32, numpy=array([60, 64, 68, 72, 76, 80, 84, 88, 92, 96])>,\n",
       " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "         66])>,\n",
       " <tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concept of three sets\n",
    "split = int(len(X) * .8)\n",
    "X_train,X_test, y_train, y_test = X[:split],X[split:], y[:split],y[split:]\n",
    "X_train, X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "26c04b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
    "\n",
    "plt.scatter(X_test,y_test, c=\"g\", label=\"Test data\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "46bbfde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's have a look at how to build neural network for the training data\n",
    "\n",
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=[1])])\n",
    "\n",
    "#2. compiler your model\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.losses.mae, metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "#model.fit(X_train,X_test, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "25afade0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Visualizing your model by runninf model.summary\n",
    "model.summary() # the model should be build in advance to view the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "74150050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000249CE97B9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 63.00979 ],\n",
       "       [ 67.21044 ],\n",
       "       [ 71.411095],\n",
       "       [ 75.61175 ],\n",
       "       [ 79.8124  ],\n",
       "       [ 84.013054],\n",
       "       [ 88.21371 ],\n",
       "       [ 92.41436 ],\n",
       "       [ 96.61501 ],\n",
       "       [100.81566 ]], dtype=float32)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bb9c6bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model which builds automatically\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(20, input_shape=[1], name = \"Input_layer\"),\n",
    "                            tf.keras.layers.Dense(1, name=\"output_layer\")], name= \"Model_1\")\n",
    "\n",
    "#2. compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01), loss= tf.keras.losses.mae, metrics=[\"mae\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bb12e4",
   "metadata": {},
   "source": [
    "** total parameters -- total numbers of parameters in the model that your model will train.<br>\n",
    "** trainable parameters -- There are the parameters (patters) the model can update as it trains.<br>\n",
    "** Non-trainable params -- these parameters are not updated during training, this will happens when you have already trained <br>\n",
    "models or parameters from transfer learnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "38f76b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (Dense)          (None, 20)                40        \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#3. view the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "97cb290d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x249cd11a3a0>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=100,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b5500e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (Dense)          (None, 20)                40        \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 61\n",
      "Trainable params: 61\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4a9914bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fb9598",
   "metadata": {},
   "source": [
    "## Visulalizing our model's prediction\n",
    "To visualize predictions, it's a good idea to plot them against the ground truth labels.\n",
    "Often you'll see this in the form of y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3bc66c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000249CBE590D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 70.353   ],\n",
       "       [ 74.92796 ],\n",
       "       [ 79.502945],\n",
       "       [ 84.07792 ],\n",
       "       [ 88.65289 ],\n",
       "       [ 93.227875],\n",
       "       [ 97.80285 ],\n",
       "       [102.37783 ],\n",
       "       [106.952805],\n",
       "       [111.52779 ]], dtype=float32)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7902d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model prediction function\n",
    "def plot_predictions(train_data = X_train, train_labels = y_train,\n",
    "                    test_data = X_test, test_labels = y_test,\n",
    "                    predictions = y_pred):\n",
    "    plt.figure(figsize=(13,7))\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", label=\"Test Data\")\n",
    "    plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ee32561c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(X_train,y_train,X_test,y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c0e2a0",
   "metadata": {},
   "source": [
    "## Evaluating our model's predictions with regression evaluation metrics\n",
    "\n",
    "Depeding on the problem you're working on we can use different metrics for the evaluation of the model. MAE or MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "214be4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9404 - mae: 2.9404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.9403862953186035, 2.9403862953186035]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d9763c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The issue here with y_pred is not in same shape as y_test due to which losses.mae is not giving right answer. TO resolve this issue\n",
    "# change the y_pred to tensor and then reshape it to make sure that they are in right format and shape\n",
    "y_pred = tf.constant(y_pred)\n",
    "y_pred = tf.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "04780c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([ 70.353   ,  74.92796 ,  79.502945,  84.07792 ,  88.65289 ,\n",
       "         93.227875,  97.80285 , 102.37783 , 106.952805, 111.52779 ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "dafa5686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.9403863>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the Mean absolute error\n",
    "model_mae = tf.keras.losses.MAE(y_test, y_pred)\n",
    "model_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "257b8047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=11.373308>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the mean square error of the model to evaluate the model.\n",
    "model_mse = tf.keras.losses.MSE(y_test,y_pred)\n",
    "model_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "20e83636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metrics(y_true, y_pred):\n",
    "    y_pred = tf.squeeze(tf.constant(y_pred))\n",
    "    model_mae = tf.keras.losses.mae(y_true, y_pred)\n",
    "    model_mse = tf.keras.losses.mse(y_true,y_pred)\n",
    "    print(\"Model MAE is {}, Model MSE is {}\".format(model_mae, model_mse))\n",
    "    return model_mae, model_mse\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f696ab6",
   "metadata": {},
   "source": [
    "### Running experiments to improve our model\n",
    "1. Get more data to train your data, allow model to better understand the patterns.\n",
    "2. Make your model larger (Using a more complex model, adding more hidden units in each layer)\n",
    "3. Train for longer- give your model a change to find pattern by giving more time\n",
    "\n",
    "Let's perform three experiments -\n",
    "1. Model1 - Same as the original, 1 layer, trained for 100 epochs.\n",
    "2. Model2 - 2 layers, trained for 100 epochs.\n",
    "3. Model3 - 2 layers, trained for 500 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b10eac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 17.4325 - mae: 17.4325WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.9024 - mae: 15.9024\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.2837 - mae: 11.2837\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 11.1075 - mae: 11.1075\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.2990 - mae: 9.2990\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.1677 - mae: 10.1677\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.4303 - mae: 9.4303\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.5704 - mae: 8.5704\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 9.0442 - mae: 9.0442\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 18.7517 - mae: 18.7517\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.1142 - mae: 10.1142\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 8.3980 - mae: 8.3980\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.6639 - mae: 10.6639\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.7977 - mae: 9.7977\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 16.0103 - mae: 16.0103\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.4068 - mae: 11.4068\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.5393 - mae: 8.5393\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.6348 - mae: 13.6348\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.4629 - mae: 11.4629\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 17.9148 - mae: 17.9148\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.0494 - mae: 15.0494\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 995us/step - loss: 11.0216 - mae: 11.0216\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 8.1558 - mae: 8.1558\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.5138 - mae: 9.5138\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.6617 - mae: 7.6617\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.1859 - mae: 13.1859\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 16.4211 - mae: 16.4211\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.1660 - mae: 13.1660\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 14.2559 - mae: 14.2559\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.0670 - mae: 10.0670\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.3409 - mae: 16.3409\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.6444 - mae: 23.6444\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 7.6215 - mae: 7.6215\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.3221 - mae: 9.3221\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.7313 - mae: 13.7313\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.1276 - mae: 11.1276\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.3222 - mae: 13.3222\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.4763 - mae: 9.4763\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 10.1381 - mae: 10.1381\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 10.1793 - mae: 10.1793\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.9137 - mae: 10.9137\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9063 - mae: 7.9063\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 10.0914 - mae: 10.0914\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 8.7006 - mae: 8.7006\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.2046 - mae: 12.2046\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.7970 - mae: 13.7970\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.4687 - mae: 8.4687\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.1330 - mae: 9.1330\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.6190 - mae: 10.6190\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 7.7503 - mae: 7.7503\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.5407 - mae: 9.5407\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 9.1584 - mae: 9.1584\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 16.3630 - mae: 16.3630\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.1299 - mae: 14.1299\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.1247 - mae: 21.1247\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 16.3961 - mae: 16.3961\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.9806 - mae: 9.9806\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.9606 - mae: 9.9606\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.2209 - mae: 9.2209\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 8.4239 - mae: 8.4239\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.4869 - mae: 9.4869\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.4354 - mae: 11.4354\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.6887 - mae: 11.6887\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 16.9675 - mae: 16.9675\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 12.4599 - mae: 12.4599\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.0184 - mae: 13.0184\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.0600 - mae: 8.0600\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.1888 - mae: 10.1888\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.3633 - mae: 12.3633\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.0516 - mae: 9.0516\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.0378 - mae: 10.0378\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.0516 - mae: 10.0516\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.6151 - mae: 12.6151\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.3819 - mae: 10.3819\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.7229 - mae: 9.7229\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.2252 - mae: 11.2252\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.3642 - mae: 8.3642\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 9.1274 - mae: 9.1274\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 19.5039 - mae: 19.5039\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.8945 - mae: 14.8945\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.0034 - mae: 9.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.0206 - mae: 13.0206\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.9299 - mae: 7.9299\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.6872 - mae: 7.6872\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0328 - mae: 10.0328\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.2433 - mae: 9.2433\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.0209 - mae: 12.0209\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.6389 - mae: 10.6389\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 7.2667 - mae: 7.2667\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 12.7786 - mae: 12.7786\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 7.3481 - mae: 7.3481\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.7175 - mae: 7.7175\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.1263 - mae: 7.1263\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.6190 - mae: 12.6190\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.0912 - mae: 10.0912\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.3558 - mae: 9.3558\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.6834 - mae: 12.6834\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.6762 - mae: 8.6762\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 9.4693 - mae: 9.4693\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 8.7067 - mae: 8.7067\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 73.0019 - mae: 73.0019\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.5325 - mae: 17.5325\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 20.4862 - mae: 20.4862\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 13.1871 - mae: 13.1871\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 14.5492 - mae: 14.5492\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 11.6087 - mae: 11.6087\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.6668 - mae: 12.6668\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 11.0468 - mae: 11.0468\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 39.7317 - mae: 39.7317\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 497us/step - loss: 27.2189 - mae: 27.2189\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 11.0353 - mae: 11.0353\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 24.4166 - mae: 24.4166\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 19.3019 - mae: 19.3019\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 23.5364 - mae: 23.5364\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.3061 - mae: 15.3061\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.3811 - mae: 11.3811\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 23.2584 - mae: 23.2584\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.8111 - mae: 11.8111\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 16.5386 - mae: 16.5386\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.2427 - mae: 8.2427\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 14.4055 - mae: 14.4055\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.8167 - mae: 12.8167\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 15.4582 - mae: 15.4582\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.2467 - mae: 15.2467\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 14.3296 - mae: 14.3296\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 19.3209 - mae: 19.3209\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.4720 - mae: 11.4720\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 29.1772 - mae: 29.1772\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 999us/step - loss: 9.2578 - mae: 9.2578\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 29.8922 - mae: 29.8922\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 54.2504 - mae: 54.2504\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 9.5899 - mae: 9.5899\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 12.1833 - mae: 12.1833\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 23.9573 - mae: 23.9573\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.6202 - mae: 12.6202\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 21.5189 - mae: 21.5189\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 995us/step - loss: 11.3948 - mae: 11.3948\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.4825 - mae: 13.4825\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.8031 - mae: 10.8031\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 16.6186 - mae: 16.6186\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 753us/step - loss: 10.9878 - mae: 10.9878\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.3120 - mae: 9.3120\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.6002 - mae: 9.6002\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 28.0120 - mae: 28.0120\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.2956 - mae: 11.2956\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 14.0830 - mae: 14.0830\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.5011 - mae: 13.5011\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 17.3373 - mae: 17.3373\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5238 - mae: 9.5238\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.7154 - mae: 13.7154\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.5670 - mae: 11.5670\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 502us/step - loss: 30.2257 - mae: 30.2257\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.7352 - mae: 13.7352\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 26.4457 - mae: 26.4457\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 26.0367 - mae: 26.0367\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.2460 - mae: 11.2460\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.2249 - mae: 13.2249\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.8754 - mae: 9.8754\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 995us/step - loss: 13.4150 - mae: 13.4150\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 10.9405 - mae: 10.9405\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.5630 - mae: 13.5630\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 17.8775 - mae: 17.8775\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.7416 - mae: 8.7416\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 16.1381 - mae: 16.1381\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.7498 - mae: 10.7498\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 22.1831 - mae: 22.1831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.2709 - mae: 10.2709\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.4682 - mae: 13.4682\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.4343 - mae: 11.4343\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 13.6187 - mae: 13.6187\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.6233 - mae: 15.6233\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.8532 - mae: 11.8532\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 16.6254 - mae: 16.6254\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 24.1342 - mae: 24.1342\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 9.6315 - mae: 9.6315\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.4825 - mae: 12.4825\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 16.7086 - mae: 16.7086\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 999us/step - loss: 9.0873 - mae: 9.0873\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 24.0255 - mae: 24.0255\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 26.8174 - mae: 26.8174\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 11.7213 - mae: 11.7213\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 12.0124 - mae: 12.0124\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.4085 - mae: 17.4085\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 7.2769 - mae: 7.2769\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 14.9605 - mae: 14.9605\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 15.2848 - mae: 15.2848\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 19.0979 - mae: 19.0979\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 29.8574 - mae: 29.8574\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.1967 - mae: 10.1967\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 21.5458 - mae: 21.5458\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 10.5927 - mae: 10.5927\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.4135 - mae: 18.4135\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.4299 - mae: 7.4299\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.7470 - mae: 17.7470\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.1306 - mae: 11.1306\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 499us/step - loss: 19.4420 - mae: 19.4420\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.1735 - mae: 12.1735\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 497us/step - loss: 11.5784 - mae: 11.5784\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 498us/step - loss: 13.8853 - mae: 13.8853\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 996us/step - loss: 20.2151 - mae: 20.2151\n",
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 21.9353 - mae: 21.9353\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 22.0862 - mae: 22.0862\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 28.3525 - mae: 28.3525\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 23.1307 - mae: 23.1307\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.8184 - mae: 13.8184\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.0722 - mae: 11.0722\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 12.0519 - mae: 12.0519\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 10.8345 - mae: 10.8345\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 37.3929 - mae: 37.3929\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 506us/step - loss: 25.0762 - mae: 25.0762\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.2397 - mae: 10.2397\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 25.4130 - mae: 25.4130\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.7518 - mae: 16.7518\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 25.4925 - mae: 25.4925\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 17.4063 - mae: 17.4063\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 9.9920 - mae: 9.9920\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 18.4421 - mae: 18.4421\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.3144 - mae: 11.3144\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.8716 - mae: 13.8716\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 11.1646 - mae: 11.1646\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 17.1884 - mae: 17.1884\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 15.4261 - mae: 15.4261\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 9.2387 - mae: 9.2387\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.2938 - mae: 17.2938\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 15.9566 - mae: 15.9566\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 20.9786 - mae: 20.9786\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 25.8546 - mae: 25.8546\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.3662 - mae: 18.3662\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.2329 - mae: 9.2329\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 28.9805 - mae: 28.9805\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 52.4765 - mae: 52.4765\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.8777 - mae: 11.8777\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.4465 - mae: 15.4465\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.5576 - mae: 12.5576\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.1757 - mae: 9.1757\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 16.4221 - mae: 16.4221\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 11.0940 - mae: 11.0940\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 18.2250 - mae: 18.2250\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 19.1549 - mae: 19.1549\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 20.5317 - mae: 20.5317\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 14.7742 - mae: 14.7742\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 12.1779 - mae: 12.1779\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.6799 - mae: 10.6799\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 32.2250 - mae: 32.2250\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.4480 - mae: 12.4480\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 17.4835 - mae: 17.4835\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 15.7628 - mae: 15.7628\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.3758 - mae: 8.3758\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.9879 - mae: 13.9879\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.8303 - mae: 12.8303\n",
      "Epoch 51/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 499us/step - loss: 14.8378 - mae: 14.8378\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.7219 - mae: 18.7219\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 24.1752 - mae: 24.1752\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 23.1613 - mae: 23.1613\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 24.0097 - mae: 24.0097\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.1460 - mae: 11.1460\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.0999 - mae: 13.0999\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.7993 - mae: 9.7993\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.2909 - mae: 13.2909\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.8583 - mae: 10.8583\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.4608 - mae: 13.4608\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.4913 - mae: 17.4913\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.1507 - mae: 9.1507\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.3653 - mae: 18.3653\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.1067 - mae: 10.1067\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 24.2312 - mae: 24.2312\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.8745 - mae: 10.8745\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.7588 - mae: 10.7588\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 23.2247 - mae: 23.2247\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 8.8148 - mae: 8.8148\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 15.9842 - mae: 15.9842\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 8.1389 - mae: 8.1389\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.4628 - mae: 9.4628\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 28.1605 - mae: 28.1605\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 10.1856 - mae: 10.1856\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 13.1352 - mae: 13.1352\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.3781 - mae: 18.3781\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.0070 - mae: 9.0070\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 23.4318 - mae: 23.4318\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 26.1007 - mae: 26.1007\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.3773 - mae: 11.3773\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 12.4943 - mae: 12.4943\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 17.1806 - mae: 17.1806\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 6.5868 - mae: 6.5868\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 20.2937 - mae: 20.2937\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 10.1603 - mae: 10.1603\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 24.3412 - mae: 24.3412\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 19.0062 - mae: 19.0062\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.1568 - mae: 7.1568\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.2525 - mae: 18.2525\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.3016 - mae: 13.3016\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 14.8493 - mae: 14.8493\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.6420 - mae: 11.6420\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.1989 - mae: 16.1989\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 15.5408 - mae: 15.5408\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 15.0745 - mae: 15.0745\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 10.9028 - mae: 10.9028\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 14.3632 - mae: 14.3632\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.3803 - mae: 13.3803\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 20.0006 - mae: 20.0006\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 22.5093 - mae: 22.5093\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 11.2684 - mae: 11.2684\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 9.3537 - mae: 9.3537\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 25.1414 - mae: 25.1414\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.4051 - mae: 12.4051\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 9.3900 - mae: 9.3900\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 23.1575 - mae: 23.1575\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.2658 - mae: 8.2658\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 13.9986 - mae: 13.9986\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.6380 - mae: 10.6380\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 16.9615 - mae: 16.9615\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 8.2612 - mae: 8.2612\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 19.6433 - mae: 19.6433\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 17.3525 - mae: 17.3525\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.2152 - mae: 11.2152\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 23.5090 - mae: 23.5090\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.7123 - mae: 9.7123\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.7899 - mae: 10.7899\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.0862 - mae: 8.0862\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 29.8441 - mae: 29.8441\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.1167 - mae: 8.1167\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 28.4188 - mae: 28.4188\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 33.0344 - mae: 33.0344\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 19.7398 - mae: 19.7398\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.0483 - mae: 7.0483\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 21.8956 - mae: 21.8956\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.0288 - mae: 8.0288\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 21.1270 - mae: 21.1270\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.0605 - mae: 9.0605\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 24.1044 - mae: 24.1044\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 9.8044 - mae: 9.8044\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 18.3432 - mae: 18.3432\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.6218 - mae: 7.6218\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 18.6010 - mae: 18.6010\n",
      "Epoch 135/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 997us/step - loss: 10.5756 - mae: 10.5756\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 994us/step - loss: 18.2770 - mae: 18.2770\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 23.1654 - mae: 23.1654\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 9.1616 - mae: 9.1616\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.9421 - mae: 8.9421\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 16.4477 - mae: 16.4477\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 8.4558 - mae: 8.4558\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 496us/step - loss: 36.8323 - mae: 36.8323\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 25.5072 - mae: 25.5072\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 9.5716 - mae: 9.5716\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 26.6433 - mae: 26.6433\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.7122 - mae: 8.7122\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 995us/step - loss: 15.6727 - mae: 15.6727\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.3720 - mae: 18.3720\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.1830 - mae: 8.1830\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 7.5115 - mae: 7.5115\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 18.2000 - mae: 18.2000\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.2853 - mae: 10.2853\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 995us/step - loss: 29.3987 - mae: 29.3987\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.6230 - mae: 10.6230\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.5145 - mae: 15.5145\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 17.1399 - mae: 17.1399\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 32.5115 - mae: 32.5115\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.6486 - mae: 10.6486\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 8.8944 - mae: 8.8944\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 21.8907 - mae: 21.8907\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.1114 - mae: 11.1114\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 21.4158 - mae: 21.4158\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 18.8954 - mae: 18.8954\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.7352 - mae: 12.7352\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 12.7258 - mae: 12.7258\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 18.8948 - mae: 18.8948\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 26.8457 - mae: 26.8457\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.0009 - mae: 10.0009\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.0898 - mae: 23.0898\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 10.0868 - mae: 10.0868\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.8336 - mae: 17.8336\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 29.3574 - mae: 29.3574\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 16.9520 - mae: 16.9520\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.1855 - mae: 11.1855\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 27.4547 - mae: 27.4547\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 8.4489 - mae: 8.4489\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 9.4056 - mae: 9.4056\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 18.5519 - mae: 18.5519\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.4275 - mae: 10.4275\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 8.0056 - mae: 8.0056\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.7260 - mae: 17.7260\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.1923 - mae: 11.1923\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.3743 - mae: 12.3743\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 27.2881 - mae: 27.2881\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 7.5876 - mae: 7.5876\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 15.9848 - mae: 15.9848\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 8.6030 - mae: 8.6030\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 28.7597 - mae: 28.7597\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 13.1783 - mae: 13.1783\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 18.3223 - mae: 18.3223\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.7529 - mae: 13.7529\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.7311 - mae: 13.7311\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 28.5937 - mae: 28.5937\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 7.0936 - mae: 7.0936\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 7.0888 - mae: 7.0888\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 22.0412 - mae: 22.0412\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 20.7798 - mae: 20.7798\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 12.4450 - mae: 12.4450\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.8517 - mae: 17.8517\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.6976 - mae: 13.6976\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 5.5117 - mae: 5.5117\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 13.6463 - mae: 13.6463\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.4264 - mae: 9.4264\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 20.8496 - mae: 20.8496\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.5375 - mae: 9.5375\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.1761 - mae: 11.1761\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 17.7283 - mae: 17.7283\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.4239 - mae: 14.4239\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 16.7506 - mae: 16.7506\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 18.2737 - mae: 18.2737\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 9.9818 - mae: 9.9818\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 18.7556 - mae: 18.7556\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 14.9413 - mae: 14.9413\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.5283 - mae: 14.5283\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.1686 - mae: 23.1686\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.6047 - mae: 13.6047\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 497us/step - loss: 10.0734 - mae: 10.0734\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.4186 - mae: 12.4186\n",
      "Epoch 219/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 997us/step - loss: 5.8714 - mae: 5.8714\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.2063 - mae: 10.2063\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 28.8825 - mae: 28.8825\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 28.0701 - mae: 28.0701\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 10.0777 - mae: 10.0777\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 14.6278 - mae: 14.6278\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 16.6448 - mae: 16.6448\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.8666 - mae: 15.8666\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.0852 - mae: 16.0852\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 13.8641 - mae: 13.8641\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.9840 - mae: 17.9840\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.5783 - mae: 15.5783\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 21.1014 - mae: 21.1014\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 25.5060 - mae: 25.5060\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 16.5073 - mae: 16.5073\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 7.3624 - mae: 7.3624\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 17.1462 - mae: 17.1462\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.2218 - mae: 7.2218\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 9.3194 - mae: 9.3194\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 8.1775 - mae: 8.1775\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 17.1610 - mae: 17.1610\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.9479 - mae: 8.9479\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.2574 - mae: 13.2574\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 8.8585 - mae: 8.8585\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 18.8868 - mae: 18.8868\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.0563 - mae: 14.0563\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 14.6840 - mae: 14.6840\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 15.8171 - mae: 15.8171\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 17.6968 - mae: 17.6968\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 13.2535 - mae: 13.2535\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.5275 - mae: 14.5275\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 23.2527 - mae: 23.2527\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.3337 - mae: 9.3337\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 36.5867 - mae: 36.5867\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 21.7806 - mae: 21.7806\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.3169 - mae: 7.3169\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 24.6447 - mae: 24.6447\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.4179 - mae: 12.4179\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 497us/step - loss: 10.5846 - mae: 10.5846\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 14.1860 - mae: 14.1860\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.2612 - mae: 11.2612\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 31.5570 - mae: 31.5570\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.1806 - mae: 11.1806\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.0363 - mae: 10.0363\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.9539 - mae: 8.9539\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.4497 - mae: 21.4497\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.4696 - mae: 11.4696\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.3109 - mae: 13.3109\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 11.0960 - mae: 11.0960\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 995us/step - loss: 19.1820 - mae: 19.1820\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 40.6321 - mae: 40.6321\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.8939 - mae: 12.8939\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.7735 - mae: 14.7735\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 28.5239 - mae: 28.5239\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.3649 - mae: 7.3649\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 6.3646 - mae: 6.3646\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 36.8359 - mae: 36.8359\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.2925 - mae: 8.2925\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 27.6667 - mae: 27.6667\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.6925 - mae: 10.6925\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.1202 - mae: 16.1202\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 21.2550 - mae: 21.2550\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.7470 - mae: 23.7470\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.2580 - mae: 8.2580\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.4443 - mae: 8.4443\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 26.5833 - mae: 26.5833\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.1990 - mae: 14.1990\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.2652 - mae: 5.2652\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 20.8363 - mae: 20.8363\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 27.5655 - mae: 27.5655\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.4466 - mae: 10.4466\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 16.3191 - mae: 16.3191\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 16.5101 - mae: 16.5101\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.4372 - mae: 7.4372\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.5537 - mae: 16.5537\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 25.3454 - mae: 25.3454\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.5567 - mae: 14.5567\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 4.6779 - mae: 4.6779\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 7.2820 - mae: 7.2820\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 19.5894 - mae: 19.5894\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 6.6188 - mae: 6.6188\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 22.0367 - mae: 22.0367\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 9.1308 - mae: 9.1308\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.1834 - mae: 11.1834\n",
      "Epoch 303/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step - loss: 9.3357 - mae: 9.3357\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 23.6902 - mae: 23.6902\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 7.9213 - mae: 7.9213\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 23.7434 - mae: 23.7434\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 5.8868 - mae: 5.8868\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 21.3286 - mae: 21.3286\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 18.3994 - mae: 18.3994\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 4.4978 - mae: 4.4978\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 6.5091 - mae: 6.5091\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 35.4382 - mae: 35.4382\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 28.9148 - mae: 28.9148\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.1945 - mae: 11.1945\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 23.5547 - mae: 23.5547\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.4208 - mae: 14.4208\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 501us/step - loss: 19.9661 - mae: 19.9661\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 7.9954 - mae: 7.9954\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 18.1037 - mae: 18.1037\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 10.6353 - mae: 10.6353\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 7.0212 - mae: 7.0212\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 8.6726 - mae: 8.6726\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 18.3385 - mae: 18.3385\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 987us/step - loss: 6.3034 - mae: 6.3034\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.6095 - mae: 14.6095\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 6.9862 - mae: 6.9862\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.6239 - mae: 17.6239\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.3733 - mae: 14.3733\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 17.6845 - mae: 17.6845\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 6.7786 - mae: 6.7786\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 19.7463 - mae: 19.7463\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 502us/step - loss: 10.5487 - mae: 10.5487\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 16.3442 - mae: 16.3442\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.7154 - mae: 9.7154\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 13.0544 - mae: 13.0544\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 32.4919 - mae: 32.4919\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.0362 - mae: 11.0362\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 19.9478 - mae: 19.9478\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 34.3321 - mae: 34.3321\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.2796 - mae: 9.2796\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.3006 - mae: 17.3006\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 14.9113 - mae: 14.9113\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 10.3158 - mae: 10.3158\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 9.9336 - mae: 9.9336\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 30.8990 - mae: 30.8990\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.6250 - mae: 10.6250\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 25.5353 - mae: 25.5353\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.3548 - mae: 13.3548\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 13.0062 - mae: 13.0062\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.3883 - mae: 15.3883\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 32.8591 - mae: 32.8591\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 14.0585 - mae: 14.0585\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.7457 - mae: 17.7457\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.3277 - mae: 11.3277\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 26.7386 - mae: 26.7386\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 10.1938 - mae: 10.1938\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 14.7789 - mae: 14.7789\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 14.6654 - mae: 14.6654\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 12.3236 - mae: 12.3236\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 20.3227 - mae: 20.3227\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 10.9378 - mae: 10.9378\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 6.8188 - mae: 6.8188\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 23.8776 - mae: 23.8776\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 29.6005 - mae: 29.6005\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 8.3080 - mae: 8.3080\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 6.1020 - mae: 6.1020\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 34.7127 - mae: 34.7127\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 7.3756 - mae: 7.3756\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.1755 - mae: 9.1755\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.8641 - mae: 10.8641\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.6410 - mae: 8.6410\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.4582 - mae: 6.4582\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.4218 - mae: 23.4218\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 10.4537 - mae: 10.4537\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.0513 - mae: 13.0513\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 14.9367 - mae: 14.9367\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 14.8224 - mae: 14.8224\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.2965 - mae: 16.2965\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 20.8895 - mae: 20.8895\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 33.3745 - mae: 33.3745\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.1589 - mae: 8.1589\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.0057 - mae: 13.0057\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.4480 - mae: 8.4480\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.0604 - mae: 7.0604\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.9545 - mae: 10.9545\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 19.8100 - mae: 19.8100\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 997us/step - loss: 24.7596 - mae: 24.7596\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.6847 - mae: 8.6847\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 5.9197 - mae: 5.9197\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 24.3429 - mae: 24.3429\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 5.9424 - mae: 5.9424\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 16.0986 - mae: 16.0986\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 6.4637 - mae: 6.4637\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 614us/step - loss: 12.5466 - mae: 12.5466\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.4190 - mae: 12.4190\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.3305 - mae: 7.3305\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 7.5898 - mae: 7.5898\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 20.3907 - mae: 20.3907\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 5.8798 - mae: 5.8798\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 24.5904 - mae: 24.5904\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 13.2330 - mae: 13.2330\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.3559 - mae: 8.3559\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.2302 - mae: 10.2302\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.0815 - mae: 10.0815\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 6.2633 - mae: 6.2633\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 19.4353 - mae: 19.4353\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 10.2699 - mae: 10.2699\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 20.8920 - mae: 20.8920\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 30.8533 - mae: 30.8533\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 9.3428 - mae: 9.3428\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 14.9321 - mae: 14.9321\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 21.8482 - mae: 21.8482\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.4072 - mae: 12.4072\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 6.6135 - mae: 6.6135\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.7063 - mae: 12.7063\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 26.9449 - mae: 26.9449\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.0251 - mae: 12.0251\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.0729 - mae: 13.0729\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 16.0353 - mae: 16.0353\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 25.0797 - mae: 25.0797\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 16.5748 - mae: 16.5748\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.6843 - mae: 8.6843\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.8024 - mae: 24.8024\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 16.5055 - mae: 16.5055\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 7.2266 - mae: 7.2266\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 500us/step - loss: 20.6458 - mae: 20.6458\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 6.3986 - mae: 6.3986\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.2137 - mae: 13.2137\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.9741 - mae: 10.9741\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.8502 - mae: 11.8502\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.4907 - mae: 8.4907\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 18.5577 - mae: 18.5577\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.1399 - mae: 10.1399\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 30.6716 - mae: 30.6716\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.1748 - mae: 11.1748\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 28.7722 - mae: 28.7722\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 8.0387 - mae: 8.0387\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 12.8111 - mae: 12.8111\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 33.9087 - mae: 33.9087\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 15.4282 - mae: 15.4282\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 17.7708 - mae: 17.7708\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 6.4168 - mae: 6.4168\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 12.8951 - mae: 12.8951\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 5.5577 - mae: 5.5577\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 9.6911 - mae: 9.6911\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.1375 - mae: 15.1375\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 22.3797 - mae: 22.3797\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.6292 - mae: 13.6292\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 11.7118 - mae: 11.7118\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 15.2425 - mae: 15.2425\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 17.0833 - mae: 17.0833\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 45.3382 - mae: 45.3382\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 26.1022 - mae: 26.1022\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 22.7545 - mae: 22.7545\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 8.0246 - mae: 8.0246\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 10.4082 - mae: 10.4082\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 15.0143 - mae: 15.0143\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 16.5696 - mae: 16.5696\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 26.8504 - mae: 26.8504\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.4544 - mae: 12.4544\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.4981 - mae: 12.4981\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 13.3250 - mae: 13.3250\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 29.5628 - mae: 29.5628\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.4787 - mae: 3.4787\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 999us/step - loss: 15.2241 - mae: 15.2241\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 20.8594 - mae: 20.8594\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 30.4365 - mae: 30.4365\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 11.0335 - mae: 11.0335\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.7942 - mae: 12.7942\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 3.2505 - mae: 3.2505\n",
      "Epoch 471/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 997us/step - loss: 16.7254 - mae: 16.7254\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.4109 - mae: 13.4109\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 15.3054 - mae: 15.3054\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 996us/step - loss: 11.7739 - mae: 11.7739\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 16.4374 - mae: 16.4374\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 13.8916 - mae: 13.8916\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 30.6912 - mae: 30.6912\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 8.6252 - mae: 8.6252\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 10.7660 - mae: 10.7660\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 17.9336 - mae: 17.9336\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 15.8334 - mae: 15.8334\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 21.3522 - mae: 21.3522\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 25.2810 - mae: 25.2810\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 23.8773 - mae: 23.8773\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 5.7682 - mae: 5.7682\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 19.8748 - mae: 19.8748\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.0581 - mae: 14.0581\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 30.6372 - mae: 30.6372\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 11.9881 - mae: 11.9881\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 12.7608 - mae: 12.7608\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 23.6628 - mae: 23.6628\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 498us/step - loss: 20.4167 - mae: 20.4167\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 4.9820 - mae: 4.9820\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 12.6966 - mae: 12.6966\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 13.4265 - mae: 13.4265\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 497us/step - loss: 12.7079 - mae: 12.7079\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 17.6841 - mae: 17.6841\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 998us/step - loss: 23.4230 - mae: 23.4230\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 499us/step - loss: 9.1590 - mae: 9.1590\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 997us/step - loss: 14.3818 - mae: 14.3818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x249cd156f70>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build model-1\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model1 = tf.keras.Sequential([tf.keras.layers.Dense(1)])\n",
    "model1.compile(optimizer=\"SGD\", loss=\"mae\", metrics=[\"mae\"])\n",
    "model1.fit(X_train,y_train, epochs=100)\n",
    "\n",
    "# model2\n",
    "model2 = tf.keras.Sequential([tf.keras.layers.Dense(10),\n",
    "                             tf.keras.layers.Dense(1)])\n",
    "model2.compile(optimizer=\"SGD\", loss=\"mae\",metrics=[\"mae\"])\n",
    "model2.fit(X_train,y_train,epochs=100)\n",
    "\n",
    "# model3\n",
    "model3 = tf.keras.Sequential([tf.keras.layers.Dense(10),\n",
    "                             tf.keras.layers.Dense(1)])\n",
    "model3.compile(optimizer=\"SGD\", loss=\"mae\",metrics=[\"mae\"])\n",
    "model3.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "82815a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000249CD353160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[62.28419 ],\n",
       "       [65.76943 ],\n",
       "       [69.25468 ],\n",
       "       [72.739914],\n",
       "       [76.22515 ],\n",
       "       [79.710396],\n",
       "       [83.19563 ],\n",
       "       [86.68087 ],\n",
       "       [90.16611 ],\n",
       "       [93.65135 ]], dtype=float32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_y_pred = model1.predict(y_test)\n",
    "model1_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7f79cb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MAE is 10.032228469848633, Model MSE is 102.8316650390625\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(X_train,y_train,X_test, y_test, model1_y_pred)\n",
    "mae_1, mse_1 = evaluation_metrics(y_test, model1_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1d38cec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000249CCCC8550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Model MAE is 3.1110053062438965, Model MSE is 12.497129440307617\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2_y_pred = model2.predict(X_test)\n",
    "plot_predictions(X_train,y_train, X_test, y_test, model2_y_pred)\n",
    "mae_2, mse_2 = evaluation_metrics(y_test, model2_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a4de7782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:10 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000249CCE51280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Model MAE is 67.9095687866211, Model MSE is 4696.0634765625\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3_y_pred = model3.predict(X_test)\n",
    "plot_predictions(X_train,y_train, X_test, y_test, model3_y_pred)\n",
    "mae_3, mse_3 = evaluation_metrics(y_test, model3_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cc243986",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparing the results of your experiments\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8ee5805e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model1</td>\n",
       "      <td>10.032228</td>\n",
       "      <td>102.831665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model2</td>\n",
       "      <td>3.111005</td>\n",
       "      <td>12.497129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model3</td>\n",
       "      <td>67.909569</td>\n",
       "      <td>4696.063477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Models        MAE          MSE\n",
       "0  model1  10.032228   102.831665\n",
       "1  model2   3.111005    12.497129\n",
       "2  model3  67.909569  4696.063477"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results = [[\"model1\", mae_1.numpy(), mse_1.numpy()],\n",
    "                [\"model2\", mae_2.numpy(), mse_2.numpy()],\n",
    "                 [\"model3\", mae_3.numpy(), mse_3.numpy()]]\n",
    "\n",
    "all_results = pd.DataFrame(model_results, columns=[\"Models\",\"MAE\",\"MSE\"])\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "641c38f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c409310c",
   "metadata": {},
   "source": [
    "** one of your goals should be the time between your experiments. The more experiments you do, the more things your will figure\n",
    "out which will provide better insights about models and what will work to increase the accuracy of model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3837963c",
   "metadata": {},
   "source": [
    "## Tracking your experiments -\n",
    "one really good habit is to keep track of your experiments but it becomes very difficult to do so when you are running lots\n",
    "of experiments. as you run more models you can look into TENSORBOARD which will assist you in better managing and tracking your\n",
    "experiments. \n",
    "Another one weights and biases-- plug straight into tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "96c9fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ea5a6fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: first_tensormodel\\assets\n"
     ]
    }
   ],
   "source": [
    "# There are two formats for saving models - HDF5 and savedmodel format.\\\\\n",
    "# Hdf5 will also has assets in protobuf format\n",
    "# HDf5 has the extension of h5 which allow to process larger amount of data easily across different platforms.\n",
    "\n",
    "# Save model using savemodel format\n",
    "\n",
    "model2.save(\"first_tensormodel\")\n",
    "model2.save(\"first_tensormodel.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "97dd8a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Loading the saved models and testing them\n",
    "\n",
    "loaded_savedmodel_format = tf.keras.models.load_model(\"first_tensormodel\")\n",
    "loaded_savedmodel_format.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "301719f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000249CCCC8160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_predictions = loaded_savedmodel_format.predict(X_test)\n",
    "loaded_model_predictions == model2_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6d3b84b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_h5_model = tf.keras.models.load_model(\"first_tensormodel.h5\")\n",
    "loaded_h5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2a2600c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 70.48064 ],\n",
       "       [ 75.06517 ],\n",
       "       [ 79.6497  ],\n",
       "       [ 84.23422 ],\n",
       "       [ 88.81875 ],\n",
       "       [ 93.40326 ],\n",
       "       [ 97.987785],\n",
       "       [102.57232 ],\n",
       "       [107.156845],\n",
       "       [111.74137 ]], dtype=float32)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a4b082bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_h5_preds = loaded_h5_model.predict(X_test)\n",
    "loaded_h5_preds == model2_y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c3d14",
   "metadata": {},
   "source": [
    "### A Larger example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "90f35b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6c16ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the source file\n",
    "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "fbb3d334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b4903ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.207025</td>\n",
       "      <td>30.663397</td>\n",
       "      <td>1.094918</td>\n",
       "      <td>13270.422265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.049960</td>\n",
       "      <td>6.098187</td>\n",
       "      <td>1.205493</td>\n",
       "      <td>12110.011237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1121.873900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>26.296250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4740.287150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9382.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>34.693750</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16639.912515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>53.130000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>63770.428010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          bmi     children       charges\n",
       "count  1338.000000  1338.000000  1338.000000   1338.000000\n",
       "mean     39.207025    30.663397     1.094918  13270.422265\n",
       "std      14.049960     6.098187     1.205493  12110.011237\n",
       "min      18.000000    15.960000     0.000000   1121.873900\n",
       "25%      27.000000    26.296250     0.000000   4740.287150\n",
       "50%      39.000000    30.400000     1.000000   9382.033000\n",
       "75%      51.000000    34.693750     2.000000  16639.912515\n",
       "max      64.000000    53.130000     5.000000  63770.428010"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8467a5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "insurance.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2ef18a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>10600.54830</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>2205.98080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>1629.83350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>2007.94500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>29141.36030</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
       "0      19  27.900         0  16884.92400           1         0          0   \n",
       "1      18  33.770         1   1725.55230           0         1          1   \n",
       "2      28  33.000         3   4449.46200           0         1          1   \n",
       "3      33  22.705         0  21984.47061           0         1          1   \n",
       "4      32  28.880         0   3866.85520           0         1          1   \n",
       "...   ...     ...       ...          ...         ...       ...        ...   \n",
       "1333   50  30.970         3  10600.54830           0         1          1   \n",
       "1334   18  31.920         0   2205.98080           1         0          1   \n",
       "1335   18  36.850         0   1629.83350           1         0          1   \n",
       "1336   21  25.800         0   2007.94500           1         0          1   \n",
       "1337   61  29.070         0  29141.36030           1         0          0   \n",
       "\n",
       "      smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
       "0              1                 0                 0                 0   \n",
       "1              0                 0                 0                 1   \n",
       "2              0                 0                 0                 1   \n",
       "3              0                 0                 1                 0   \n",
       "4              0                 0                 1                 0   \n",
       "...          ...               ...               ...               ...   \n",
       "1333           0                 0                 1                 0   \n",
       "1334           0                 1                 0                 0   \n",
       "1335           0                 0                 0                 1   \n",
       "1336           0                 0                 0                 0   \n",
       "1337           1                 0                 1                 0   \n",
       "\n",
       "      region_southwest  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "1333                 0  \n",
       "1334                 0  \n",
       "1335                 0  \n",
       "1336                 1  \n",
       "1337                 0  \n",
       "\n",
       "[1338 rows x 12 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_one_hot = pd.get_dummies(insurance)\n",
    "insurance_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "2c66b2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(age                   int64\n",
       " bmi                 float64\n",
       " children              int64\n",
       " sex_female            uint8\n",
       " sex_male              uint8\n",
       " smoker_no             uint8\n",
       " smoker_yes            uint8\n",
       " region_northeast      uint8\n",
       " region_northwest      uint8\n",
       " region_southeast      uint8\n",
       " region_southwest      uint8\n",
       " dtype: object,\n",
       " dtype('float64'))"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = insurance_one_hot.drop([\"charges\"],axis=1)\n",
    "y = insurance_one_hot[\"charges\"]\n",
    "X.dtypes, y.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "a5fdd75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 1070)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split =  int(round(len(X)*.8))\n",
    "X_train, X_test = X.iloc[:split,:], X.iloc[split:,:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "5b7fdda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "68e4b1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Layer dense_60 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 381us/step - loss: 8417.7715 - mae: 8417.7715\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7534.7109 - mae: 7534.7109\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 352us/step - loss: 7588.4492 - mae: 7588.4492\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7605.2920 - mae: 7605.2920\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7684.2012 - mae: 7684.2012\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 363us/step - loss: 7341.3657 - mae: 7341.3657\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7484.7373 - mae: 7484.7373\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7516.0957 - mae: 7516.0957\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7440.3594 - mae: 7440.3594\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7723.9370 - mae: 7723.9370\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7455.2773 - mae: 7455.2773\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7557.6206 - mae: 7557.6206\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7411.5820 - mae: 7411.5820\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 573us/step - loss: 7696.8232 - mae: 7696.8232\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7431.5449 - mae: 7431.5449\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7435.9243 - mae: 7435.9243\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7626.6831 - mae: 7626.6831\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7528.3232 - mae: 7528.3232\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7304.8970 - mae: 7304.8970\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 557us/step - loss: 7570.1880 - mae: 7570.1880\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 499us/step - loss: 7514.2622 - mae: 7514.2622\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7629.5654 - mae: 7629.5654\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7560.2686 - mae: 7560.2686\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7507.5625 - mae: 7507.5625\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7406.0640 - mae: 7406.0640\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 350us/step - loss: 7306.2388 - mae: 7306.2388\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7394.7251 - mae: 7394.7251\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7426.4575 - mae: 7426.4575\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7305.2974 - mae: 7305.2974\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7325.2759 - mae: 7325.2759\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 528us/step - loss: 7368.2637 - mae: 7368.2637\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7580.4487 - mae: 7580.4487\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7485.3022 - mae: 7485.3022\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7581.1943 - mae: 7581.1943\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7349.0352 - mae: 7349.0352\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7092.8604 - mae: 7092.8604\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7476.2900 - mae: 7476.2900\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 364us/step - loss: 7623.7383 - mae: 7623.7383\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7128.8330 - mae: 7128.8330\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7318.7480 - mae: 7318.7480\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7359.2305 - mae: 7359.2305\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7386.5957 - mae: 7386.5957\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7311.2964 - mae: 7311.2964\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7579.1626 - mae: 7579.1626\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7365.8652 - mae: 7365.8652\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7397.7412 - mae: 7397.7412\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7357.6421 - mae: 7357.6421\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7536.2920 - mae: 7536.2920\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7513.8447 - mae: 7513.8447\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 389us/step - loss: 7401.3784 - mae: 7401.3784\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7441.6855 - mae: 7441.6855\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7229.9604 - mae: 7229.9604\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7152.4619 - mae: 7152.4619\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7314.6094 - mae: 7314.6094\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7428.3325 - mae: 7428.3325\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 389us/step - loss: 7386.7646 - mae: 7386.7646\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7391.5210 - mae: 7391.5210\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 616us/step - loss: 7303.4238 - mae: 7303.4238\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 557us/step - loss: 7331.3745 - mae: 7331.3745\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7256.2168 - mae: 7256.2168\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7194.3120 - mae: 7194.3120\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7228.5835 - mae: 7228.5835\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7393.7231 - mae: 7393.7231\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7141.4248 - mae: 7141.4248\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7368.0923 - mae: 7368.0923\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7330.0688 - mae: 7330.0688\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7413.8418 - mae: 7413.8418\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7304.7886 - mae: 7304.7886\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7313.7661 - mae: 7313.7661\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7298.5332 - mae: 7298.5332\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7291.5176 - mae: 7291.5176\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7233.1343 - mae: 7233.1343\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 469us/step - loss: 7275.7441 - mae: 7275.7441\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7337.7769 - mae: 7337.7769\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7108.5762 - mae: 7108.5762\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7040.5859 - mae: 7040.5859\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7229.2905 - mae: 7229.2905\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 410us/step - loss: 7241.0713 - mae: 7241.0713\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 444us/step - loss: 7067.3174 - mae: 7067.3174\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7286.1177 - mae: 7286.1177\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7367.3838 - mae: 7367.3838\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7349.1172 - mae: 7349.1172\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 439us/step - loss: 7388.1963 - mae: 7388.1963\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7251.3018 - mae: 7251.3018\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7202.6436 - mae: 7202.6436\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7118.2734 - mae: 7118.2734\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7276.3618 - mae: 7276.3618\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7456.0454 - mae: 7456.0454\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6967.2148 - mae: 6967.2148\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7359.5869 - mae: 7359.5869\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7270.0439 - mae: 7270.0439\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7078.2578 - mae: 7078.2578\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7050.9473 - mae: 7050.9473\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 416us/step - loss: 7129.9229 - mae: 7129.9229\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6943.3394 - mae: 6943.3394\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 454us/step - loss: 7074.5078 - mae: 7074.5078\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7471.9004 - mae: 7471.9004\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7198.4541 - mae: 7198.4541\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7115.1733 - mae: 7115.1733\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7115.5664 - mae: 7115.5664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x249d35f87f0>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "## Create a baseline neural network to check the model performance\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(10),\n",
    "                            tf.keras.layers.Dense(1)])\n",
    "\n",
    "# compiling the model\n",
    "model.compile(optimizer= tf.keras.optimizers.SGD(), loss= tf.keras.losses.mae, metrics=[\"mae\"])\n",
    "\n",
    "\n",
    "# fitting the model\n",
    "model.fit(X_train,y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "0d781ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 554us/step - loss: 6556.6406 - mae: 6556.6406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6556.640625, 6556.640625]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results of the insurance model on the test data\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ddf5f",
   "metadata": {},
   "source": [
    "### Improving the model by following experiments -\n",
    "\n",
    "1. Change the number of epochs to 500. \n",
    "2. Increase the number of dense layers for training.\n",
    "3. Increase the number of dense layers and increase no of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "410bc82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:Layer dense_96 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 368us/step - loss: 8372.6094 - mae: 8372.6094\n",
      "Epoch 2/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7456.5308 - mae: 7456.5308\n",
      "Epoch 3/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7624.8379 - mae: 7624.8379\n",
      "Epoch 4/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7551.2510 - mae: 7551.2510\n",
      "Epoch 5/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7731.8252 - mae: 7731.8252\n",
      "Epoch 6/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7371.2866 - mae: 7371.2866\n",
      "Epoch 7/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7660.0293 - mae: 7660.0293\n",
      "Epoch 8/500\n",
      "34/34 [==============================] - 0s 431us/step - loss: 7608.2593 - mae: 7608.2593\n",
      "Epoch 9/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7474.7705 - mae: 7474.7705\n",
      "Epoch 10/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7719.9980 - mae: 7719.9980\n",
      "Epoch 11/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7540.0146 - mae: 7540.0146\n",
      "Epoch 12/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7696.2617 - mae: 7696.2617\n",
      "Epoch 13/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7320.2319 - mae: 7320.2319\n",
      "Epoch 14/500\n",
      "34/34 [==============================] - 0s 397us/step - loss: 7647.1235 - mae: 7647.1235\n",
      "Epoch 15/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7434.0200 - mae: 7434.0200\n",
      "Epoch 16/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 7451.3789 - mae: 7451.3789\n",
      "Epoch 17/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7719.9209 - mae: 7719.9209\n",
      "Epoch 18/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7513.1284 - mae: 7513.1284\n",
      "Epoch 19/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7294.0508 - mae: 7294.0508\n",
      "Epoch 20/500\n",
      "34/34 [==============================] - 0s 451us/step - loss: 7485.3091 - mae: 7485.3091\n",
      "Epoch 21/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7491.9673 - mae: 7491.9673\n",
      "Epoch 22/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7714.5879 - mae: 7714.5879\n",
      "Epoch 23/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 7430.9551 - mae: 7430.9551\n",
      "Epoch 24/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7535.4937 - mae: 7535.4937\n",
      "Epoch 25/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7552.8247 - mae: 7552.8247\n",
      "Epoch 26/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7464.7808 - mae: 7464.7808\n",
      "Epoch 27/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7263.1250 - mae: 7263.1250\n",
      "Epoch 28/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 7351.8140 - mae: 7351.8140\n",
      "Epoch 29/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7350.8872 - mae: 7350.8872\n",
      "Epoch 30/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7633.2031 - mae: 7633.2031\n",
      "Epoch 31/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 7343.8984 - mae: 7343.8984\n",
      "Epoch 32/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7597.4194 - mae: 7597.4194\n",
      "Epoch 33/500\n",
      "34/34 [==============================] - ETA: 0s - loss: 7933.7910 - mae: 7933.791 - 0s 411us/step - loss: 7418.6670 - mae: 7418.6670\n",
      "Epoch 34/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7588.5723 - mae: 7588.5723\n",
      "Epoch 35/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 7451.5742 - mae: 7451.5742\n",
      "Epoch 36/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7345.4106 - mae: 7345.4106\n",
      "Epoch 37/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7469.3877 - mae: 7469.3877\n",
      "Epoch 38/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7538.0903 - mae: 7538.0903\n",
      "Epoch 39/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7389.8096 - mae: 7389.8096\n",
      "Epoch 40/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7506.3652 - mae: 7506.3652\n",
      "Epoch 41/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 7203.7349 - mae: 7203.7349\n",
      "Epoch 42/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7389.4697 - mae: 7389.4697\n",
      "Epoch 43/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7229.0303 - mae: 7229.0303\n",
      "Epoch 44/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7554.8848 - mae: 7554.8848\n",
      "Epoch 45/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7223.9492 - mae: 7223.9492\n",
      "Epoch 46/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7385.7451 - mae: 7385.7451\n",
      "Epoch 47/500\n",
      "34/34 [==============================] - 0s 464us/step - loss: 7318.2773 - mae: 7318.2773\n",
      "Epoch 48/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 7405.2461 - mae: 7405.2461\n",
      "Epoch 49/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 7475.3359 - mae: 7475.3359\n",
      "Epoch 50/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7363.7397 - mae: 7363.7397\n",
      "Epoch 51/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 7408.2866 - mae: 7408.2866\n",
      "Epoch 52/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7267.9893 - mae: 7267.9893\n",
      "Epoch 53/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7302.1997 - mae: 7302.1997\n",
      "Epoch 54/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7387.2319 - mae: 7387.2319\n",
      "Epoch 55/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7585.1807 - mae: 7585.1807\n",
      "Epoch 56/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 7111.5049 - mae: 7111.5049\n",
      "Epoch 57/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7283.5366 - mae: 7283.5366\n",
      "Epoch 58/500\n",
      "34/34 [==============================] - 0s 383us/step - loss: 7228.9575 - mae: 7228.9575\n",
      "Epoch 59/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7376.1729 - mae: 7376.1729\n",
      "Epoch 60/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7248.2910 - mae: 7248.2910\n",
      "Epoch 61/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7264.9766 - mae: 7264.9766\n",
      "Epoch 62/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7283.3452 - mae: 7283.3452\n",
      "Epoch 63/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7319.1172 - mae: 7319.1172\n",
      "Epoch 64/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7178.7739 - mae: 7178.7739\n",
      "Epoch 65/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7393.4795 - mae: 7393.4795\n",
      "Epoch 66/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7246.4883 - mae: 7246.4883\n",
      "Epoch 67/500\n",
      "34/34 [==============================] - 0s 383us/step - loss: 7356.6128 - mae: 7356.6128\n",
      "Epoch 68/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7247.0469 - mae: 7247.0469\n",
      "Epoch 69/500\n",
      "34/34 [==============================] - 0s 370us/step - loss: 7400.3530 - mae: 7400.3530\n",
      "Epoch 70/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7212.2588 - mae: 7212.2588\n",
      "Epoch 71/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 7394.3647 - mae: 7394.3647\n",
      "Epoch 72/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7256.1367 - mae: 7256.1367\n",
      "Epoch 73/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 411us/step - loss: 7117.8564 - mae: 7117.8564\n",
      "Epoch 74/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7411.0884 - mae: 7411.0884\n",
      "Epoch 75/500\n",
      "34/34 [==============================] - 0s 401us/step - loss: 7150.5137 - mae: 7150.5137\n",
      "Epoch 76/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7236.3735 - mae: 7236.3735\n",
      "Epoch 77/500\n",
      "34/34 [==============================] - 0s 369us/step - loss: 7291.4077 - mae: 7291.4077\n",
      "Epoch 78/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7232.8276 - mae: 7232.8276\n",
      "Epoch 79/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7156.6685 - mae: 7156.6685\n",
      "Epoch 80/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7218.8423 - mae: 7218.8423\n",
      "Epoch 81/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 7308.6787 - mae: 7308.6787\n",
      "Epoch 82/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 7259.3735 - mae: 7259.3735\n",
      "Epoch 83/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7144.7998 - mae: 7144.7998\n",
      "Epoch 84/500\n",
      "34/34 [==============================] - 0s 371us/step - loss: 7330.5356 - mae: 7330.5356\n",
      "Epoch 85/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7351.8691 - mae: 7351.8691\n",
      "Epoch 86/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7278.2085 - mae: 7278.2085\n",
      "Epoch 87/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7344.0942 - mae: 7344.0942\n",
      "Epoch 88/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 7415.4092 - mae: 7415.4092\n",
      "Epoch 89/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6797.1719 - mae: 6797.1719\n",
      "Epoch 90/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7158.0190 - mae: 7158.0190\n",
      "Epoch 91/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7411.0625 - mae: 7411.0625\n",
      "Epoch 92/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7390.2139 - mae: 7390.2139\n",
      "Epoch 93/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7224.8179 - mae: 7224.8179\n",
      "Epoch 94/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7118.2104 - mae: 7118.2104\n",
      "Epoch 95/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 7127.9595 - mae: 7127.9595\n",
      "Epoch 96/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 7247.1143 - mae: 7247.1143\n",
      "Epoch 97/500\n",
      "34/34 [==============================] - 0s 362us/step - loss: 7446.3379 - mae: 7446.3379\n",
      "Epoch 98/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7045.0913 - mae: 7045.0913\n",
      "Epoch 99/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7304.3066 - mae: 7304.3066\n",
      "Epoch 100/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7073.0806 - mae: 7073.0806\n",
      "Epoch 101/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7309.4380 - mae: 7309.4380\n",
      "Epoch 102/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7163.8604 - mae: 7163.8604\n",
      "Epoch 103/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6833.9941 - mae: 6833.9941\n",
      "Epoch 104/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 7139.6685 - mae: 7139.6685\n",
      "Epoch 105/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6994.9302 - mae: 6994.9302\n",
      "Epoch 106/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 7082.2280 - mae: 7082.2280\n",
      "Epoch 107/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 6955.5806 - mae: 6955.5806\n",
      "Epoch 108/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6967.9365 - mae: 6967.9365\n",
      "Epoch 109/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7163.2017 - mae: 7163.2017\n",
      "Epoch 110/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7271.8691 - mae: 7271.8691\n",
      "Epoch 111/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7019.6904 - mae: 7019.6904\n",
      "Epoch 112/500\n",
      "34/34 [==============================] - 0s 434us/step - loss: 7081.3740 - mae: 7081.3740\n",
      "Epoch 113/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7190.3955 - mae: 7190.3955\n",
      "Epoch 114/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7026.1250 - mae: 7026.1250\n",
      "Epoch 115/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7271.6787 - mae: 7271.6787\n",
      "Epoch 116/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6986.8447 - mae: 6986.8447\n",
      "Epoch 117/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7197.3755 - mae: 7197.3755\n",
      "Epoch 118/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6934.2393 - mae: 6934.2393\n",
      "Epoch 119/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 6895.8267 - mae: 6895.8267\n",
      "Epoch 120/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7092.9165 - mae: 7092.9165\n",
      "Epoch 121/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 7204.9863 - mae: 7204.9863\n",
      "Epoch 122/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6948.7402 - mae: 6948.7402\n",
      "Epoch 123/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7496.5161 - mae: 7496.5161\n",
      "Epoch 124/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7180.6177 - mae: 7180.6177\n",
      "Epoch 125/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6915.8384 - mae: 6915.8384\n",
      "Epoch 126/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 7124.2661 - mae: 7124.2661\n",
      "Epoch 127/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 7245.8462 - mae: 7245.8462\n",
      "Epoch 128/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7005.4932 - mae: 7005.4932\n",
      "Epoch 129/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7108.3062 - mae: 7108.3062\n",
      "Epoch 130/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7047.5898 - mae: 7047.5898\n",
      "Epoch 131/500\n",
      "34/34 [==============================] - 0s 414us/step - loss: 7060.2832 - mae: 7060.2832\n",
      "Epoch 132/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6942.5767 - mae: 6942.5767\n",
      "Epoch 133/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7088.6157 - mae: 7088.6157\n",
      "Epoch 134/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6766.3862 - mae: 6766.3862\n",
      "Epoch 135/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7156.1074 - mae: 7156.1074\n",
      "Epoch 136/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7265.7583 - mae: 7265.7583\n",
      "Epoch 137/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6890.1729 - mae: 6890.1729\n",
      "Epoch 138/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6846.5718 - mae: 6846.5718\n",
      "Epoch 139/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7386.1924 - mae: 7386.1924\n",
      "Epoch 140/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6642.5840 - mae: 6642.5840\n",
      "Epoch 141/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7111.1440 - mae: 7111.1440\n",
      "Epoch 142/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7083.4756 - mae: 7083.4756\n",
      "Epoch 143/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6779.6357 - mae: 6779.6357\n",
      "Epoch 144/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7101.2827 - mae: 7101.2827\n",
      "Epoch 145/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6823.5400 - mae: 6823.5400\n",
      "Epoch 146/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6899.2378 - mae: 6899.2378\n",
      "Epoch 147/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7221.4185 - mae: 7221.4185\n",
      "Epoch 148/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7039.2520 - mae: 7039.2520\n",
      "Epoch 149/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7238.0161 - mae: 7238.0161\n",
      "Epoch 150/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6879.5596 - mae: 6879.5596\n",
      "Epoch 151/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 6710.7598 - mae: 6710.7598\n",
      "Epoch 152/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 411us/step - loss: 7065.0723 - mae: 7065.0723\n",
      "Epoch 153/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6996.8735 - mae: 6996.8735\n",
      "Epoch 154/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6762.2012 - mae: 6762.2012\n",
      "Epoch 155/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6811.9272 - mae: 6811.9272\n",
      "Epoch 156/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6759.7441 - mae: 6759.7441\n",
      "Epoch 157/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6966.4683 - mae: 6966.4683\n",
      "Epoch 158/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6873.9966 - mae: 6873.9966\n",
      "Epoch 159/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 7029.3110 - mae: 7029.3110\n",
      "Epoch 160/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6909.3398 - mae: 6909.3398\n",
      "Epoch 161/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6922.7964 - mae: 6922.7964\n",
      "Epoch 162/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 6804.7979 - mae: 6804.7979\n",
      "Epoch 163/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6717.7744 - mae: 6717.7744\n",
      "Epoch 164/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6778.7437 - mae: 6778.7437\n",
      "Epoch 165/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7123.5942 - mae: 7123.5942\n",
      "Epoch 166/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6437.7344 - mae: 6437.7344\n",
      "Epoch 167/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7019.7329 - mae: 7019.7329\n",
      "Epoch 168/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 6909.9570 - mae: 6909.9570\n",
      "Epoch 169/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6868.2290 - mae: 6868.2290\n",
      "Epoch 170/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6735.5083 - mae: 6735.5083\n",
      "Epoch 171/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6737.6895 - mae: 6737.6895\n",
      "Epoch 172/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6725.7217 - mae: 6725.7217\n",
      "Epoch 173/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6719.3149 - mae: 6719.3149\n",
      "Epoch 174/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6947.4941 - mae: 6947.4941\n",
      "Epoch 175/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6920.6406 - mae: 6920.6406\n",
      "Epoch 176/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6648.4194 - mae: 6648.4194\n",
      "Epoch 177/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7001.4077 - mae: 7001.4077\n",
      "Epoch 178/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6662.0923 - mae: 6662.0923\n",
      "Epoch 179/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7034.8423 - mae: 7034.8423\n",
      "Epoch 180/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6550.3247 - mae: 6550.3247\n",
      "Epoch 181/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6993.5688 - mae: 6993.5688\n",
      "Epoch 182/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6925.1846 - mae: 6925.1846\n",
      "Epoch 183/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6504.9521 - mae: 6504.9521\n",
      "Epoch 184/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6982.2646 - mae: 6982.2646\n",
      "Epoch 185/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 6941.8623 - mae: 6941.8623\n",
      "Epoch 186/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6748.3096 - mae: 6748.3096\n",
      "Epoch 187/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6998.6299 - mae: 6998.6299\n",
      "Epoch 188/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6782.8828 - mae: 6782.8828\n",
      "Epoch 189/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6700.5142 - mae: 6700.5142\n",
      "Epoch 190/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6645.3916 - mae: 6645.3916\n",
      "Epoch 191/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6800.8047 - mae: 6800.8047\n",
      "Epoch 192/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6747.8745 - mae: 6747.8745\n",
      "Epoch 193/500\n",
      "34/34 [==============================] - 0s 351us/step - loss: 6809.1401 - mae: 6809.1401\n",
      "Epoch 194/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6579.3779 - mae: 6579.3779\n",
      "Epoch 195/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6779.5596 - mae: 6779.5596\n",
      "Epoch 196/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6747.5449 - mae: 6747.5449\n",
      "Epoch 197/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6474.7573 - mae: 6474.7573\n",
      "Epoch 198/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6666.3618 - mae: 6666.3618\n",
      "Epoch 199/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6700.7778 - mae: 6700.7778\n",
      "Epoch 200/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6874.6538 - mae: 6874.6538\n",
      "Epoch 201/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6752.1675 - mae: 6752.1675\n",
      "Epoch 202/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6758.9312 - mae: 6758.9312\n",
      "Epoch 203/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6659.4351 - mae: 6659.4351\n",
      "Epoch 204/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7027.1870 - mae: 7027.1870\n",
      "Epoch 205/500\n",
      "34/34 [==============================] - 0s 543us/step - loss: 6702.0220 - mae: 6702.0220\n",
      "Epoch 206/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6869.6133 - mae: 6869.6133\n",
      "Epoch 207/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6567.0991 - mae: 6567.0991\n",
      "Epoch 208/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6783.1099 - mae: 6783.1099\n",
      "Epoch 209/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6591.0269 - mae: 6591.0269\n",
      "Epoch 210/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6719.3833 - mae: 6719.3833\n",
      "Epoch 211/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6738.3047 - mae: 6738.3047\n",
      "Epoch 212/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6731.2021 - mae: 6731.2021\n",
      "Epoch 213/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6662.1582 - mae: 6662.1582\n",
      "Epoch 214/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6285.6963 - mae: 6285.6963\n",
      "Epoch 215/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6694.2017 - mae: 6694.2017\n",
      "Epoch 216/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 6594.3423 - mae: 6594.3423\n",
      "Epoch 217/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6703.1870 - mae: 6703.1870\n",
      "Epoch 218/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6601.9102 - mae: 6601.9102\n",
      "Epoch 219/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6719.1914 - mae: 6719.1914\n",
      "Epoch 220/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6575.1392 - mae: 6575.1392\n",
      "Epoch 221/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6776.8262 - mae: 6776.8262\n",
      "Epoch 222/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6708.6338 - mae: 6708.6338\n",
      "Epoch 223/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6494.7471 - mae: 6494.7471\n",
      "Epoch 224/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6811.8062 - mae: 6811.8062\n",
      "Epoch 225/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6431.3384 - mae: 6431.3384\n",
      "Epoch 226/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6455.5083 - mae: 6455.5083\n",
      "Epoch 227/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6895.2793 - mae: 6895.2793\n",
      "Epoch 228/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6580.1807 - mae: 6580.1807\n",
      "Epoch 229/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6653.5181 - mae: 6653.5181\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 352us/step - loss: 6763.9277 - mae: 6763.9277\n",
      "Epoch 231/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6838.2861 - mae: 6838.2861\n",
      "Epoch 232/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6658.1733 - mae: 6658.1733\n",
      "Epoch 233/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6639.9233 - mae: 6639.9233\n",
      "Epoch 234/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6805.9082 - mae: 6805.9082\n",
      "Epoch 235/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6766.0474 - mae: 6766.0474\n",
      "Epoch 236/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6411.3721 - mae: 6411.3721\n",
      "Epoch 237/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 6503.1680 - mae: 6503.1680\n",
      "Epoch 238/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6219.5352 - mae: 6219.5352\n",
      "Epoch 239/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6477.5542 - mae: 6477.5542\n",
      "Epoch 240/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 6567.7104 - mae: 6567.7104\n",
      "Epoch 241/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6787.9648 - mae: 6787.9648\n",
      "Epoch 242/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6819.2822 - mae: 6819.2822\n",
      "Epoch 243/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6654.1685 - mae: 6654.1685\n",
      "Epoch 244/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 6605.6353 - mae: 6605.6353\n",
      "Epoch 245/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6497.7485 - mae: 6497.7485\n",
      "Epoch 246/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6940.5757 - mae: 6940.5757\n",
      "Epoch 247/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6466.5620 - mae: 6466.5620\n",
      "Epoch 248/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6841.7480 - mae: 6841.7480\n",
      "Epoch 249/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6329.3066 - mae: 6329.3066\n",
      "Epoch 250/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6514.2964 - mae: 6514.2964\n",
      "Epoch 251/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6406.9722 - mae: 6406.9722\n",
      "Epoch 252/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6458.9302 - mae: 6458.9302\n",
      "Epoch 253/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6488.5938 - mae: 6488.5938\n",
      "Epoch 254/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6826.9209 - mae: 6826.9209\n",
      "Epoch 255/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6614.5083 - mae: 6614.5083\n",
      "Epoch 256/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6525.4839 - mae: 6525.4839\n",
      "Epoch 257/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 6747.9922 - mae: 6747.9922\n",
      "Epoch 258/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6688.0991 - mae: 6688.0991\n",
      "Epoch 259/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6800.5288 - mae: 6800.5288\n",
      "Epoch 260/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6733.2773 - mae: 6733.2773\n",
      "Epoch 261/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6630.5889 - mae: 6630.5889\n",
      "Epoch 262/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6397.7002 - mae: 6397.7002\n",
      "Epoch 263/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6506.0864 - mae: 6506.0864\n",
      "Epoch 264/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6758.8135 - mae: 6758.8135\n",
      "Epoch 265/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6292.7017 - mae: 6292.7017\n",
      "Epoch 266/500\n",
      "34/34 [==============================] - 0s 393us/step - loss: 6851.8403 - mae: 6851.8403\n",
      "Epoch 267/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6421.6025 - mae: 6421.6025\n",
      "Epoch 268/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6867.4438 - mae: 6867.4438\n",
      "Epoch 269/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 6520.3306 - mae: 6520.3306\n",
      "Epoch 270/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6347.8945 - mae: 6347.8945\n",
      "Epoch 271/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6406.4399 - mae: 6406.4399\n",
      "Epoch 272/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6787.6196 - mae: 6787.6196\n",
      "Epoch 273/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6672.4702 - mae: 6672.4702\n",
      "Epoch 274/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6876.6885 - mae: 6876.6885\n",
      "Epoch 275/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6364.6504 - mae: 6364.6504\n",
      "Epoch 276/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6626.8589 - mae: 6626.8589\n",
      "Epoch 277/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6475.5947 - mae: 6475.5947\n",
      "Epoch 278/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6479.3135 - mae: 6479.3135\n",
      "Epoch 279/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6211.9575 - mae: 6211.9575\n",
      "Epoch 280/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6361.7544 - mae: 6361.7544\n",
      "Epoch 281/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6727.2954 - mae: 6727.2954\n",
      "Epoch 282/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6354.3965 - mae: 6354.3965\n",
      "Epoch 283/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6487.9810 - mae: 6487.9810\n",
      "Epoch 284/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6604.9824 - mae: 6604.9824\n",
      "Epoch 285/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6685.5679 - mae: 6685.5679\n",
      "Epoch 286/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6623.6582 - mae: 6623.6582\n",
      "Epoch 287/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6202.1592 - mae: 6202.1592\n",
      "Epoch 288/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6637.8418 - mae: 6637.8418\n",
      "Epoch 289/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6625.3081 - mae: 6625.3081\n",
      "Epoch 290/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6677.8179 - mae: 6677.8179\n",
      "Epoch 291/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6303.9194 - mae: 6303.9194\n",
      "Epoch 292/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6692.5747 - mae: 6692.5747\n",
      "Epoch 293/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6366.4839 - mae: 6366.4839\n",
      "Epoch 294/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6424.7759 - mae: 6424.7759\n",
      "Epoch 295/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6755.5767 - mae: 6755.5767\n",
      "Epoch 296/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6592.9185 - mae: 6592.9185\n",
      "Epoch 297/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6704.1636 - mae: 6704.1636\n",
      "Epoch 298/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6316.3418 - mae: 6316.3418\n",
      "Epoch 299/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6411.0737 - mae: 6411.0737\n",
      "Epoch 300/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6303.2021 - mae: 6303.2021\n",
      "Epoch 301/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6579.0361 - mae: 6579.0361\n",
      "Epoch 302/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6482.5713 - mae: 6482.5713\n",
      "Epoch 303/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6663.7480 - mae: 6663.7480\n",
      "Epoch 304/500\n",
      "34/34 [==============================] - 0s 462us/step - loss: 6271.8140 - mae: 6271.8140\n",
      "Epoch 305/500\n",
      "34/34 [==============================] - 0s 792us/step - loss: 6570.6650 - mae: 6570.6650\n",
      "Epoch 306/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 6531.8711 - mae: 6531.8711\n",
      "Epoch 307/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6444.9082 - mae: 6444.9082\n",
      "Epoch 308/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 469us/step - loss: 7008.3857 - mae: 7008.3857\n",
      "Epoch 309/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6751.3896 - mae: 6751.3896\n",
      "Epoch 310/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6490.0977 - mae: 6490.0977\n",
      "Epoch 311/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6248.7646 - mae: 6248.7646\n",
      "Epoch 312/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 6497.4062 - mae: 6497.4062\n",
      "Epoch 313/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 6620.0562 - mae: 6620.0562\n",
      "Epoch 314/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6452.9077 - mae: 6452.9077\n",
      "Epoch 315/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6736.6587 - mae: 6736.6587\n",
      "Epoch 316/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6662.1001 - mae: 6662.1001\n",
      "Epoch 317/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6462.2168 - mae: 6462.2168\n",
      "Epoch 318/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6623.0640 - mae: 6623.0640\n",
      "Epoch 319/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6227.5630 - mae: 6227.5630\n",
      "Epoch 320/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6591.1338 - mae: 6591.1338\n",
      "Epoch 321/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6161.2524 - mae: 6161.2524\n",
      "Epoch 322/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 6253.8940 - mae: 6253.8940\n",
      "Epoch 323/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6507.5342 - mae: 6507.5342\n",
      "Epoch 324/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 6608.2896 - mae: 6608.2896\n",
      "Epoch 325/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6413.4741 - mae: 6413.4741\n",
      "Epoch 326/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6467.5098 - mae: 6467.5098\n",
      "Epoch 327/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6211.2598 - mae: 6211.2598\n",
      "Epoch 328/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6242.3760 - mae: 6242.3760\n",
      "Epoch 329/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6448.4106 - mae: 6448.4106\n",
      "Epoch 330/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 6393.3521 - mae: 6393.3521\n",
      "Epoch 331/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 6609.1421 - mae: 6609.1421\n",
      "Epoch 332/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6472.0947 - mae: 6472.0947\n",
      "Epoch 333/500\n",
      "34/34 [==============================] - 0s 536us/step - loss: 6610.0293 - mae: 6610.0293\n",
      "Epoch 334/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6158.6177 - mae: 6158.6177\n",
      "Epoch 335/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 6631.2407 - mae: 6631.2407\n",
      "Epoch 336/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 6472.2314 - mae: 6472.2314\n",
      "Epoch 337/500\n",
      "34/34 [==============================] - 0s 648us/step - loss: 6696.6963 - mae: 6696.6963\n",
      "Epoch 338/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 6589.4692 - mae: 6589.4692\n",
      "Epoch 339/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 6569.1460 - mae: 6569.1460\n",
      "Epoch 340/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 6428.8276 - mae: 6428.8276\n",
      "Epoch 341/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6443.7715 - mae: 6443.7715\n",
      "Epoch 342/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6398.1475 - mae: 6398.1475\n",
      "Epoch 343/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 6849.2007 - mae: 6849.2007\n",
      "Epoch 344/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 6444.1255 - mae: 6444.1255\n",
      "Epoch 345/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 6405.4268 - mae: 6405.4268\n",
      "Epoch 346/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 6390.4585 - mae: 6390.4585\n",
      "Epoch 347/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 6450.1694 - mae: 6450.1694\n",
      "Epoch 348/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 6740.5894 - mae: 6740.5894\n",
      "Epoch 349/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 6082.3184 - mae: 6082.3184\n",
      "Epoch 350/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 6273.1450 - mae: 6273.1450\n",
      "Epoch 351/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 6209.1558 - mae: 6209.1558\n",
      "Epoch 352/500\n",
      "34/34 [==============================] - 0s 601us/step - loss: 6359.0522 - mae: 6359.0522\n",
      "Epoch 353/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6641.5913 - mae: 6641.5913\n",
      "Epoch 354/500\n",
      "34/34 [==============================] - 0s 821us/step - loss: 6113.6104 - mae: 6113.6104\n",
      "Epoch 355/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6480.2539 - mae: 6480.2539\n",
      "Epoch 356/500\n",
      "34/34 [==============================] - 0s 811us/step - loss: 6441.9746 - mae: 6441.9746\n",
      "Epoch 357/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6319.7891 - mae: 6319.7891\n",
      "Epoch 358/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6095.3516 - mae: 6095.3516\n",
      "Epoch 359/500\n",
      "34/34 [==============================] - 0s 821us/step - loss: 5912.5708 - mae: 5912.5708\n",
      "Epoch 360/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6600.4536 - mae: 6600.4536\n",
      "Epoch 361/500\n",
      "34/34 [==============================] - 0s 880us/step - loss: 6316.4116 - mae: 6316.4116\n",
      "Epoch 362/500\n",
      "34/34 [==============================] - 0s 826us/step - loss: 6459.3027 - mae: 6459.3027\n",
      "Epoch 363/500\n",
      "34/34 [==============================] - 0s 708us/step - loss: 6290.0190 - mae: 6290.0190\n",
      "Epoch 364/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6449.4058 - mae: 6449.4058\n",
      "Epoch 365/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6806.1206 - mae: 6806.1206\n",
      "Epoch 366/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6557.1230 - mae: 6557.1230\n",
      "Epoch 367/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6535.0830 - mae: 6535.0830\n",
      "Epoch 368/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6511.2812 - mae: 6511.2812\n",
      "Epoch 369/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6519.1904 - mae: 6519.1904\n",
      "Epoch 370/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6754.1333 - mae: 6754.1333\n",
      "Epoch 371/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6113.0083 - mae: 6113.0083\n",
      "Epoch 372/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6524.5723 - mae: 6524.5723\n",
      "Epoch 373/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6123.3643 - mae: 6123.3643\n",
      "Epoch 374/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 6270.3872 - mae: 6270.3872\n",
      "Epoch 375/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 6136.9829 - mae: 6136.9829\n",
      "Epoch 376/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 6340.2808 - mae: 6340.2808\n",
      "Epoch 377/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6404.8345 - mae: 6404.8345\n",
      "Epoch 378/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 6740.3652 - mae: 6740.3652\n",
      "Epoch 379/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6339.0381 - mae: 6339.0381\n",
      "Epoch 380/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6309.0654 - mae: 6309.0654\n",
      "Epoch 381/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6222.4883 - mae: 6222.4883\n",
      "Epoch 382/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 6335.4546 - mae: 6335.4546\n",
      "Epoch 383/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6452.4585 - mae: 6452.4585\n",
      "Epoch 384/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6157.2402 - mae: 6157.2402\n",
      "Epoch 385/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6039.2881 - mae: 6039.2881\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 557us/step - loss: 6328.8525 - mae: 6328.8525\n",
      "Epoch 387/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6630.7485 - mae: 6630.7485\n",
      "Epoch 388/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6232.1655 - mae: 6232.1655\n",
      "Epoch 389/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 6208.5591 - mae: 6208.5591\n",
      "Epoch 390/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 6280.7544 - mae: 6280.7544\n",
      "Epoch 391/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6513.6538 - mae: 6513.6538\n",
      "Epoch 392/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 6273.1108 - mae: 6273.1108\n",
      "Epoch 393/500\n",
      "34/34 [==============================] - 0s 792us/step - loss: 6257.8560 - mae: 6257.8560\n",
      "Epoch 394/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6414.5308 - mae: 6414.5308\n",
      "Epoch 395/500\n",
      "34/34 [==============================] - 0s 792us/step - loss: 6389.2607 - mae: 6389.2607\n",
      "Epoch 396/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6599.5732 - mae: 6599.5732\n",
      "Epoch 397/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6460.3105 - mae: 6460.3105\n",
      "Epoch 398/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6501.0322 - mae: 6501.0322\n",
      "Epoch 399/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6625.2930 - mae: 6625.2930\n",
      "Epoch 400/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6419.0942 - mae: 6419.0942\n",
      "Epoch 401/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6264.9351 - mae: 6264.9351\n",
      "Epoch 402/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6282.0581 - mae: 6282.0581\n",
      "Epoch 403/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6148.3423 - mae: 6148.3423\n",
      "Epoch 404/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 6026.1401 - mae: 6026.1401\n",
      "Epoch 405/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6573.5117 - mae: 6573.5117\n",
      "Epoch 406/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6123.6724 - mae: 6123.6724\n",
      "Epoch 407/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 5939.3950 - mae: 5939.3950\n",
      "Epoch 408/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6157.9946 - mae: 6157.9946\n",
      "Epoch 409/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6636.3037 - mae: 6636.3037\n",
      "Epoch 410/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6341.5234 - mae: 6341.5234\n",
      "Epoch 411/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 6487.1074 - mae: 6487.1074\n",
      "Epoch 412/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6258.6143 - mae: 6258.6143\n",
      "Epoch 413/500\n",
      "34/34 [==============================] - 0s 821us/step - loss: 6550.5142 - mae: 6550.5142\n",
      "Epoch 414/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6253.5024 - mae: 6253.5024\n",
      "Epoch 415/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 5965.4775 - mae: 5965.4775\n",
      "Epoch 416/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 6358.4775 - mae: 6358.4775\n",
      "Epoch 417/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6133.1143 - mae: 6133.1143\n",
      "Epoch 418/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6011.7109 - mae: 6011.7109\n",
      "Epoch 419/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 6147.9600 - mae: 6147.9600\n",
      "Epoch 420/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6320.8809 - mae: 6320.8809\n",
      "Epoch 421/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6367.8081 - mae: 6367.8081\n",
      "Epoch 422/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 6357.0557 - mae: 6357.0557\n",
      "Epoch 423/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6151.6992 - mae: 6151.6992\n",
      "Epoch 424/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6117.3638 - mae: 6117.3638\n",
      "Epoch 425/500\n",
      "34/34 [==============================] - 0s 851us/step - loss: 6137.3906 - mae: 6137.3906\n",
      "Epoch 426/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 5986.3691 - mae: 5986.3691\n",
      "Epoch 427/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 5775.6494 - mae: 5775.6494\n",
      "Epoch 428/500\n",
      "34/34 [==============================] - 0s 636us/step - loss: 6255.4038 - mae: 6255.4038\n",
      "Epoch 429/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 6377.2793 - mae: 6377.2793\n",
      "Epoch 430/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6255.2422 - mae: 6255.2422\n",
      "Epoch 431/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6462.2275 - mae: 6462.2275\n",
      "Epoch 432/500\n",
      "34/34 [==============================] - 0s 666us/step - loss: 6100.3564 - mae: 6100.3564\n",
      "Epoch 433/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6022.8032 - mae: 6022.8032\n",
      "Epoch 434/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6262.1748 - mae: 6262.1748\n",
      "Epoch 435/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 6315.6787 - mae: 6315.6787\n",
      "Epoch 436/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6307.5747 - mae: 6307.5747\n",
      "Epoch 437/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6334.2441 - mae: 6334.2441\n",
      "Epoch 438/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6235.4189 - mae: 6235.4189\n",
      "Epoch 439/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6475.6694 - mae: 6475.6694\n",
      "Epoch 440/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6104.9351 - mae: 6104.9351\n",
      "Epoch 441/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6203.5571 - mae: 6203.5571\n",
      "Epoch 442/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6171.5010 - mae: 6171.5010\n",
      "Epoch 443/500\n",
      "34/34 [==============================] - 0s 851us/step - loss: 6359.0737 - mae: 6359.0737\n",
      "Epoch 444/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6191.7588 - mae: 6191.7588\n",
      "Epoch 445/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6368.1304 - mae: 6368.1304\n",
      "Epoch 446/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6262.1084 - mae: 6262.1084\n",
      "Epoch 447/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6313.8032 - mae: 6313.8032\n",
      "Epoch 448/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6476.8569 - mae: 6476.8569\n",
      "Epoch 449/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6306.0845 - mae: 6306.0845\n",
      "Epoch 450/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6463.3110 - mae: 6463.3110\n",
      "Epoch 451/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6274.3462 - mae: 6274.3462\n",
      "Epoch 452/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6089.0264 - mae: 6089.0264\n",
      "Epoch 453/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6131.0825 - mae: 6131.0825\n",
      "Epoch 454/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 5934.6157 - mae: 5934.6157\n",
      "Epoch 455/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6047.6226 - mae: 6047.6226\n",
      "Epoch 456/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6135.4351 - mae: 6135.4351\n",
      "Epoch 457/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 5698.6909 - mae: 5698.6909\n",
      "Epoch 458/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6244.7930 - mae: 6244.7930\n",
      "Epoch 459/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6433.8647 - mae: 6433.8647\n",
      "Epoch 460/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6422.7446 - mae: 6422.7446\n",
      "Epoch 461/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 6510.2358 - mae: 6510.2358\n",
      "Epoch 462/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6069.6543 - mae: 6069.6543\n",
      "Epoch 463/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6206.2705 - mae: 6206.2705\n",
      "Epoch 464/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 851us/step - loss: 5985.2573 - mae: 5985.2573\n",
      "Epoch 465/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6072.7925 - mae: 6072.7925\n",
      "Epoch 466/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6184.0640 - mae: 6184.0640\n",
      "Epoch 467/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6129.6206 - mae: 6129.6206\n",
      "Epoch 468/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 5606.8062 - mae: 5606.8062\n",
      "Epoch 469/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6513.7119 - mae: 6513.7119\n",
      "Epoch 470/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 5961.6294 - mae: 5961.6294\n",
      "Epoch 471/500\n",
      "34/34 [==============================] - 0s 939us/step - loss: 6277.8203 - mae: 6277.8203\n",
      "Epoch 472/500\n",
      "34/34 [==============================] - 0s 909us/step - loss: 6326.5923 - mae: 6326.5923\n",
      "Epoch 473/500\n",
      "34/34 [==============================] - 0s 792us/step - loss: 6053.4272 - mae: 6053.4272\n",
      "Epoch 474/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 5713.2222 - mae: 5713.2222\n",
      "Epoch 475/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6209.6279 - mae: 6209.6279\n",
      "Epoch 476/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6243.2944 - mae: 6243.2944\n",
      "Epoch 477/500\n",
      "34/34 [==============================] - 0s 792us/step - loss: 6293.8569 - mae: 6293.8569\n",
      "Epoch 478/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6030.0273 - mae: 6030.0273\n",
      "Epoch 479/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 5999.5742 - mae: 5999.5742\n",
      "Epoch 480/500\n",
      "34/34 [==============================] - 0s 792us/step - loss: 6180.7612 - mae: 6180.7612\n",
      "Epoch 481/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6352.9121 - mae: 6352.9121\n",
      "Epoch 482/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6263.3086 - mae: 6263.3086\n",
      "Epoch 483/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6248.8081 - mae: 6248.8081\n",
      "Epoch 484/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6260.3838 - mae: 6260.3838\n",
      "Epoch 485/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 5894.3823 - mae: 5894.3823\n",
      "Epoch 486/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 5959.8818 - mae: 5959.8818\n",
      "Epoch 487/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6121.3159 - mae: 6121.3159\n",
      "Epoch 488/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6137.0649 - mae: 6137.0649\n",
      "Epoch 489/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 5954.2622 - mae: 5954.2622\n",
      "Epoch 490/500\n",
      "34/34 [==============================] - 0s 792us/step - loss: 6410.1475 - mae: 6410.1475\n",
      "Epoch 491/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6247.7866 - mae: 6247.7866\n",
      "Epoch 492/500\n",
      "34/34 [==============================] - 0s 792us/step - loss: 6301.4473 - mae: 6301.4473\n",
      "Epoch 493/500\n",
      "34/34 [==============================] - 0s 997us/step - loss: 6434.4434 - mae: 6434.4434\n",
      "Epoch 494/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6076.3125 - mae: 6076.3125\n",
      "Epoch 495/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6384.7354 - mae: 6384.7354\n",
      "Epoch 496/500\n",
      "34/34 [==============================] - 0s 939us/step - loss: 6222.9316 - mae: 6222.9316\n",
      "Epoch 497/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6205.8667 - mae: 6205.8667\n",
      "Epoch 498/500\n",
      "34/34 [==============================] - 0s 851us/step - loss: 5991.0000 - mae: 5991.0000\n",
      "Epoch 499/500\n",
      "34/34 [==============================] - 0s 821us/step - loss: 5948.9526 - mae: 5948.9526\n",
      "Epoch 500/500\n",
      "34/34 [==============================] - 0s 880us/step - loss: 6139.6035 - mae: 6139.6035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x249d50ff760>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the model\n",
    "insurance_model1 = tf.keras.Sequential([tf.keras.layers.Dense(10),\n",
    "                                       tf.keras.layers.Dense(1)])\n",
    "# compiling the model\n",
    "insurance_model1.compile(optimizer=tf.keras.optimizers.SGD(), loss = tf.keras.losses.mae, metrics=[\"mae\"])\n",
    "\n",
    "# fitting the model1\n",
    "insurance_model1.fit(X_train,y_train,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "119dd802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_139 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(43)\n",
    "\n",
    "insurance_model2 = tf.keras.Sequential([tf.keras.layers.Dense(100),\n",
    "                                        tf.keras.layers.Dense(10),\n",
    "                                        tf.keras.layers.Dense(1)])\n",
    "\n",
    "insurance_model2.compile(optimizer=tf.keras.optimizers.Adam(),loss=\"mae\", metrics=[\"mae\"])\n",
    "\n",
    "history = insurance_model2.fit(X_train,y_train,epochs=125, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "ea726916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 443us/step - loss: 4073.2439 - mae: 4073.2439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4073.243896484375, 4073.243896484375]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "6cd3f063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:Layer dense_134 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "34/34 [==============================] - 0s 557us/step - loss: 13219.2139 - mae: 13219.2139\n",
      "Epoch 2/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 13207.2129 - mae: 13207.2129\n",
      "Epoch 3/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 13194.9219 - mae: 13194.9219\n",
      "Epoch 4/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 13181.5293 - mae: 13181.5293\n",
      "Epoch 5/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 13166.2920 - mae: 13166.2920\n",
      "Epoch 6/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 13148.6621 - mae: 13148.6621\n",
      "Epoch 7/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 13128.1797 - mae: 13128.1797\n",
      "Epoch 8/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 13104.5332 - mae: 13104.5332\n",
      "Epoch 9/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 13077.4443 - mae: 13077.4443\n",
      "Epoch 10/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 13046.5967 - mae: 13046.5967\n",
      "Epoch 11/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 13011.6904 - mae: 13011.6904\n",
      "Epoch 12/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 12972.5010 - mae: 12972.5010\n",
      "Epoch 13/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 12928.9463 - mae: 12928.9463\n",
      "Epoch 14/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 12880.8184 - mae: 12880.8184\n",
      "Epoch 15/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 12828.2080 - mae: 12828.2080\n",
      "Epoch 16/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 12771.1826 - mae: 12771.1826\n",
      "Epoch 17/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 12709.5703 - mae: 12709.5703\n",
      "Epoch 18/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 12643.4053 - mae: 12643.4053\n",
      "Epoch 19/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 12572.5879 - mae: 12572.5879\n",
      "Epoch 20/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 12497.1650 - mae: 12497.1650\n",
      "Epoch 21/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 12416.9678 - mae: 12416.9678\n",
      "Epoch 22/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 12331.8154 - mae: 12331.8154\n",
      "Epoch 23/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 12242.2852 - mae: 12242.2852\n",
      "Epoch 24/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 12147.9756 - mae: 12147.9756\n",
      "Epoch 25/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 12049.1631 - mae: 12049.1631\n",
      "Epoch 26/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 11945.9316 - mae: 11945.9316\n",
      "Epoch 27/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 11838.7744 - mae: 11838.7744\n",
      "Epoch 28/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 11728.1719 - mae: 11728.1719\n",
      "Epoch 29/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 11613.9551 - mae: 11613.9551\n",
      "Epoch 30/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 11496.9863 - mae: 11496.9863\n",
      "Epoch 31/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 11377.3848 - mae: 11377.3848\n",
      "Epoch 32/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 11255.3730 - mae: 11255.3730\n",
      "Epoch 33/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 11131.7227 - mae: 11131.7227\n",
      "Epoch 34/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 11006.5615 - mae: 11006.5615\n",
      "Epoch 35/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 10879.4238 - mae: 10879.4238\n",
      "Epoch 36/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 10753.3252 - mae: 10753.3252\n",
      "Epoch 37/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 10627.5547 - mae: 10627.5547\n",
      "Epoch 38/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 10503.5791 - mae: 10503.5791\n",
      "Epoch 39/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 10380.7363 - mae: 10380.7363\n",
      "Epoch 40/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 10261.0078 - mae: 10261.0078\n",
      "Epoch 41/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 10142.7891 - mae: 10142.7891\n",
      "Epoch 42/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 10022.9824 - mae: 10022.9824\n",
      "Epoch 43/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 9903.5566 - mae: 9903.5566\n",
      "Epoch 44/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 9784.7891 - mae: 9784.7891\n",
      "Epoch 45/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 9668.5566 - mae: 9668.5566\n",
      "Epoch 46/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 9552.8008 - mae: 9552.8008\n",
      "Epoch 47/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 9435.9746 - mae: 9435.9746\n",
      "Epoch 48/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 9321.5840 - mae: 9321.5840\n",
      "Epoch 49/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 9210.0322 - mae: 9210.0322\n",
      "Epoch 50/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 9099.0723 - mae: 9099.0723\n",
      "Epoch 51/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 8990.7764 - mae: 8990.7764\n",
      "Epoch 52/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 8889.1914 - mae: 8889.1914\n",
      "Epoch 53/500\n",
      "34/34 [==============================] - 0s 490us/step - loss: 8789.9316 - mae: 8789.9316\n",
      "Epoch 54/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 8693.9717 - mae: 8693.9717\n",
      "Epoch 55/500\n",
      "34/34 [==============================] - 0s 481us/step - loss: 8603.0713 - mae: 8603.0713\n",
      "Epoch 56/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 8514.6084 - mae: 8514.6084\n",
      "Epoch 57/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 8431.7852 - mae: 8431.7852\n",
      "Epoch 58/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 8349.6963 - mae: 8349.6963\n",
      "Epoch 59/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 8273.1045 - mae: 8273.1045\n",
      "Epoch 60/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 8200.4912 - mae: 8200.4912\n",
      "Epoch 61/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 8131.5879 - mae: 8131.5879\n",
      "Epoch 62/500\n",
      "34/34 [==============================] - 0s 517us/step - loss: 8064.6646 - mae: 8064.6646\n",
      "Epoch 63/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 8003.0747 - mae: 8003.0747\n",
      "Epoch 64/500\n",
      "34/34 [==============================] - 0s 557us/step - loss: 7944.7065 - mae: 7944.7065\n",
      "Epoch 65/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 7889.2852 - mae: 7889.2852\n",
      "Epoch 66/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 7837.7471 - mae: 7837.7471\n",
      "Epoch 67/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 7791.1572 - mae: 7791.1572\n",
      "Epoch 68/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7748.3218 - mae: 7748.3218\n",
      "Epoch 69/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7709.8013 - mae: 7709.8013\n",
      "Epoch 70/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7673.5454 - mae: 7673.5454\n",
      "Epoch 71/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7640.7378 - mae: 7640.7378\n",
      "Epoch 72/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 440us/step - loss: 7609.9131 - mae: 7609.9131\n",
      "Epoch 73/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7581.9536 - mae: 7581.9536\n",
      "Epoch 74/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7557.9653 - mae: 7557.9653\n",
      "Epoch 75/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7536.4297 - mae: 7536.4297\n",
      "Epoch 76/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7517.4443 - mae: 7517.4443\n",
      "Epoch 77/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7499.3169 - mae: 7499.3169\n",
      "Epoch 78/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7483.9189 - mae: 7483.9189\n",
      "Epoch 79/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7471.2720 - mae: 7471.2720\n",
      "Epoch 80/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7459.4214 - mae: 7459.4214\n",
      "Epoch 81/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 7448.8149 - mae: 7448.8149\n",
      "Epoch 82/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7439.7524 - mae: 7439.7524\n",
      "Epoch 83/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7430.5938 - mae: 7430.5938\n",
      "Epoch 84/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7422.4902 - mae: 7422.4902\n",
      "Epoch 85/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7415.7344 - mae: 7415.7344\n",
      "Epoch 86/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7409.2812 - mae: 7409.2812\n",
      "Epoch 87/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7403.6899 - mae: 7403.6899\n",
      "Epoch 88/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7398.2446 - mae: 7398.2446\n",
      "Epoch 89/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7393.2593 - mae: 7393.2593\n",
      "Epoch 90/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7388.8477 - mae: 7388.8477\n",
      "Epoch 91/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7383.6772 - mae: 7383.6772\n",
      "Epoch 92/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7379.0830 - mae: 7379.0830\n",
      "Epoch 93/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7374.7192 - mae: 7374.7192\n",
      "Epoch 94/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7370.8887 - mae: 7370.8887\n",
      "Epoch 95/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7366.5776 - mae: 7366.5776\n",
      "Epoch 96/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7363.0894 - mae: 7363.0894\n",
      "Epoch 97/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7359.5449 - mae: 7359.5449\n",
      "Epoch 98/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7355.9033 - mae: 7355.9033\n",
      "Epoch 99/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7352.7207 - mae: 7352.7207\n",
      "Epoch 100/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7349.6934 - mae: 7349.6934\n",
      "Epoch 101/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7346.6143 - mae: 7346.6143\n",
      "Epoch 102/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7343.5146 - mae: 7343.5146\n",
      "Epoch 103/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7340.5166 - mae: 7340.5166\n",
      "Epoch 104/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7337.6812 - mae: 7337.6812\n",
      "Epoch 105/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7334.6084 - mae: 7334.6084\n",
      "Epoch 106/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7331.8696 - mae: 7331.8696\n",
      "Epoch 107/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7328.7314 - mae: 7328.7314\n",
      "Epoch 108/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7325.8633 - mae: 7325.8633\n",
      "Epoch 109/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7323.0205 - mae: 7323.0205\n",
      "Epoch 110/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7319.8652 - mae: 7319.8652\n",
      "Epoch 111/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7316.9351 - mae: 7316.9351\n",
      "Epoch 112/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7313.8169 - mae: 7313.8169\n",
      "Epoch 113/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7310.8535 - mae: 7310.8535\n",
      "Epoch 114/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7307.7393 - mae: 7307.7393\n",
      "Epoch 115/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7304.7085 - mae: 7304.7085\n",
      "Epoch 116/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7301.9600 - mae: 7301.9600\n",
      "Epoch 117/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 7298.8311 - mae: 7298.8311\n",
      "Epoch 118/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7295.5166 - mae: 7295.5166\n",
      "Epoch 119/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7292.3833 - mae: 7292.3833\n",
      "Epoch 120/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7289.2700 - mae: 7289.2700\n",
      "Epoch 121/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7286.2188 - mae: 7286.2188\n",
      "Epoch 122/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7282.9312 - mae: 7282.9312\n",
      "Epoch 123/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7279.7896 - mae: 7279.7896\n",
      "Epoch 124/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7276.6187 - mae: 7276.6187\n",
      "Epoch 125/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7273.3643 - mae: 7273.3643\n",
      "Epoch 126/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7270.2573 - mae: 7270.2573\n",
      "Epoch 127/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7267.0244 - mae: 7267.0244\n",
      "Epoch 128/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7263.7529 - mae: 7263.7529\n",
      "Epoch 129/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7260.3604 - mae: 7260.3604\n",
      "Epoch 130/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7257.1577 - mae: 7257.1577\n",
      "Epoch 131/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7254.0903 - mae: 7254.0903\n",
      "Epoch 132/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7250.4702 - mae: 7250.4702\n",
      "Epoch 133/500\n",
      "34/34 [==============================] - 0s 503us/step - loss: 7247.2310 - mae: 7247.2310\n",
      "Epoch 134/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7244.0859 - mae: 7244.0859\n",
      "Epoch 135/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7240.6035 - mae: 7240.6035\n",
      "Epoch 136/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 7237.3105 - mae: 7237.3105\n",
      "Epoch 137/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 7233.9551 - mae: 7233.9551\n",
      "Epoch 138/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 7230.6592 - mae: 7230.6592\n",
      "Epoch 139/500\n",
      "34/34 [==============================] - 0s 680us/step - loss: 7227.2617 - mae: 7227.2617\n",
      "Epoch 140/500\n",
      "34/34 [==============================] - 0s 622us/step - loss: 7223.9326 - mae: 7223.9326\n",
      "Epoch 141/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7220.6450 - mae: 7220.6450\n",
      "Epoch 142/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7217.1909 - mae: 7217.1909\n",
      "Epoch 143/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7213.7827 - mae: 7213.7827\n",
      "Epoch 144/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7210.3242 - mae: 7210.3242\n",
      "Epoch 145/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7207.0835 - mae: 7207.0835\n",
      "Epoch 146/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 7203.5820 - mae: 7203.5820\n",
      "Epoch 147/500\n",
      "34/34 [==============================] - 0s 646us/step - loss: 7200.0171 - mae: 7200.0171\n",
      "Epoch 148/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 7196.6567 - mae: 7196.6567\n",
      "Epoch 149/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7193.3042 - mae: 7193.3042\n",
      "Epoch 150/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 7189.7051 - mae: 7189.7051\n",
      "Epoch 151/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 616us/step - loss: 7186.3330 - mae: 7186.3330\n",
      "Epoch 152/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 7182.8599 - mae: 7182.8599\n",
      "Epoch 153/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 7179.4419 - mae: 7179.4419\n",
      "Epoch 154/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7175.9463 - mae: 7175.9463\n",
      "Epoch 155/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 7172.6748 - mae: 7172.6748\n",
      "Epoch 156/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7168.9624 - mae: 7168.9624\n",
      "Epoch 157/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 7165.4019 - mae: 7165.4019\n",
      "Epoch 158/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7161.7788 - mae: 7161.7788\n",
      "Epoch 159/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7158.2739 - mae: 7158.2739\n",
      "Epoch 160/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7154.8154 - mae: 7154.8154\n",
      "Epoch 161/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 7151.1196 - mae: 7151.1196\n",
      "Epoch 162/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7147.5376 - mae: 7147.5376\n",
      "Epoch 163/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7144.1372 - mae: 7144.1372\n",
      "Epoch 164/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7140.4678 - mae: 7140.4678\n",
      "Epoch 165/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7136.8027 - mae: 7136.8027\n",
      "Epoch 166/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 7133.2974 - mae: 7133.2974\n",
      "Epoch 167/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7129.5781 - mae: 7129.5781\n",
      "Epoch 168/500\n",
      "34/34 [==============================] - 0s 821us/step - loss: 7125.9849 - mae: 7125.9849\n",
      "Epoch 169/500\n",
      "34/34 [==============================] - 0s 739us/step - loss: 7122.3633 - mae: 7122.3633\n",
      "Epoch 170/500\n",
      "34/34 [==============================] - 0s 649us/step - loss: 7118.8940 - mae: 7118.8940\n",
      "Epoch 171/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 7115.1055 - mae: 7115.1055\n",
      "Epoch 172/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7111.3691 - mae: 7111.3691\n",
      "Epoch 173/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7107.6772 - mae: 7107.6772\n",
      "Epoch 174/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 7103.9961 - mae: 7103.9961\n",
      "Epoch 175/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7100.4932 - mae: 7100.4932\n",
      "Epoch 176/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 7096.6343 - mae: 7096.6343\n",
      "Epoch 177/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7092.8110 - mae: 7092.8110\n",
      "Epoch 178/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7089.0991 - mae: 7089.0991\n",
      "Epoch 179/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 7085.3750 - mae: 7085.3750\n",
      "Epoch 180/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7081.4785 - mae: 7081.4785\n",
      "Epoch 181/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7077.8223 - mae: 7077.8223\n",
      "Epoch 182/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 7073.8472 - mae: 7073.8472\n",
      "Epoch 183/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7070.0703 - mae: 7070.0703\n",
      "Epoch 184/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 7066.1494 - mae: 7066.1494\n",
      "Epoch 185/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 7062.3813 - mae: 7062.3813\n",
      "Epoch 186/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7058.5518 - mae: 7058.5518\n",
      "Epoch 187/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 7054.6060 - mae: 7054.6060\n",
      "Epoch 188/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7050.6260 - mae: 7050.6260\n",
      "Epoch 189/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 7046.8203 - mae: 7046.8203\n",
      "Epoch 190/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7042.7993 - mae: 7042.7993\n",
      "Epoch 191/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 7038.9272 - mae: 7038.9272\n",
      "Epoch 192/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 7035.0552 - mae: 7035.0552\n",
      "Epoch 193/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7030.9565 - mae: 7030.9565\n",
      "Epoch 194/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7026.9482 - mae: 7026.9482\n",
      "Epoch 195/500\n",
      "34/34 [==============================] - 0s 634us/step - loss: 7023.1211 - mae: 7023.1211\n",
      "Epoch 196/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7019.2271 - mae: 7019.2271\n",
      "Epoch 197/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7015.3115 - mae: 7015.3115\n",
      "Epoch 198/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 7011.2778 - mae: 7011.2778\n",
      "Epoch 199/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 7007.3467 - mae: 7007.3467\n",
      "Epoch 200/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 7003.6323 - mae: 7003.6323\n",
      "Epoch 201/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6999.7383 - mae: 6999.7383\n",
      "Epoch 202/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6995.5005 - mae: 6995.5005\n",
      "Epoch 203/500\n",
      "34/34 [==============================] - 0s 728us/step - loss: 6992.1235 - mae: 6992.1235\n",
      "Epoch 204/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6988.6455 - mae: 6988.6455\n",
      "Epoch 205/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6984.0601 - mae: 6984.0601\n",
      "Epoch 206/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6979.9775 - mae: 6979.9775\n",
      "Epoch 207/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6976.1768 - mae: 6976.1768\n",
      "Epoch 208/500\n",
      "34/34 [==============================] - 0s 821us/step - loss: 6972.6616 - mae: 6972.6616\n",
      "Epoch 209/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6968.6133 - mae: 6968.6133\n",
      "Epoch 210/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6964.5835 - mae: 6964.5835\n",
      "Epoch 211/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6960.9512 - mae: 6960.9512\n",
      "Epoch 212/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6957.0884 - mae: 6957.0884\n",
      "Epoch 213/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6953.3408 - mae: 6953.3408\n",
      "Epoch 214/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6949.7080 - mae: 6949.7080\n",
      "Epoch 215/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6945.6294 - mae: 6945.6294\n",
      "Epoch 216/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6941.5000 - mae: 6941.5000\n",
      "Epoch 217/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6937.4932 - mae: 6937.4932\n",
      "Epoch 218/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6933.9531 - mae: 6933.9531\n",
      "Epoch 219/500\n",
      "34/34 [==============================] - 0s 821us/step - loss: 6929.5562 - mae: 6929.5562\n",
      "Epoch 220/500\n",
      "34/34 [==============================] - 0s 677us/step - loss: 6925.6465 - mae: 6925.6465\n",
      "Epoch 221/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6922.4185 - mae: 6922.4185\n",
      "Epoch 222/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6917.9712 - mae: 6917.9712\n",
      "Epoch 223/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6913.8677 - mae: 6913.8677\n",
      "Epoch 224/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6910.0811 - mae: 6910.0811\n",
      "Epoch 225/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6905.7949 - mae: 6905.7949\n",
      "Epoch 226/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6901.5889 - mae: 6901.5889\n",
      "Epoch 227/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6897.7207 - mae: 6897.7207\n",
      "Epoch 228/500\n",
      "34/34 [==============================] - 0s 792us/step - loss: 6893.5381 - mae: 6893.5381\n",
      "Epoch 229/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 763us/step - loss: 6889.5869 - mae: 6889.5869\n",
      "Epoch 230/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6885.2866 - mae: 6885.2866\n",
      "Epoch 231/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6881.0518 - mae: 6881.0518\n",
      "Epoch 232/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6877.1255 - mae: 6877.1255\n",
      "Epoch 233/500\n",
      "34/34 [==============================] - 0s 851us/step - loss: 6873.3667 - mae: 6873.3667\n",
      "Epoch 234/500\n",
      "34/34 [==============================] - 0s 851us/step - loss: 6869.0571 - mae: 6869.0571\n",
      "Epoch 235/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6865.1216 - mae: 6865.1216\n",
      "Epoch 236/500\n",
      "34/34 [==============================] - 0s 792us/step - loss: 6860.4849 - mae: 6860.4849\n",
      "Epoch 237/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6856.5381 - mae: 6856.5381\n",
      "Epoch 238/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6852.3452 - mae: 6852.3452\n",
      "Epoch 239/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6848.1558 - mae: 6848.1558\n",
      "Epoch 240/500\n",
      "34/34 [==============================] - 0s 900us/step - loss: 6843.9180 - mae: 6843.9180\n",
      "Epoch 241/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6839.9648 - mae: 6839.9648\n",
      "Epoch 242/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6835.7544 - mae: 6835.7544\n",
      "Epoch 243/500\n",
      "34/34 [==============================] - 0s 792us/step - loss: 6831.5513 - mae: 6831.5513\n",
      "Epoch 244/500\n",
      "34/34 [==============================] - 0s 821us/step - loss: 6827.7236 - mae: 6827.7236\n",
      "Epoch 245/500\n",
      "34/34 [==============================] - 0s 851us/step - loss: 6822.9526 - mae: 6822.9526\n",
      "Epoch 246/500\n",
      "34/34 [==============================] - 0s 779us/step - loss: 6819.0947 - mae: 6819.0947\n",
      "Epoch 247/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6814.6802 - mae: 6814.6802\n",
      "Epoch 248/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6810.6143 - mae: 6810.6143\n",
      "Epoch 249/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6806.6567 - mae: 6806.6567\n",
      "Epoch 250/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6802.5488 - mae: 6802.5488\n",
      "Epoch 251/500\n",
      "34/34 [==============================] - 0s 821us/step - loss: 6798.2827 - mae: 6798.2827\n",
      "Epoch 252/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6794.4463 - mae: 6794.4463\n",
      "Epoch 253/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6790.0728 - mae: 6790.0728\n",
      "Epoch 254/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6785.8623 - mae: 6785.8623\n",
      "Epoch 255/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6781.7363 - mae: 6781.7363\n",
      "Epoch 256/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6777.7041 - mae: 6777.7041\n",
      "Epoch 257/500\n",
      "34/34 [==============================] - 0s 778us/step - loss: 6773.7280 - mae: 6773.7280\n",
      "Epoch 258/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6769.4097 - mae: 6769.4097\n",
      "Epoch 259/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6765.3335 - mae: 6765.3335\n",
      "Epoch 260/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6760.9424 - mae: 6760.9424\n",
      "Epoch 261/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6757.1206 - mae: 6757.1206\n",
      "Epoch 262/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6752.6831 - mae: 6752.6831\n",
      "Epoch 263/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6748.7969 - mae: 6748.7969\n",
      "Epoch 264/500\n",
      "34/34 [==============================] - 0s 792us/step - loss: 6744.1387 - mae: 6744.1387\n",
      "Epoch 265/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6740.4380 - mae: 6740.4380\n",
      "Epoch 266/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6735.3979 - mae: 6735.3979\n",
      "Epoch 267/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6731.2563 - mae: 6731.2563\n",
      "Epoch 268/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6727.0923 - mae: 6727.0923\n",
      "Epoch 269/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6722.9160 - mae: 6722.9160\n",
      "Epoch 270/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6718.1704 - mae: 6718.1704\n",
      "Epoch 271/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6713.8979 - mae: 6713.8979\n",
      "Epoch 272/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6709.6440 - mae: 6709.6440\n",
      "Epoch 273/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6705.1216 - mae: 6705.1216\n",
      "Epoch 274/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6700.6235 - mae: 6700.6235\n",
      "Epoch 275/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6696.4731 - mae: 6696.4731\n",
      "Epoch 276/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6692.3799 - mae: 6692.3799\n",
      "Epoch 277/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6687.8896 - mae: 6687.8896\n",
      "Epoch 278/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6683.3540 - mae: 6683.3540\n",
      "Epoch 279/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6678.9937 - mae: 6678.9937\n",
      "Epoch 280/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6674.9805 - mae: 6674.9805\n",
      "Epoch 281/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6670.2832 - mae: 6670.2832\n",
      "Epoch 282/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6665.7329 - mae: 6665.7329\n",
      "Epoch 283/500\n",
      "34/34 [==============================] - 0s 790us/step - loss: 6661.1904 - mae: 6661.1904\n",
      "Epoch 284/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6657.0488 - mae: 6657.0488\n",
      "Epoch 285/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6652.5498 - mae: 6652.5498\n",
      "Epoch 286/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6648.1528 - mae: 6648.1528\n",
      "Epoch 287/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6643.8848 - mae: 6643.8848\n",
      "Epoch 288/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6639.3384 - mae: 6639.3384\n",
      "Epoch 289/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6634.8096 - mae: 6634.8096\n",
      "Epoch 290/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6630.5210 - mae: 6630.5210\n",
      "Epoch 291/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6626.3169 - mae: 6626.3169\n",
      "Epoch 292/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6622.1011 - mae: 6622.1011\n",
      "Epoch 293/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6618.2368 - mae: 6618.2368\n",
      "Epoch 294/500\n",
      "34/34 [==============================] - 0s 720us/step - loss: 6613.7178 - mae: 6613.7178\n",
      "Epoch 295/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6609.5249 - mae: 6609.5249\n",
      "Epoch 296/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6605.4878 - mae: 6605.4878\n",
      "Epoch 297/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6601.4722 - mae: 6601.4722\n",
      "Epoch 298/500\n",
      "34/34 [==============================] - 0s 673us/step - loss: 6597.1265 - mae: 6597.1265\n",
      "Epoch 299/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6593.0898 - mae: 6593.0898\n",
      "Epoch 300/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6589.0122 - mae: 6589.0122\n",
      "Epoch 301/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6584.8853 - mae: 6584.8853\n",
      "Epoch 302/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6580.8022 - mae: 6580.8022\n",
      "Epoch 303/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6576.6392 - mae: 6576.6392\n",
      "Epoch 304/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6572.9438 - mae: 6572.9438\n",
      "Epoch 305/500\n",
      "34/34 [==============================] - 0s 781us/step - loss: 6568.7007 - mae: 6568.7007\n",
      "Epoch 306/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6564.6323 - mae: 6564.6323\n",
      "Epoch 307/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 792us/step - loss: 6560.6465 - mae: 6560.6465\n",
      "Epoch 308/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6557.1851 - mae: 6557.1851\n",
      "Epoch 309/500\n",
      "34/34 [==============================] - 0s 695us/step - loss: 6552.8101 - mae: 6552.8101\n",
      "Epoch 310/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6548.6221 - mae: 6548.6221\n",
      "Epoch 311/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6544.6157 - mae: 6544.6157\n",
      "Epoch 312/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6540.5117 - mae: 6540.5117\n",
      "Epoch 313/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6536.8008 - mae: 6536.8008\n",
      "Epoch 314/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6533.1592 - mae: 6533.1592\n",
      "Epoch 315/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6528.7119 - mae: 6528.7119\n",
      "Epoch 316/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6525.2290 - mae: 6525.2290\n",
      "Epoch 317/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6521.2700 - mae: 6521.2700\n",
      "Epoch 318/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6517.0962 - mae: 6517.0962\n",
      "Epoch 319/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6513.7056 - mae: 6513.7056\n",
      "Epoch 320/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6509.9404 - mae: 6509.9404\n",
      "Epoch 321/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6505.9575 - mae: 6505.9575\n",
      "Epoch 322/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6502.6167 - mae: 6502.6167\n",
      "Epoch 323/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6498.8901 - mae: 6498.8901\n",
      "Epoch 324/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6495.2891 - mae: 6495.2891\n",
      "Epoch 325/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6491.6792 - mae: 6491.6792\n",
      "Epoch 326/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6488.4644 - mae: 6488.4644\n",
      "Epoch 327/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6484.8574 - mae: 6484.8574\n",
      "Epoch 328/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6481.1470 - mae: 6481.1470\n",
      "Epoch 329/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6477.9023 - mae: 6477.9023\n",
      "Epoch 330/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6474.9512 - mae: 6474.9512\n",
      "Epoch 331/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6471.9512 - mae: 6471.9512\n",
      "Epoch 332/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6468.6826 - mae: 6468.6826\n",
      "Epoch 333/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6465.3960 - mae: 6465.3960\n",
      "Epoch 334/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6462.5830 - mae: 6462.5830\n",
      "Epoch 335/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6459.4531 - mae: 6459.4531\n",
      "Epoch 336/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6456.7241 - mae: 6456.7241\n",
      "Epoch 337/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6454.5527 - mae: 6454.5527\n",
      "Epoch 338/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6450.9990 - mae: 6450.9990\n",
      "Epoch 339/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6447.6157 - mae: 6447.6157\n",
      "Epoch 340/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6444.6738 - mae: 6444.6738\n",
      "Epoch 341/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6442.2412 - mae: 6442.2412\n",
      "Epoch 342/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6439.7417 - mae: 6439.7417\n",
      "Epoch 343/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6436.8750 - mae: 6436.8750\n",
      "Epoch 344/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6433.7988 - mae: 6433.7988\n",
      "Epoch 345/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6431.1479 - mae: 6431.1479\n",
      "Epoch 346/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6428.2964 - mae: 6428.2964\n",
      "Epoch 347/500\n",
      "34/34 [==============================] - 0s 660us/step - loss: 6425.8740 - mae: 6425.8740\n",
      "Epoch 348/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6423.5757 - mae: 6423.5757\n",
      "Epoch 349/500\n",
      "34/34 [==============================] - 0s 880us/step - loss: 6420.6846 - mae: 6420.6846\n",
      "Epoch 350/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6418.4248 - mae: 6418.4248\n",
      "Epoch 351/500\n",
      "34/34 [==============================] - 0s 730us/step - loss: 6415.7139 - mae: 6415.7139\n",
      "Epoch 352/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6413.2412 - mae: 6413.2412\n",
      "Epoch 353/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6410.9673 - mae: 6410.9673\n",
      "Epoch 354/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6408.6543 - mae: 6408.6543\n",
      "Epoch 355/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6406.4521 - mae: 6406.4521\n",
      "Epoch 356/500\n",
      "34/34 [==============================] - 0s 697us/step - loss: 6404.0908 - mae: 6404.0908\n",
      "Epoch 357/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6401.8418 - mae: 6401.8418\n",
      "Epoch 358/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6399.6582 - mae: 6399.6582\n",
      "Epoch 359/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6397.5171 - mae: 6397.5171\n",
      "Epoch 360/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6395.5889 - mae: 6395.5889\n",
      "Epoch 361/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6393.6240 - mae: 6393.6240\n",
      "Epoch 362/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6391.4180 - mae: 6391.4180\n",
      "Epoch 363/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6389.8042 - mae: 6389.8042\n",
      "Epoch 364/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6387.8647 - mae: 6387.8647\n",
      "Epoch 365/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6386.0493 - mae: 6386.0493\n",
      "Epoch 366/500\n",
      "34/34 [==============================] - 0s 672us/step - loss: 6384.1577 - mae: 6384.1577\n",
      "Epoch 367/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6382.5435 - mae: 6382.5435\n",
      "Epoch 368/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6380.9023 - mae: 6380.9023\n",
      "Epoch 369/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6378.8701 - mae: 6378.8701\n",
      "Epoch 370/500\n",
      "34/34 [==============================] - 0s 724us/step - loss: 6377.1143 - mae: 6377.1143\n",
      "Epoch 371/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6375.4502 - mae: 6375.4502\n",
      "Epoch 372/500\n",
      "34/34 [==============================] - 0s 851us/step - loss: 6373.4849 - mae: 6373.4849\n",
      "Epoch 373/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6372.0752 - mae: 6372.0752\n",
      "Epoch 374/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6370.3447 - mae: 6370.3447\n",
      "Epoch 375/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6368.9790 - mae: 6368.9790\n",
      "Epoch 376/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6367.1348 - mae: 6367.1348\n",
      "Epoch 377/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6365.5303 - mae: 6365.5303\n",
      "Epoch 378/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6364.2959 - mae: 6364.2959\n",
      "Epoch 379/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6362.5947 - mae: 6362.5947\n",
      "Epoch 380/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6361.2563 - mae: 6361.2563\n",
      "Epoch 381/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6359.6348 - mae: 6359.6348\n",
      "Epoch 382/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6358.0981 - mae: 6358.0981\n",
      "Epoch 383/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6356.8970 - mae: 6356.8970\n",
      "Epoch 384/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6354.9976 - mae: 6354.9976\n",
      "Epoch 385/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 733us/step - loss: 6353.6890 - mae: 6353.6890\n",
      "Epoch 386/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6352.3218 - mae: 6352.3218\n",
      "Epoch 387/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6350.8281 - mae: 6350.8281\n",
      "Epoch 388/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6349.2896 - mae: 6349.2896\n",
      "Epoch 389/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6348.0420 - mae: 6348.0420\n",
      "Epoch 390/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6346.3877 - mae: 6346.3877\n",
      "Epoch 391/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6344.9912 - mae: 6344.9912\n",
      "Epoch 392/500\n",
      "34/34 [==============================] - 0s 909us/step - loss: 6343.8276 - mae: 6343.8276\n",
      "Epoch 393/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6342.5161 - mae: 6342.5161\n",
      "Epoch 394/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6341.5850 - mae: 6341.5850\n",
      "Epoch 395/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6339.7861 - mae: 6339.7861\n",
      "Epoch 396/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6338.5625 - mae: 6338.5625\n",
      "Epoch 397/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6337.0596 - mae: 6337.0596\n",
      "Epoch 398/500\n",
      "34/34 [==============================] - 0s 665us/step - loss: 6336.5278 - mae: 6336.5278\n",
      "Epoch 399/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6334.2231 - mae: 6334.2231\n",
      "Epoch 400/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6332.9790 - mae: 6332.9790\n",
      "Epoch 401/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6331.5869 - mae: 6331.5869\n",
      "Epoch 402/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6330.5249 - mae: 6330.5249\n",
      "Epoch 403/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6328.8843 - mae: 6328.8843\n",
      "Epoch 404/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6327.7158 - mae: 6327.7158\n",
      "Epoch 405/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6326.5679 - mae: 6326.5679\n",
      "Epoch 406/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 6325.0801 - mae: 6325.0801\n",
      "Epoch 407/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6324.2510 - mae: 6324.2510\n",
      "Epoch 408/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6322.5596 - mae: 6322.5596\n",
      "Epoch 409/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6320.9844 - mae: 6320.9844\n",
      "Epoch 410/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6320.2397 - mae: 6320.2397\n",
      "Epoch 411/500\n",
      "34/34 [==============================] - 0s 597us/step - loss: 6318.4336 - mae: 6318.4336\n",
      "Epoch 412/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6317.1436 - mae: 6317.1436\n",
      "Epoch 413/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6315.8481 - mae: 6315.8481\n",
      "Epoch 414/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 6315.9434 - mae: 6315.9434\n",
      "Epoch 415/500\n",
      "34/34 [==============================] - 0s 638us/step - loss: 6314.2168 - mae: 6314.2168\n",
      "Epoch 416/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6312.5029 - mae: 6312.5029\n",
      "Epoch 417/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6310.9048 - mae: 6310.9048\n",
      "Epoch 418/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6309.6548 - mae: 6309.6548\n",
      "Epoch 419/500\n",
      "34/34 [==============================] - 0s 820us/step - loss: 6308.3921 - mae: 6308.3921\n",
      "Epoch 420/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6307.3530 - mae: 6307.3530\n",
      "Epoch 421/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6306.1968 - mae: 6306.1968\n",
      "Epoch 422/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6304.7612 - mae: 6304.7612\n",
      "Epoch 423/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6303.7285 - mae: 6303.7285\n",
      "Epoch 424/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6303.0952 - mae: 6303.0952\n",
      "Epoch 425/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6301.6260 - mae: 6301.6260\n",
      "Epoch 426/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6300.4624 - mae: 6300.4624\n",
      "Epoch 427/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6298.7827 - mae: 6298.7827\n",
      "Epoch 428/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6297.6875 - mae: 6297.6875\n",
      "Epoch 429/500\n",
      "34/34 [==============================] - 0s 851us/step - loss: 6297.0225 - mae: 6297.0225\n",
      "Epoch 430/500\n",
      "34/34 [==============================] - 0s 662us/step - loss: 6295.1626 - mae: 6295.1626\n",
      "Epoch 431/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6293.9580 - mae: 6293.9580\n",
      "Epoch 432/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6292.6968 - mae: 6292.6968\n",
      "Epoch 433/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6291.4810 - mae: 6291.4810\n",
      "Epoch 434/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6290.2705 - mae: 6290.2705\n",
      "Epoch 435/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6289.0112 - mae: 6289.0112\n",
      "Epoch 436/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6287.7437 - mae: 6287.7437\n",
      "Epoch 437/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6286.4692 - mae: 6286.4692\n",
      "Epoch 438/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6285.3623 - mae: 6285.3623\n",
      "Epoch 439/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6284.0552 - mae: 6284.0552\n",
      "Epoch 440/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6282.9741 - mae: 6282.9741\n",
      "Epoch 441/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6281.7285 - mae: 6281.7285\n",
      "Epoch 442/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6280.4707 - mae: 6280.4707\n",
      "Epoch 443/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6279.3643 - mae: 6279.3643\n",
      "Epoch 444/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6278.1426 - mae: 6278.1426\n",
      "Epoch 445/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6276.8672 - mae: 6276.8672\n",
      "Epoch 446/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6275.8105 - mae: 6275.8105\n",
      "Epoch 447/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6274.6924 - mae: 6274.6924\n",
      "Epoch 448/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6273.5381 - mae: 6273.5381\n",
      "Epoch 449/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6272.2246 - mae: 6272.2246\n",
      "Epoch 450/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6270.7393 - mae: 6270.7393\n",
      "Epoch 451/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6269.7632 - mae: 6269.7632\n",
      "Epoch 452/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6268.3765 - mae: 6268.3765\n",
      "Epoch 453/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6267.3169 - mae: 6267.3169\n",
      "Epoch 454/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6266.1201 - mae: 6266.1201\n",
      "Epoch 455/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6264.8525 - mae: 6264.8525\n",
      "Epoch 456/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6263.7197 - mae: 6263.7197\n",
      "Epoch 457/500\n",
      "34/34 [==============================] - 0s 694us/step - loss: 6262.4956 - mae: 6262.4956\n",
      "Epoch 458/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6261.2451 - mae: 6261.2451\n",
      "Epoch 459/500\n",
      "34/34 [==============================] - 0s 694us/step - loss: 6259.9331 - mae: 6259.9331\n",
      "Epoch 460/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6259.6812 - mae: 6259.6812\n",
      "Epoch 461/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6257.5581 - mae: 6257.5581\n",
      "Epoch 462/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6256.2520 - mae: 6256.2520\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 645us/step - loss: 6255.0464 - mae: 6255.0464\n",
      "Epoch 464/500\n",
      "34/34 [==============================] - 0s 792us/step - loss: 6253.7686 - mae: 6253.7686\n",
      "Epoch 465/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6252.7471 - mae: 6252.7471\n",
      "Epoch 466/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6251.7339 - mae: 6251.7339\n",
      "Epoch 467/500\n",
      "34/34 [==============================] - ETA: 0s - loss: 9489.3291 - mae: 9489.329 - 0s 704us/step - loss: 6250.2925 - mae: 6250.2925\n",
      "Epoch 468/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6248.9561 - mae: 6248.9561\n",
      "Epoch 469/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6247.9204 - mae: 6247.9204\n",
      "Epoch 470/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6246.4448 - mae: 6246.4448\n",
      "Epoch 471/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6245.4512 - mae: 6245.4512\n",
      "Epoch 472/500\n",
      "34/34 [==============================] - 0s 657us/step - loss: 6244.1772 - mae: 6244.1772\n",
      "Epoch 473/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6243.1421 - mae: 6243.1421\n",
      "Epoch 474/500\n",
      "34/34 [==============================] - 0s 727us/step - loss: 6241.6621 - mae: 6241.6621\n",
      "Epoch 475/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6240.8564 - mae: 6240.8564\n",
      "Epoch 476/500\n",
      "34/34 [==============================] - 0s 674us/step - loss: 6239.4019 - mae: 6239.4019\n",
      "Epoch 477/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6238.2095 - mae: 6238.2095\n",
      "Epoch 478/500\n",
      "34/34 [==============================] - 0s 722us/step - loss: 6236.7363 - mae: 6236.7363\n",
      "Epoch 479/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6235.4771 - mae: 6235.4771\n",
      "Epoch 480/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6234.2632 - mae: 6234.2632\n",
      "Epoch 481/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 6233.1743 - mae: 6233.1743\n",
      "Epoch 482/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6231.7739 - mae: 6231.7739\n",
      "Epoch 483/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6230.7373 - mae: 6230.7373\n",
      "Epoch 484/500\n",
      "34/34 [==============================] - 0s 722us/step - loss: 6229.3989 - mae: 6229.3989\n",
      "Epoch 485/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6228.1309 - mae: 6228.1309\n",
      "Epoch 486/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6226.9219 - mae: 6226.9219\n",
      "Epoch 487/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6225.6289 - mae: 6225.6289\n",
      "Epoch 488/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6224.5918 - mae: 6224.5918\n",
      "Epoch 489/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6223.0771 - mae: 6223.0771\n",
      "Epoch 490/500\n",
      "34/34 [==============================] - 0s 756us/step - loss: 6221.8989 - mae: 6221.8989\n",
      "Epoch 491/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6220.7271 - mae: 6220.7271\n",
      "Epoch 492/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6219.4683 - mae: 6219.4683\n",
      "Epoch 493/500\n",
      "34/34 [==============================] - 0s 851us/step - loss: 6218.6357 - mae: 6218.6357\n",
      "Epoch 494/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6217.0903 - mae: 6217.0903\n",
      "Epoch 495/500\n",
      "34/34 [==============================] - 0s 794us/step - loss: 6215.8408 - mae: 6215.8408\n",
      "Epoch 496/500\n",
      "34/34 [==============================] - 0s 670us/step - loss: 6214.6035 - mae: 6214.6035\n",
      "Epoch 497/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6213.6660 - mae: 6213.6660\n",
      "Epoch 498/500\n",
      "34/34 [==============================] - 0s 675us/step - loss: 6211.9785 - mae: 6211.9785\n",
      "Epoch 499/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6211.1572 - mae: 6211.1572\n",
      "Epoch 500/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 6209.7402 - mae: 6209.7402\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x249d89428b0>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model3 = tf.keras.Sequential([tf.keras.layers.Dense(10),\n",
    "                                      tf.keras.layers.Dense(1)])\n",
    "\n",
    "insurance_model3.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"mae\", metrics=[\"mae\"])\n",
    "\n",
    "insurance_model3.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "7f3f0e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot()\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a9c120",
   "metadata": {},
   "source": [
    "##### For how long should you run the training, you can use early stopping machanism to stop the traning if validation error is more than the median of previous runs. Use \"Earlystopping callback\" in Tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e038d9",
   "metadata": {},
   "source": [
    "Preprocessing data (Normalization and standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "d011b4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X[\"age\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d3e5dcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X[\"children\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaler transforms the data by using mean of 0 and standard deviation of 1. Normalization is transforming data between 0,1\n",
    "# In terms of scaling values, neural network prefers normalization.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "1a1c46fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "d907776e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "77dbb8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>10600.54830</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>2205.98080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>1629.83350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>2007.94500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>29141.36030</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
       "0      19  27.900         0  16884.92400           1         0          0   \n",
       "1      18  33.770         1   1725.55230           0         1          1   \n",
       "2      28  33.000         3   4449.46200           0         1          1   \n",
       "3      33  22.705         0  21984.47061           0         1          1   \n",
       "4      32  28.880         0   3866.85520           0         1          1   \n",
       "...   ...     ...       ...          ...         ...       ...        ...   \n",
       "1333   50  30.970         3  10600.54830           0         1          1   \n",
       "1334   18  31.920         0   2205.98080           1         0          1   \n",
       "1335   18  36.850         0   1629.83350           1         0          1   \n",
       "1336   21  25.800         0   2007.94500           1         0          1   \n",
       "1337   61  29.070         0  29141.36030           1         0          0   \n",
       "\n",
       "      smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
       "0              1                 0                 0                 0   \n",
       "1              0                 0                 0                 1   \n",
       "2              0                 0                 0                 1   \n",
       "3              0                 0                 1                 0   \n",
       "4              0                 0                 1                 0   \n",
       "...          ...               ...               ...               ...   \n",
       "1333           0                 0                 1                 0   \n",
       "1334           0                 1                 0                 0   \n",
       "1335           0                 0                 0                 1   \n",
       "1336           0                 0                 0                 0   \n",
       "1337           1                 0                 1                 0   \n",
       "\n",
       "      region_southwest  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "1333                 0  \n",
       "1334                 0  \n",
       "1335                 0  \n",
       "1336                 1  \n",
       "1337                 0  \n",
       "\n",
       "[1338 rows x 12 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance = pd.get_dummies(insurance)\n",
    "insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "6d7ae29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       " 0      19  27.900         0           1         0          0           1   \n",
       " 1      18  33.770         1           0         1          1           0   \n",
       " 2      28  33.000         3           0         1          1           0   \n",
       " 3      33  22.705         0           0         1          1           0   \n",
       " 4      32  28.880         0           0         1          1           0   \n",
       " ...   ...     ...       ...         ...       ...        ...         ...   \n",
       " 1333   50  30.970         3           0         1          1           0   \n",
       " 1334   18  31.920         0           1         0          1           0   \n",
       " 1335   18  36.850         0           1         0          1           0   \n",
       " 1336   21  25.800         0           1         0          1           0   \n",
       " 1337   61  29.070         0           1         0          0           1   \n",
       " \n",
       "       region_northeast  region_northwest  region_southeast  region_southwest  \n",
       " 0                    0                 0                 0                 1  \n",
       " 1                    0                 0                 1                 0  \n",
       " 2                    0                 0                 1                 0  \n",
       " 3                    0                 1                 0                 0  \n",
       " 4                    0                 1                 0                 0  \n",
       " ...                ...               ...               ...               ...  \n",
       " 1333                 0                 1                 0                 0  \n",
       " 1334                 1                 0                 0                 0  \n",
       " 1335                 0                 0                 1                 0  \n",
       " 1336                 0                 0                 0                 1  \n",
       " 1337                 0                 1                 0                 0  \n",
       " \n",
       " [1338 rows x 11 columns],\n",
       " 0       16884.92400\n",
       " 1        1725.55230\n",
       " 2        4449.46200\n",
       " 3       21984.47061\n",
       " 4        3866.85520\n",
       "            ...     \n",
       " 1333    10600.54830\n",
       " 1334     2205.98080\n",
       " 1335     1629.83350\n",
       " 1336     2007.94500\n",
       " 1337    29141.36030\n",
       " Name: charges, Length: 1338, dtype: float64)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = insurance.drop([\"charges\"], axis=1)\n",
    "y = insurance[\"charges\"]\n",
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "80e32d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "b97585e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the input data\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "sc = MinMaxScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cc5f99",
   "metadata": {},
   "source": [
    "#### Alternative to get_dummies you can also use sklearn to combine onehot encoding with sklearn\n",
    "\n",
    "'from sklearn.compose import make_column_transformer'\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "ct =  make_column_transformer(\n",
    "            (MinMaxScaler(),[\"age\",\"bmi\",\"children\"]),\n",
    "            (OneHotEncoder(),[\"sex\",\"smoker\",\"region\"])\n",
    "                             )'\n",
    "\n",
    "#### Make sure to transform only training data and then use same object of transformer to transform test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "db425525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.58695652, 0.24791499, 0.4       , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.39130435, 0.37826204, 0.        , ..., 1.        , 0.        ,\n",
       "         0.        ],\n",
       "        [1.        , 0.29391983, 0.        , ..., 1.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.76086957, 0.14635459, 0.2       , ..., 0.        , 0.        ,\n",
       "         1.        ],\n",
       "        [0.17391304, 0.36803874, 0.8       , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.10869565, 0.44659672, 0.        , ..., 0.        , 1.        ,\n",
       "         0.        ]]),\n",
       " array([[0.54347826, 0.24535916, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.45652174, 0.52031208, 0.4       , ..., 0.        , 0.        ,\n",
       "         1.        ],\n",
       "        [0.58695652, 0.39104116, 0.2       , ..., 1.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.86956522, 0.24791499, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.41304348, 0.85122411, 0.4       , ..., 0.        , 0.        ,\n",
       "         1.        ],\n",
       "        [0.80434783, 0.37503363, 0.        , ..., 0.        , 0.        ,\n",
       "         1.        ]]))"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "4572752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 13376.7520 - mae: 13376.7520\n",
      "Epoch 2/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 13370.3857 - mae: 13370.3857\n",
      "Epoch 3/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 13357.3799 - mae: 13357.3799\n",
      "Epoch 4/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 13332.2109 - mae: 13332.2109\n",
      "Epoch 5/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 13288.6689 - mae: 13288.6689\n",
      "Epoch 6/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 13220.3525 - mae: 13220.3525\n",
      "Epoch 7/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 13121.2588 - mae: 13121.2588\n",
      "Epoch 8/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 12985.6787 - mae: 12985.6787\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 12807.8906 - mae: 12807.8906\n",
      "Epoch 10/500\n",
      "28/28 [==============================] - 0s 932us/step - loss: 12582.1904 - mae: 12582.1904\n",
      "Epoch 11/500\n",
      "28/28 [==============================] - 0s 855us/step - loss: 12303.0859 - mae: 12303.0859\n",
      "Epoch 12/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 11970.3506 - mae: 11970.3506\n",
      "Epoch 13/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 11589.2842 - mae: 11589.2842\n",
      "Epoch 14/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 11182.0732 - mae: 11182.0732\n",
      "Epoch 15/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 10777.2256 - mae: 10777.2256\n",
      "Epoch 16/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 10365.9248 - mae: 10365.9248\n",
      "Epoch 17/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 9960.9707 - mae: 9960.9707\n",
      "Epoch 18/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 9572.9932 - mae: 9572.9932\n",
      "Epoch 19/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 9225.8633 - mae: 9225.8633\n",
      "Epoch 20/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 8924.3193 - mae: 8924.3193\n",
      "Epoch 21/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 8674.1885 - mae: 8674.1885\n",
      "Epoch 22/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 8461.6074 - mae: 8461.6074\n",
      "Epoch 23/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 8294.7939 - mae: 8294.7939\n",
      "Epoch 24/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 8175.9561 - mae: 8175.9561\n",
      "Epoch 25/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 8080.8940 - mae: 8080.8940\n",
      "Epoch 26/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 8013.7876 - mae: 8013.7876\n",
      "Epoch 27/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7959.9297 - mae: 7959.9297\n",
      "Epoch 28/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7911.8564 - mae: 7911.8564\n",
      "Epoch 29/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7869.8481 - mae: 7869.8481\n",
      "Epoch 30/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7829.1768 - mae: 7829.1768\n",
      "Epoch 31/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7789.6245 - mae: 7789.6245\n",
      "Epoch 32/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7752.8628 - mae: 7752.8628\n",
      "Epoch 33/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7714.8521 - mae: 7714.8521\n",
      "Epoch 34/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7680.2446 - mae: 7680.2446\n",
      "Epoch 35/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7639.7070 - mae: 7639.7070\n",
      "Epoch 36/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7603.4185 - mae: 7603.4185\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 7565.3867 - mae: 7565.3867\n",
      "Epoch 38/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7526.5068 - mae: 7526.5068\n",
      "Epoch 39/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7486.9214 - mae: 7486.9214\n",
      "Epoch 40/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 7447.6499 - mae: 7447.6499\n",
      "Epoch 41/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7406.1455 - mae: 7406.1455\n",
      "Epoch 42/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7364.2954 - mae: 7364.2954\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7320.8716 - mae: 7320.8716\n",
      "Epoch 44/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7277.5093 - mae: 7277.5093\n",
      "Epoch 45/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7231.8062 - mae: 7231.8062\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 7186.1533 - mae: 7186.1533\n",
      "Epoch 47/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7138.2407 - mae: 7138.2407\n",
      "Epoch 48/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7091.3452 - mae: 7091.3452\n",
      "Epoch 49/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 7039.9170 - mae: 7039.9170\n",
      "Epoch 50/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6988.6919 - mae: 6988.6919\n",
      "Epoch 51/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6935.4805 - mae: 6935.4805\n",
      "Epoch 52/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 6878.7241 - mae: 6878.7241\n",
      "Epoch 53/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 6822.5400 - mae: 6822.5400\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 6763.0151 - mae: 6763.0151\n",
      "Epoch 55/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 6703.0693 - mae: 6703.0693\n",
      "Epoch 56/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6637.8525 - mae: 6637.8525\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6572.3193 - mae: 6572.3193\n",
      "Epoch 58/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6504.0713 - mae: 6504.0713\n",
      "Epoch 59/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6433.6978 - mae: 6433.6978\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6357.9346 - mae: 6357.9346\n",
      "Epoch 61/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6280.8584 - mae: 6280.8584\n",
      "Epoch 62/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6202.4023 - mae: 6202.4023\n",
      "Epoch 63/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6117.5864 - mae: 6117.5864\n",
      "Epoch 64/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 6030.9570 - mae: 6030.9570\n",
      "Epoch 65/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 5939.6987 - mae: 5939.6987\n",
      "Epoch 66/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 5846.4468 - mae: 5846.4468\n",
      "Epoch 67/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 5749.9033 - mae: 5749.9033\n",
      "Epoch 68/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 5650.6670 - mae: 5650.6670\n",
      "Epoch 69/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 5550.2339 - mae: 5550.2339\n",
      "Epoch 70/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 5449.6680 - mae: 5449.6680\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 5337.6748 - mae: 5337.6748\n",
      "Epoch 72/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 5226.4370 - mae: 5226.4370\n",
      "Epoch 73/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 5113.7720 - mae: 5113.7720\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 4996.6987 - mae: 4996.6987\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 4881.5542 - mae: 4881.5542\n",
      "Epoch 76/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 4763.7026 - mae: 4763.7026\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 4644.7607 - mae: 4644.7607\n",
      "Epoch 78/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 4531.8936 - mae: 4531.8936\n",
      "Epoch 79/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 4425.7603 - mae: 4425.7603\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 4326.8315 - mae: 4326.8315\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 997us/step - loss: 4234.8599 - mae: 4234.8599\n",
      "Epoch 82/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 4143.5684 - mae: 4143.5684\n",
      "Epoch 83/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 4057.5725 - mae: 4057.5725\n",
      "Epoch 84/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3981.3186 - mae: 3981.3186\n",
      "Epoch 85/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3915.3481 - mae: 3915.3481\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3858.2673 - mae: 3858.2673\n",
      "Epoch 87/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3812.5540 - mae: 3812.5540\n",
      "Epoch 88/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3772.1406 - mae: 3772.1406\n",
      "Epoch 89/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3740.0859 - mae: 3740.0859\n",
      "Epoch 90/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3717.3203 - mae: 3717.3203\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3701.2263 - mae: 3701.2263\n",
      "Epoch 92/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3686.7075 - mae: 3686.7075\n",
      "Epoch 93/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3678.2634 - mae: 3678.2634\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3668.9565 - mae: 3668.9565\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3664.5344 - mae: 3664.5344\n",
      "Epoch 96/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3659.8562 - mae: 3659.8562\n",
      "Epoch 97/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3657.3977 - mae: 3657.3977\n",
      "Epoch 98/500\n",
      "28/28 [==============================] - 0s 961us/step - loss: 3655.3982 - mae: 3655.3982\n",
      "Epoch 99/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3653.2258 - mae: 3653.2258\n",
      "Epoch 100/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3651.0989 - mae: 3651.0989\n",
      "Epoch 101/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3648.8813 - mae: 3648.8813\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3648.5813 - mae: 3648.5813\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3645.6008 - mae: 3645.6008\n",
      "Epoch 104/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3644.8933 - mae: 3644.8933\n",
      "Epoch 105/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3643.0864 - mae: 3643.0864\n",
      "Epoch 106/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3642.7751 - mae: 3642.7751\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3641.0486 - mae: 3641.0486\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3640.0310 - mae: 3640.0310\n",
      "Epoch 109/500\n",
      "28/28 [==============================] - 0s 819us/step - loss: 3640.2224 - mae: 3640.2224\n",
      "Epoch 110/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3638.7891 - mae: 3638.7891\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3636.6206 - mae: 3636.6206\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3637.7532 - mae: 3637.7532\n",
      "Epoch 113/500\n",
      "28/28 [==============================] - 0s 855us/step - loss: 3636.6663 - mae: 3636.6663\n",
      "Epoch 114/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3635.7952 - mae: 3635.7952\n",
      "Epoch 115/500\n",
      "28/28 [==============================] - 0s 855us/step - loss: 3634.7700 - mae: 3634.7700\n",
      "Epoch 116/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3634.6055 - mae: 3634.6055\n",
      "Epoch 117/500\n",
      "28/28 [==============================] - 0s 819us/step - loss: 3632.4036 - mae: 3632.4036\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3631.1099 - mae: 3631.1099\n",
      "Epoch 119/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3630.2341 - mae: 3630.2341\n",
      "Epoch 120/500\n",
      "28/28 [==============================] - 0s 855us/step - loss: 3629.0698 - mae: 3629.0698\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3629.9419 - mae: 3629.9419\n",
      "Epoch 122/500\n",
      "28/28 [==============================] - 0s 891us/step - loss: 3626.8679 - mae: 3626.8679\n",
      "Epoch 123/500\n",
      "28/28 [==============================] - 0s 855us/step - loss: 3627.1392 - mae: 3627.1392\n",
      "Epoch 124/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3624.9668 - mae: 3624.9668\n",
      "Epoch 125/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3624.1099 - mae: 3624.1099\n",
      "Epoch 126/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3624.2551 - mae: 3624.2551\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3622.4512 - mae: 3622.4512\n",
      "Epoch 128/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3622.2239 - mae: 3622.2239\n",
      "Epoch 129/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3620.8892 - mae: 3620.8892\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3618.8767 - mae: 3618.8767\n",
      "Epoch 131/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3617.5833 - mae: 3617.5833\n",
      "Epoch 132/500\n",
      "28/28 [==============================] - 0s 891us/step - loss: 3618.1711 - mae: 3618.1711\n",
      "Epoch 133/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3616.6094 - mae: 3616.6094\n",
      "Epoch 134/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3616.1667 - mae: 3616.1667\n",
      "Epoch 135/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3614.1003 - mae: 3614.1003\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3613.3008 - mae: 3613.3008\n",
      "Epoch 137/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3611.9231 - mae: 3611.9231\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3610.8411 - mae: 3610.8411\n",
      "Epoch 139/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3611.8464 - mae: 3611.8464\n",
      "Epoch 140/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3609.9426 - mae: 3609.9426\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3607.9749 - mae: 3607.9749\n",
      "Epoch 142/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3606.8872 - mae: 3606.8872\n",
      "Epoch 143/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3605.8894 - mae: 3605.8894\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3606.7344 - mae: 3606.7344\n",
      "Epoch 145/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3603.1692 - mae: 3603.1692\n",
      "Epoch 146/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3604.6074 - mae: 3604.6074\n",
      "Epoch 147/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3606.2000 - mae: 3606.2000\n",
      "Epoch 148/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3600.9160 - mae: 3600.9160\n",
      "Epoch 149/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3599.7512 - mae: 3599.7512\n",
      "Epoch 150/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3599.1233 - mae: 3599.1233\n",
      "Epoch 151/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3597.8713 - mae: 3597.8713\n",
      "Epoch 152/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3597.2625 - mae: 3597.2625\n",
      "Epoch 153/500\n",
      "28/28 [==============================] - 0s 855us/step - loss: 3595.7195 - mae: 3595.7195\n",
      "Epoch 154/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3594.0259 - mae: 3594.0259\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3593.6755 - mae: 3593.6755\n",
      "Epoch 156/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3592.0925 - mae: 3592.0925\n",
      "Epoch 157/500\n",
      "28/28 [==============================] - 0s 855us/step - loss: 3590.6724 - mae: 3590.6724\n",
      "Epoch 158/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3591.8518 - mae: 3591.8518\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3588.2288 - mae: 3588.2288\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 962us/step - loss: 3588.2051 - mae: 3588.2051\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3585.3296 - mae: 3585.3296\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3586.0828 - mae: 3586.0828\n",
      "Epoch 163/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3585.9624 - mae: 3585.9624\n",
      "Epoch 164/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3582.7017 - mae: 3582.7017\n",
      "Epoch 165/500\n",
      "28/28 [==============================] - 0s 784us/step - loss: 3581.4497 - mae: 3581.4497\n",
      "Epoch 166/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3581.2263 - mae: 3581.2263\n",
      "Epoch 167/500\n",
      "28/28 [==============================] - 0s 855us/step - loss: 3583.2292 - mae: 3583.2292\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - 0s 891us/step - loss: 3578.2991 - mae: 3578.2991\n",
      "Epoch 169/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3576.7224 - mae: 3576.7224\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3575.4858 - mae: 3575.4858\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - 0s 855us/step - loss: 3574.8889 - mae: 3574.8889\n",
      "Epoch 172/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3572.0859 - mae: 3572.0859\n",
      "Epoch 173/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3572.5933 - mae: 3572.5933\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3572.1953 - mae: 3572.1953\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3572.8459 - mae: 3572.8459\n",
      "Epoch 176/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3568.1060 - mae: 3568.1060\n",
      "Epoch 177/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3566.4614 - mae: 3566.4614\n",
      "Epoch 178/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3567.1086 - mae: 3567.1086\n",
      "Epoch 179/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3565.9668 - mae: 3565.9668\n",
      "Epoch 180/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3562.6577 - mae: 3562.6577\n",
      "Epoch 181/500\n",
      "28/28 [==============================] - 0s 855us/step - loss: 3564.5796 - mae: 3564.5796\n",
      "Epoch 182/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3562.0911 - mae: 3562.0911\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3562.0920 - mae: 3562.0920\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3560.4548 - mae: 3560.4548\n",
      "Epoch 185/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3557.8003 - mae: 3557.8003\n",
      "Epoch 186/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3559.1746 - mae: 3559.1746\n",
      "Epoch 187/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3557.1370 - mae: 3557.1370\n",
      "Epoch 188/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3557.2129 - mae: 3557.2129\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3556.6128 - mae: 3556.6128\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3555.5918 - mae: 3555.5918\n",
      "Epoch 191/500\n",
      "28/28 [==============================] - 0s 891us/step - loss: 3557.7122 - mae: 3557.7122\n",
      "Epoch 192/500\n",
      "28/28 [==============================] - 0s 855us/step - loss: 3555.4141 - mae: 3555.4141\n",
      "Epoch 193/500\n",
      "28/28 [==============================] - 0s 855us/step - loss: 3553.0569 - mae: 3553.0569\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3552.1255 - mae: 3552.1255\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3551.3015 - mae: 3551.3015\n",
      "Epoch 196/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3551.2095 - mae: 3551.2095\n",
      "Epoch 197/500\n",
      "28/28 [==============================] - 0s 855us/step - loss: 3550.6130 - mae: 3550.6130\n",
      "Epoch 198/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3550.1489 - mae: 3550.1489\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3549.4231 - mae: 3549.4231\n",
      "Epoch 200/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3548.1658 - mae: 3548.1658\n",
      "Epoch 201/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3549.9197 - mae: 3549.9197\n",
      "Epoch 202/500\n",
      "28/28 [==============================] - 0s 855us/step - loss: 3549.3655 - mae: 3549.3655\n",
      "Epoch 203/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3547.5181 - mae: 3547.5181\n",
      "Epoch 204/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3545.8188 - mae: 3545.8188\n",
      "Epoch 205/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3545.9070 - mae: 3545.9070\n",
      "Epoch 206/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3545.3738 - mae: 3545.3738\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3544.3105 - mae: 3544.3105\n",
      "Epoch 208/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3544.2415 - mae: 3544.2415\n",
      "Epoch 209/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3542.9285 - mae: 3542.9285\n",
      "Epoch 210/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3541.1313 - mae: 3541.1313\n",
      "Epoch 211/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3543.8899 - mae: 3543.8899\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3540.4077 - mae: 3540.4077\n",
      "Epoch 213/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3540.1465 - mae: 3540.1465\n",
      "Epoch 214/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3538.8738 - mae: 3538.8738\n",
      "Epoch 215/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3541.3464 - mae: 3541.3464\n",
      "Epoch 216/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3536.6062 - mae: 3536.6062\n",
      "Epoch 217/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3536.8496 - mae: 3536.8496\n",
      "Epoch 218/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3536.3149 - mae: 3536.3149\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3534.2224 - mae: 3534.2224\n",
      "Epoch 220/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3535.2102 - mae: 3535.2102\n",
      "Epoch 221/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3537.4963 - mae: 3537.4963\n",
      "Epoch 222/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3535.7517 - mae: 3535.7517\n",
      "Epoch 223/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3531.8320 - mae: 3531.8320\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3532.3313 - mae: 3532.3313\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3532.5825 - mae: 3532.5825\n",
      "Epoch 226/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3531.8523 - mae: 3531.8523\n",
      "Epoch 227/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3530.8298 - mae: 3530.8298\n",
      "Epoch 228/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3533.4668 - mae: 3533.4668\n",
      "Epoch 229/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3529.3074 - mae: 3529.3074\n",
      "Epoch 230/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3530.8518 - mae: 3530.8518\n",
      "Epoch 231/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3529.5491 - mae: 3529.5491\n",
      "Epoch 232/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3530.3982 - mae: 3530.3982\n",
      "Epoch 233/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3528.9700 - mae: 3528.9700\n",
      "Epoch 234/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3527.0996 - mae: 3527.0996\n",
      "Epoch 235/500\n",
      "28/28 [==============================] - 0s 819us/step - loss: 3529.1716 - mae: 3529.1716\n",
      "Epoch 236/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3527.0825 - mae: 3527.0825\n",
      "Epoch 237/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3524.9651 - mae: 3524.9651\n",
      "Epoch 238/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3527.3157 - mae: 3527.3157\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 926us/step - loss: 3529.9734 - mae: 3529.9734\n",
      "Epoch 240/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3526.3489 - mae: 3526.3489\n",
      "Epoch 241/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3523.2466 - mae: 3523.2466\n",
      "Epoch 242/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3523.4858 - mae: 3523.4858\n",
      "Epoch 243/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3523.1575 - mae: 3523.1575\n",
      "Epoch 244/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3521.8323 - mae: 3521.8323\n",
      "Epoch 245/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3523.1023 - mae: 3523.1023\n",
      "Epoch 246/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3523.5957 - mae: 3523.5957\n",
      "Epoch 247/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3521.6489 - mae: 3521.6489\n",
      "Epoch 248/500\n",
      "28/28 [==============================] - 0s 891us/step - loss: 3522.2400 - mae: 3522.2400\n",
      "Epoch 249/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3520.0063 - mae: 3520.0063\n",
      "Epoch 250/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3520.3552 - mae: 3520.3552\n",
      "Epoch 251/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3519.6914 - mae: 3519.6914\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3521.3206 - mae: 3521.3206\n",
      "Epoch 253/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3519.5286 - mae: 3519.5286\n",
      "Epoch 254/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3519.2642 - mae: 3519.2642\n",
      "Epoch 255/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3517.4377 - mae: 3517.4377\n",
      "Epoch 256/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3516.9978 - mae: 3516.9978\n",
      "Epoch 257/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3515.4478 - mae: 3515.4478\n",
      "Epoch 258/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3517.6108 - mae: 3517.6108\n",
      "Epoch 259/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3519.2830 - mae: 3519.2830\n",
      "Epoch 260/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3516.6855 - mae: 3516.6855\n",
      "Epoch 261/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3513.6760 - mae: 3513.6760\n",
      "Epoch 262/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3514.6541 - mae: 3514.6541\n",
      "Epoch 263/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3512.6484 - mae: 3512.6484\n",
      "Epoch 264/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3511.9771 - mae: 3511.9771\n",
      "Epoch 265/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3511.9812 - mae: 3511.9812\n",
      "Epoch 266/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3512.6929 - mae: 3512.6929\n",
      "Epoch 267/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3511.9543 - mae: 3511.9543\n",
      "Epoch 268/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3513.3711 - mae: 3513.3711\n",
      "Epoch 269/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3511.6462 - mae: 3511.6462\n",
      "Epoch 270/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3510.6375 - mae: 3510.6375\n",
      "Epoch 271/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3509.5803 - mae: 3509.5803\n",
      "Epoch 272/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3508.5178 - mae: 3508.5178\n",
      "Epoch 273/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3509.6086 - mae: 3509.6086\n",
      "Epoch 274/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3509.4297 - mae: 3509.4297\n",
      "Epoch 275/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3506.5972 - mae: 3506.5972\n",
      "Epoch 276/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3505.9844 - mae: 3505.9844\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - 0s 891us/step - loss: 3506.1157 - mae: 3506.1157\n",
      "Epoch 278/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3507.2361 - mae: 3507.2361\n",
      "Epoch 279/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3505.0469 - mae: 3505.0469\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3506.1008 - mae: 3506.1008\n",
      "Epoch 281/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3504.3860 - mae: 3504.3860\n",
      "Epoch 282/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3504.9460 - mae: 3504.9460\n",
      "Epoch 283/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3502.4277 - mae: 3502.4277\n",
      "Epoch 284/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3502.8074 - mae: 3502.8074\n",
      "Epoch 285/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3500.7830 - mae: 3500.7830\n",
      "Epoch 286/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3501.4973 - mae: 3501.4973\n",
      "Epoch 287/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3500.8618 - mae: 3500.8618\n",
      "Epoch 288/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3500.8323 - mae: 3500.8323\n",
      "Epoch 289/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3501.6072 - mae: 3501.6072\n",
      "Epoch 290/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3499.8391 - mae: 3499.8391\n",
      "Epoch 291/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3499.7966 - mae: 3499.7966\n",
      "Epoch 292/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3499.2327 - mae: 3499.2327\n",
      "Epoch 293/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3499.6887 - mae: 3499.6887\n",
      "Epoch 294/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3499.1948 - mae: 3499.1948\n",
      "Epoch 295/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3499.0515 - mae: 3499.0515\n",
      "Epoch 296/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3499.5237 - mae: 3499.5237\n",
      "Epoch 297/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3498.4355 - mae: 3498.4355\n",
      "Epoch 298/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3502.8645 - mae: 3502.8645\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - 0s 890us/step - loss: 3502.1628 - mae: 3502.1628\n",
      "Epoch 300/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3498.1458 - mae: 3498.1458\n",
      "Epoch 301/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3499.1257 - mae: 3499.1257\n",
      "Epoch 302/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3500.7739 - mae: 3500.7739\n",
      "Epoch 303/500\n",
      "28/28 [==============================] - 0s 997us/step - loss: 3500.2644 - mae: 3500.2644\n",
      "Epoch 304/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3497.9773 - mae: 3497.9773\n",
      "Epoch 305/500\n",
      "28/28 [==============================] - 0s 819us/step - loss: 3498.4983 - mae: 3498.4983\n",
      "Epoch 306/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3498.5962 - mae: 3498.5962\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3498.2458 - mae: 3498.2458\n",
      "Epoch 308/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3498.4922 - mae: 3498.4922\n",
      "Epoch 309/500\n",
      "28/28 [==============================] - 0s 855us/step - loss: 3500.3342 - mae: 3500.3342\n",
      "Epoch 310/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3498.4705 - mae: 3498.4705\n",
      "Epoch 311/500\n",
      "28/28 [==============================] - 0s 926us/step - loss: 3498.2776 - mae: 3498.2776\n",
      "Epoch 312/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3499.1125 - mae: 3499.1125\n",
      "Epoch 313/500\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 3500.6697 - mae: 3500.6697\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - 0s 962us/step - loss: 3499.5168 - mae: 3499.5168\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",patience=10)\n",
    "# Creating the Neural network model to fit the data\n",
    "insurance_model4 = tf.keras.Sequential([tf.keras.layers.Dense(100),\n",
    "                                       tf.keras.layers.Dense(10),\n",
    "                                       tf.keras.layers.Dense(1)])\n",
    "\n",
    "# compiling the model\n",
    "\n",
    "insurance_model4.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.mae, metrics=[\"mae\"])\n",
    "\n",
    "#fitting the model\n",
    "\n",
    "history4 = insurance_model4.fit(X_train,y_train, epochs=500, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "3de8c7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAnDUlEQVR4nO3deXhV9b3v8fd3D0mYx4QpCEFRZJDBgNO9WIeK2p5qB1u9raJHa6+1dry2Wttz2tvTno7X1lZtaR3w1Ik6VHparUp7jrVFEBBkEgmThDGAhEmS7L2/94+9ghEDhuxhZe98Xs+zn7X2bw37+3sW8GHN5u6IiIi0VyTsAkREpLApSEREJCMKEhERyYiCREREMqIgERGRjMTCLiDf+vfv78OHDw+7DBGRgrJw4cId7l7e2rROFyTDhw9nwYIFYZchIlJQzGzDkabp0JaIiGREQSIiIhlRkIiISEY63TkSEZH2ampqora2loMHD4ZdSs6UlZVRWVlJPB5v8zIKEhGRNqqtraVHjx4MHz4cMwu7nKxzd3bu3EltbS1VVVVtXk6HtkRE2ujgwYP069evKEMEwMzo16/fMe9xKUhERI5BsYZIs/b0T4e22ui1ec/y5oo5lAwYxYjJF9KnfFDYJYmIdAgKkjba/fqLnLHhl7ABGubFmTv4E0z+59uJxUvCLk1EOpHu3buzb9++sMt4Bx3aaqPTr/y/HPzqJlZ98Ele7XM+Z2z5LUtvv5RUMhl2aSIioVKQHIOyrt05qfpcJn/xEV4a+RUmHvg78x/6dthliUgn5O7cfPPNjB07lnHjxvHoo48CsGXLFqZOncqECRMYO3Ysf/vb30gmk1x99dWH5r399tuzWosObbXTaVd8g1d+/BITau5ix9br6D/wuLBLEpE8+vYflrNi856srnP04J786z+NadO8TzzxBIsXL2bJkiXs2LGDyZMnM3XqVB566CGmTZvGbbfdRjKZ5MCBAyxevJhNmzaxbNkyAHbv3p3VurVH0k4WidD/Iz8gToKa338/7HJEpJN58cUXueKKK4hGowwYMICzzz6bl19+mcmTJ3PffffxrW99i6VLl9KjRw9GjBjB2rVruemmm3jmmWfo2bNnVmvRHkkGhp4wjgW9zmPMlic4eOCHlHXtHnZJIpInbd1zyBV3b7V96tSpvPDCC/zxj3/kyiuv5Oabb+aqq65iyZIl/PnPf+bOO+9k1qxZ3HvvvVmrRXskGSqbfBU97C2W/9fvwi5FRDqRqVOn8uijj5JMJqmrq+OFF15gypQpbNiwgYqKCj796U9z7bXXsmjRInbs2EEqleKjH/0o3/nOd1i0aFFWa9EeSYZOPuMDbJ/Tl8iyWXDxNWGXIyKdxIc//GHmzp3L+PHjMTN++MMfMnDgQGbOnMmPfvQj4vE43bt354EHHmDTpk1cc801pFIpAP793/89q7XYkXaPilV1dbVn+8VWL915HRO2/x5u2UBZl25ZXbeIdBwrV67k5JNPDruMnGutn2a20N2rW5tfh7ayoMvJF1BmTax++fmwSxERyTsFSRaMnDKNRo+yf8Wfwy5FRCTvFCRZ0LV7L1aXjqW8bm7YpYiI5J2CJEv2VJzK8MQ6DuyrD7sUEZG8UpBkSdcRpxE1Z/3Sf4RdiohIXilIsmTo2P8JwJ4aHd4Skc5FQZIlfSuGsMkGULL1lbBLERHJKwVJFm3tdjIDD6wKuwwRkbxSkGRRY79RDPZt7NvzZtiliEiRWr9+PaNGjeK6665j7NixfPKTn+T555/nrLPOYuTIkcyfP5/58+dz5plnMnHiRM4880xWrUr/BzeZTHLzzTczefJkTjnlFH71q19lpSY9IiWLyoaMgw2w6fVXOKn63LDLEZFcevoW2Lo0u+scOA4ueu+nidfU1PC73/2OGTNmMHnyZB566CFefPFFZs+ezfe+9z0eeOABXnjhBWKxGM8//zxf//rXefzxx7nnnnvo1asXL7/8Mg0NDZx11llccMEFVFVVZVS2giSLKk44Ff4B9RuWgIJERHKkqqqKcePGATBmzBjOO+88zIxx48axfv166uvrmT59OqtXr8bMaGpqAuDZZ5/l1Vdf5bHHHgOgvr6e1atXK0g6kkHDTuSAl5LatiLsUkQk19qw55ArpaWlh8Yjkcih75FIhEQiwTe/+U3OOeccnnzySdavX8/73vc+IP3o+Z///OdMmzYtq/XoHEkWRaJRauPD6F7/etiliEgnVl9fz5AhQwC4//77D7VPmzaNu++++9Aeyuuvv87+/fsz/j0FSZbVd6uivGFj2GWISCf21a9+lVtvvZWzzjqLZDJ5qP26665j9OjRTJo0ibFjx/KZz3yGRCKR8e/pMfJZNve+r3HGhl/y1s21dOnWI2e/IyL5p8fI6zHyeVFSMRKALet0nkREOoecBYmZ3Wtm281sWYu2H5nZa2b2qpk9aWa9W0y71cxqzGyVmU1r0X6qmS0Npt1hZha0l5rZo0H7PDMbnqu+HItelekU3127MuRKRETyI5d7JPcDFx7W9hww1t1PAV4HbgUws9HA5cCYYJm7zCwaLHM3cD0wMvg0r/Na4E13PwG4HfhBznpyDAZWjQagYZtOuIsUo2I/HdCe/uUsSNz9BWDXYW3PunvzmZ2XgMpg/BLgEXdvcPd1QA0wxcwGAT3dfa6ne/cAcGmLZWYG448B5zXvrYSpe88+7KA30TfXhV2KiGRZWVkZO3fuLNowcXd27txJWVnZMS0X5n0k/ww8GowPIR0szWqDtqZg/PD25mU2Arh7wszqgX7AjsN/yMyuJ71Xw3HHHZe9HhzB9nglPfZvyPnviEh+VVZWUltbS11dXdil5ExZWRmVlZXvPWMLoQSJmd0GJIAHm5tamc2P0n60Zd7d6D4DmAHpq7aOqdh22N91MEPrF+X6Z0Qkz+LxeMZ3gRejvF+1ZWbTgQ8Cn/S39w9rgaEtZqsENgftla20v2MZM4sBvTjsUFpYkj2GUu47aWpsCLsUEZGcy2uQmNmFwNeAD7n7gRaTZgOXB1diVZE+qT7f3bcAe83s9OD8x1XAUy2WmR6Mfwz4i3eQA5fRvsOImlO3SedJRKT45fLy34eBucBJZlZrZtcCvwB6AM+Z2WIz+yWAuy8HZgErgGeAG929+XbMG4DfkD4BvwZ4Omi/B+hnZjXAl4FbctWXY9WlfDgAuzavDrcQEZE8yNk5Ene/opXme44y/3eB77bSvgAY20r7QeCyTGrMlT5DTgDgwPb14RYiIpIHurM9B8qHHE/KjeQuXbklIsVPQZIDJaVl7LA+xPbWvvfMIiIFTkGSI7viA+l6YFPYZYiI5JyCJEf2dRlMn6atYZchIpJzCpIcaepRSXlqJ4mmxrBLERHJKQVJjkR6H0fckuzYohPuIlLcFCQ50rUi/RiFXZvXhFyJiEhuKUhypNegEQDs37Y25EpERHJLQZIjFZXpmxITupdERIqcgiRHyrp2T7+XZM/GsEsREckpBUkO7YwNoMuBze89o4hIAVOQ5NC+skH0btwWdhkiIjmlIMmhpu5DqEjVkUom33tmEZECpSDJIetzHKXWxK46PSpFRIqXgiSHSvsNA2BnbU3IlYiI5I6CJId6DkzfS7Jvu96UKCLFS0GSQ/2De0madupeEhEpXgqSHOrZux976IrV614SESleCpIc2xGpoHS/7iURkeKlIMmxPWWD6NWg95KISPFSkORYQ9fB9EttD7sMEZGcUZDkmPceSk8OsGf3zrBLERHJCQVJjsX7Dgdgh+4lEZEipSDJsR4D0y+42rNV7yURkeKkIMmxvoOPB6Bhx/pwCxERyREFSY71qxjCQY/ju3UviYgUJwVJjlkkQl2knJJ9tWGXIiKSEwqSPNhdMpDuB7eEXYaISE4oSPLgra6D6JvQvSQiUpwUJHmQ7DmU/uzm4Fv7wy5FRCTrFCR5EOtzHAB1updERIpQzoLEzO41s+1mtqxFW18ze87MVgfDPi2m3WpmNWa2ysymtWg/1cyWBtPuMDML2kvN7NGgfZ6ZDc9VXzLVtSJ9L8nuLevDLUREJAdyuUdyP3DhYW23AHPcfSQwJ/iOmY0GLgfGBMvcZWbRYJm7geuBkcGneZ3XAm+6+wnA7cAPctaTDPUJ7iV5q04vuBKR4pOzIHH3F4BdhzVfAswMxmcCl7Zof8TdG9x9HVADTDGzQUBPd5/r7g48cNgyzet6DDiveW+loykfPJykG6k33wi7FBGRrMv3OZIB7r4FIBhWBO1DgJZ37NUGbUOC8cPb37GMuyeAeqBfaz9qZteb2QIzW1BXV5elrrRdvKSUOutHdK/uJRGR4tNRTra3tifhR2k/2jLvbnSf4e7V7l5dXl7ezhIz82Z8AF3f0guuRKT45DtItgWHqwiGzTdX1AJDW8xXCWwO2itbaX/HMmYWA3rx7kNpHcb+LoPo07Qt7DJERLIu30EyG5gejE8HnmrRfnlwJVYV6ZPq84PDX3vN7PTg/MdVhy3TvK6PAX8JzqN0SE09KilP7SSZSIRdiohIVuXy8t+HgbnASWZWa2bXAt8H3m9mq4H3B99x9+XALGAF8Axwo7sng1XdAPyG9An4NcDTQfs9QD8zqwG+THAFWEcV6X0ccUtSp0uARaTIxHK1Yne/4giTzjvC/N8FvttK+wJgbCvtB4HLMqkxn7qUDwfgzc1rGDj0hHCLERHJoo5ysr3o9RqUvpdk/zbdSyIixUVBkicVlekgSezSvSQiUlwUJHnSpVsPdtGTyB4FiYgUFwVJHm2PDaHrfr0pUUSKi4Ikj/Z2G0r/hk1hlyEiklUKkjxK9BpOhe/Qe0lEpKgoSPIo3v94IuZs27Aq7FJERLJGQZJHPQafCMCbtQoSESkeCpI8GjB8NAAHt60OuRIRkexRkORRr74V7KEbtmtN2KWIiGSNgiSPLBJhc+w4uu9VkIhI8VCQ5Nme7lUMbNRNiSJSPBQkeZbqfxL9qGf3jq1hlyIikhUKkjzrMjh9wn3LmiUhVyIikh0KkjwrrzoFgL0bl4dciYhIdihI8mzgcSM54KWktq0IuxQRkaxQkORZJBrljZLj6bl7ZdiliIhkhYIkBPW9RjGssYZUMvneM4uIdHAKkhBEBk+gmx1k09plYZciIpKxNgWJmX3BzHpa2j1mtsjMLsh1ccWq7wmTAdj++sshVyIikrm27pH8s7vvAS4AyoFrgO/nrKoiN/SkSTR4nKY3FoRdiohIxtoaJBYMLwbuc/clLdrkGJWUlrG2ZCR9dr4SdikiIhlra5AsNLNnSQfJn82sB5DKXVnFb3f/SVQ1rdZLrkSk4LU1SK4FbgEmu/sBIE768Ja0U1nVGZRYknWvvhh2KSIiGWlrkJwBrHL33Wb2KeAbQH3uyip+wyacA0D9yv8OuRIRkcy0NUjuBg6Y2Xjgq8AG4IGcVdUJ9K0YwproCHpuUpCISGFra5Ak3N2BS4CfufvPgB65K6tz2D7wbE5sXEH9rrqwSxERabe2BsleM7sVuBL4o5lFSZ8nkQz0Gf8BYpZi9T+eDLsUEZF2a2uQfAJoIH0/yVZgCPCjnFXVSYycdA5b6U/p0ofDLkVEpN3aFCRBeDwI9DKzDwIH3V3nSDIUjcVYN+xjjGtYxMaapWGXIyLSLm19RMrHgfnAZcDHgXlm9rFcFtZZjJz2WRo9xuY//TDsUkRE2qWth7ZuI30PyXR3vwqYAnyzvT9qZl8ys+VmtszMHjazMjPra2bPmdnqYNinxfy3mlmNma0ys2kt2k81s6XBtDvMrODutu8/eBivlH+ISTv/yKa1etmViBSetgZJxN23t/i+8xiWfQczGwJ8Hqh297FAFLic9A2Pc9x9JDAn+I6ZjQ6mjwEuBO4KTvZD+rLk64GRwefC9tQUthEf+VcaiVP/yGdIJhJhlyMickzaGgbPmNmfzexqM7sa+CPwpwx+NwZ0MbMY0BXYTPrS4pnB9JnApcH4JcAj7t7g7uuAGmCKmQ0Cerr73ODS5AdaLFNQygcPZ8XEf2F041IW3H0tntLTZ0SkcLT1ZPvNwAzgFGA8MMPdv9aeH3T3TcCPgTeALUC9uz8LDHD3LcE8W4CKYJEhwMYWq6gN2oYE44e3v4uZXW9mC8xsQV1dx7xno/pDNzB30Kc4befvmTfjcwoTESkYbT485e6Pu/uX3f1L7t7uGx+Ccx+XAFXAYKBb8NiVIy7SWjlHaX93o/sMd6929+ry8vJjLTkvLBLh9E//nHn9P8LpWx9k/p3X0NTYEHZZIiLv6ahBYmZ7zWxPK5+9Zrannb95PrDO3evcvQl4AjgT2BYcriIYNp+TqQWGtli+kvShsNpg/PD2gmWRCJNv+M2hPZNVP7lAd72LSId31CBx9x7u3rOVTw9379nO33wDON3MugZXWZ0HrARmA9ODeaYDTwXjs4HLzazUzKpIn1SfHxz+2mtmpwfruarFMgUrEo1yxmfuZP74f+PEg0vZ8/OpbHhtUdhliYgcUd7f2e7u84DHgEXA0qCGGaTfuPh+M1sNvD/4jrsvB2YBK4BngBvdPRms7gbgN6RPwK8Bns5fT3Jryodvouaih+jq+yl/+EIW/umesEsSEWmVpS946jyqq6t9wYLCecXt9k3r2HXfFYxKrOSlio8z6dqfU1JaFnZZItLJmNlCd69ubVre90jk2FQMqWLEzf/FSxUf5/Tts1j743PYvmld2GWJiByiICkAJaVlnP7ZX7Nw8k84rnEN0V+fzbK//yHsskREAAVJQTn1A9dRd8Uz7Iv04ORnr2TuA9/U/SYiEjoFSYEZNmoS/b74Iot7nM0Za+9g4U8v4+Bb+8MuS0Q6MQVJAeresw+TvvwkLw2/keo9z7PhJ+ewY+sbYZclIp2UgqRAWSTC6Vd/j0Vn/IKhTetJ/PIc1rz6j7DLEpFOSEFS4CZNu5LNH3kSwxn0+KUsfaHg78kUkQKjICkCJ4w/i8j1f2FbdBAnzblGNy+KSF4pSIpE+eDh9L1pDmtKRjFx3leYN0tvXBSR/FCQFJFeffoz/It/5tWup3Haiu8y9752PelfROSYKEiKTJduPRjzpdm83OsCztjwS4WJiOScgqQIxUtKmXTTw2+Hyczbwi5JRIqYgqRIRWMxJt30MAt6ns8Z637BS7/917BLEpEipSApYtFYjAk3PczC7u/j9Jqf8tLD3wu7JBEpQgqSIheLl3DK52fxStezmPLaD1n09H1hlyQiRUZB0gnES0o5+XOzeL3kZMa8dDOvzX8u7JJEpIgoSDqJsq7dGXD9E2yPlDPwT1ezcfWSsEsSkSKhIOlE+pQPInLlY6SI4A9fwd76XWGXJCJFQEHSyQwZMYat02YwOLmFml99ilQyGXZJIlLgFCSd0OgzLmLBSV9h4oG/M/8/vhl2OSJS4BQkndRpl3+dBT3PZ8q6u1j630+EXY6IFDAFSSdlkQijr7+XDdHjGPTXL7FzW23YJYlIgVKQdGJdu/eCj91DD99P7f3X6P3vItIuCpJOrmr0ZF4Z9WXGvzWf+bN+EHY5IlKAFCTCaZ+4hSVdpjBh5U9Yv3JB2OWISIFRkAgWiVB59X0csC40PH6jLgkWkWOiIBEA+g2oZM2kr3NS4jVefuzHYZcjIgVEQSKHnPrBz7C0dBJjVtzO9k3rwi5HRAqEgkQOsUiEvp/4BTES1D50U9jliEiBUJDIOwwZMYZXRnyGSfv/xpK/PBJ2OSJSABQk8i7VV/wLG20wvV/8DommxrDLEZEOLpQgMbPeZvaYmb1mZivN7Awz62tmz5nZ6mDYp8X8t5pZjZmtMrNpLdpPNbOlwbQ7zMzC6E+xiZeUsuOM2xiWqmXhkz8NuxwR6eDC2iP5GfCMu48CxgMrgVuAOe4+EpgTfMfMRgOXA2OAC4G7zCwarOdu4HpgZPC5MJ+dKGYTzv9frCgZx8gVP9fj5kXkqPIeJGbWE5gK3APg7o3uvhu4BJgZzDYTuDQYvwR4xN0b3H0dUANMMbNBQE93n+vuDjzQYhnJkEUixC78Ln3Zw7JZ3w67HBHpwMLYIxkB1AH3mdkrZvYbM+sGDHD3LQDBsCKYfwiwscXytUHbkGD88PZ3MbPrzWyBmS2oq6vLbm+K2ImTzmZBz/OZWPsgWzfWhF2OiHRQYQRJDJgE3O3uE4H9BIexjqC18x5+lPZ3N7rPcPdqd68uLy8/1no7tcEf+R4RUmz4/XfCLkVEOqgwgqQWqHX3ecH3x0gHy7bgcBXBcHuL+Ye2WL4S2By0V7bSLlk0ePhJvNL/n5i44w9s2bAq7HJEpAPKe5C4+1Zgo5mdFDSdB6wAZgPTg7bpwFPB+GzgcjMrNbMq0ifV5weHv/aa2enB1VpXtVhGsmjYpd8EjI1Paa9ERN4tFtLv3gQ8aGYlwFrgGtKhNsvMrgXeAC4DcPflZjaLdNgkgBvdvfmpgjcA9wNdgKeDj2TZwKEnMK/8Q0yqe4rN615jcNWosEsSkQ7E0hc8dR7V1dW+YIEelX6sttWuofevT2NJ3wuY8oWHwi5HRPLMzBa6e3Vr03Rnu7TJgMrjWVxxCZN2Pc3mda+FXY6IdCAKEmmzqku/QQpj4x/1JkUReZuCRNqsYkgVi/tMY3zdH9i5rfa9FxCRTkFBIsdkwEVfo4QEr//hJ2GXIiIdhIJEjsmwkyawpNuZjK59lP17d4ddjoh0AAoSOWZdzv0KvdjP0tl3hF2KiHQAChI5ZqOqz2N5yTiqVt9PY8PBsMsRkZApSKRdEqd/jgHs5NXn/yPsUkQkZAoSaZdxZ19GrQ2i++J7wy5FREKmIJF2iUSj1I78JKOaVlCz5MWwyxGREClIpN1GX/xZDngpb/71F2GXIiIhUpBIu/Xs3Y+l/S/ilDefZ9f2TWGXIyIhUZBIRgae/3lKrYnX/3Rn2KWISEgUJJKRYSefyrLSCVStf4REU2PY5YhICBQkkrGmUz8dXAr8YNiliEgIFCSSsVPOvZzNVkHZK/eEXYqIhEBBIhmLxmK8MeIKRjcuZd3yeWGXIyJ5piCRrBh10Wc56HG2/0Un3UU6GwWJZEXv/gNZ2ud8xu14hj27d4ZdjojkkYJEsqb32Z+lqzWw4ulfhV2KiOSRgkSyZuTEqbweO5FBqx/EU6mwyxGRPFGQSFbVj72aYalalv/9D2GXIiJ5oiCRrBo37WrepCdNL80IuxQRyRMFiWRVWZduvDb4Uk7Z93dqa5aFXY6I5IGCRLJu5IduJkGMzX/6ftiliEgeKEgk6/oPPI7F/T/AhJ1PU7d5fdjliEiOKUgkJ4Z+8FYipFjzlPZKRIqdgkRyYnDVKBb3Oo/xWx9nx+YNYZcjIjmkIJGcGXTpd4iSZM1j3wi7FBHJIQWJ5MyQESezqOIjnLrzP9mwanHY5YhIjihIJKdOvOzbHKSUXbNvC7sUEcmR0ILEzKJm9oqZ/Wfwva+ZPWdmq4Nhnxbz3mpmNWa2ysymtWg/1cyWBtPuMDMLoy9yZH0rhrB0+HQm7n+R1+Y/F3Y5IpIDYe6RfAFY2eL7LcAcdx8JzAm+Y2ajgcuBMcCFwF1mFg2WuRu4HhgZfC7MT+lyLMZf9nV20JvIs1/X63hFilAoQWJmlcAHgN+0aL4EmBmMzwQubdH+iLs3uPs6oAaYYmaDgJ7uPtfdHXigxTLSgXTt3ov11bdxYuJ1Xn7oW2GXIyJZFtYeyU+BrwItHxE7wN23AATDiqB9CLCxxXy1QduQYPzw9ncxs+vNbIGZLairq8tKB+TYnHrxdSzqfjanrv0la5fpLYoixSTvQWJmHwS2u/vCti7SSpsfpf3dje4z3L3a3avLy8vb+LOSTRaJUDX9V+yxHsSeuIb6XQp0kWIRxh7JWcCHzGw98Ahwrpn9FtgWHK4iGG4P5q8FhrZYvhLYHLRXttIuHVSf8kFsn/ZLBia3svWuD/Jm3ZawSxKRLMh7kLj7re5e6e7DSZ9E/4u7fwqYDUwPZpsOPBWMzwYuN7NSM6sifVJ9fnD4a6+ZnR5crXVVi2Wkgxp9xkUsO/NnDG9aw767zmXT2uVhlyQiGepI95F8H3i/ma0G3h98x92XA7OAFcAzwI3ungyWuYH0CfsaYA3wdL6LlmM3adqVrL34QXp6Pb1nnsvcmbdRv3Nb2GWJSDtZ+oKnzqO6utoXLFgQdhkCbNmwiu2PfI7xb80n4RFeKzuFvf0nEqs4kV5DR9Oj3yC69epP9x69iUSj771CEckZM1vo7tWtTlOQSNjWvPoPts97lIFb/spxyTeI2jv/TKbcaCBOg5XQSAmNVkLCSmiKlJKwEhKRUpLRUlIWwy2KR2J4JP6OIc3DaBwiMYjEsGgconHsXZ8SIrE4kViMSLQEi8aIxNJt0VhJ8AnG43Fi8dL093gpsViMWLyEeLxU4SdF5WhBEst3MSKHO/6UMzn+lDMBaGw4SO26Fby58TWa9taRfGs3vFUPiYNY4i0s2UAk+ESTB4mlGilJHiCW2E3UE0Q9QYQkUU8SI0GUJDFPECNJjCRxSx69mCxKupEiguHstW68ZV1IEiNhcZIWI2kxUhYjGYmTshipYOiROKlDQRgDi4JFcItCJIaXdMe69MZipVishEg0jsXiRGKlh8IvEkuHWySenh4rCcIuVnpoPBYvJRaPEy8pIx4vwSId6Ui3FBIFiXQoJaVlDBs1iWGjJuVk/Z5KkUg0kWhqJJFoItnUSCLRSKKpkWRTE8lEA8mgPZVsItXUSDKZIJVoIpVsxINhKtmEJ5og2UQqmR56KgHJJkgm8FS6DU+BGZGGPUQb92KeIJJqwlIJIt5ENJUgmmqkxA8cCsKoJ4iSIObpIIyQIkqKiKeIkqSL5ebpACk3HEgSIUGMhMVoIkYy/es4RsqCaiyCEyFFhJRFcQwPprlF0tMtihPBrfnT/D09Dy3bm8MyEk0HJ/b2eMv2SPo7FoFIFGtuC6ZbJBIM0x9aDi0SjMeIRKJYNIJZDItEgvljWDSanhaJEonFicVLiJWUEY2l9zAtEiEaiUEkQjQaIxKJpPdYg+92qD2antZJwllBIp2KRSLES0qJl5SGXUq7NTU2sK9+F02NB0k0NhwKv0Rjw9vhl2gilWhIh14iQSrREIRgEHrJRrzFOMkENF/DkkpgySYs1QRB6OGOeTL4pDBPQjA0/B3tEU9hpIikGjF3IqSnRYIwtCAcm6dFmqcd/vEgQINPlNS7Dnt2dClP99Z55zAdyJG3AzoYOgakA90tkh4G0yIkKfFGDKeJOCmLEPXUoXmb12GHbqfzQ+PNN91tnvhlqj/0v7PeTwWJSIGJl5TSp3xQ2GWEJpVMkkwm0nuKyQTJZJJUMomn0u2eTJJMpaelkilSqQSeSuLJJKlUglQySSqVnj+VTEAqRSqVnubJFJ5K4J5KB2+igVRTOqDNU+n1eApS6SD1YIgnIZXCg4AllWrRnjwUxM1t5s3TUy3ag3/4PR0f5ima77E2T6XDItYlHSrJRswTuMWC6cE6mr3j+bXpcTejS5/c/LlRkIhIQYlEo0SiUeIU7l5lsekcB/BERCRnFCQiIpIRBYmIiGREQSIiIhlRkIiISEYUJCIikhEFiYiIZERBIiIiGel0T/81szpgQzsX7w/syGI5YVAfwlfo9UPh96HQ64f892GYu7f6rvJOFySZMLMFR3qMcqFQH8JX6PVD4feh0OuHjtUHHdoSEZGMKEhERCQjCpJjMyPsArJAfQhfodcPhd+HQq8fOlAfdI5EREQyoj0SERHJiIJEREQyoiBpIzO70MxWmVmNmd0Sdj1tYWbrzWypmS02swVBW18ze87MVgfDPmHX2ZKZ3Wtm281sWYu2I9ZsZrcG22SVmU0Lp+p3OkIfvmVmm4JtsdjMLm4xrUP1wcyGmtlfzWylmS03sy8E7QWzHY7Sh4LYDmZWZmbzzWxJUP+3g/aOuQ3cXZ/3+ABRYA0wAigBlgCjw66rDXWvB/of1vZD4JZg/BbgB2HXeVh9U4FJwLL3qhkYHWyLUqAq2EbRDtqHbwH/p5V5O1wfgEHApGC8B/B6UGfBbIej9KEgtgPp9+N2D8bjwDzg9I66DbRH0jZTgBp3X+vujcAjwCUh19RelwAzg/GZwKXhlfJu7v4CsOuw5iPVfAnwiLs3uPs6oIb0tgrVEfpwJB2uD+6+xd0XBeN7gZXAEApoOxylD0fSofrgafuCr/Hg43TQbaAgaZshwMYW32s5+h/KjsKBZ81soZldH7QNcPctkP7LBlSEVl3bHanmQtsunzOzV4NDX82HJDp0H8xsODCR9P+IC3I7HNYHKJDtYGZRM1sMbAeec/cOuw0UJG1jrbQVwnXTZ7n7JOAi4EYzmxp2QVlWSNvlbuB4YAKwBfhJ0N5h+2Bm3YHHgS+6+56jzdpKW0ftQ8FsB3dPuvsEoBKYYmZjjzJ7qPUrSNqmFhja4nslsDmkWtrM3TcHw+3Ak6R3dbeZ2SCAYLg9vArb7Eg1F8x2cfdtwT8MKeDXvH3YoUP2wczipP8BftDdnwiaC2o7tNaHQtsOAO6+G/gv4EI66DZQkLTNy8BIM6sysxLgcmB2yDUdlZl1M7MezePABcAy0nVPD2abDjwVToXH5Eg1zwYuN7NSM6sCRgLzQ6jvPTX/5Q98mPS2gA7YBzMz4B5gpbv/vxaTCmY7HKkPhbIdzKzczHoH412A84HX6KjbIKyrEgrtA1xM+sqPNcBtYdfThnpHkL6KYwmwvLlmoB8wB1gdDPuGXethdT9M+pBDE+n/ZV17tJqB24Jtsgq4KOz6j9KH/wCWAq+S/ks/qKP2AfgfpA+LvAosDj4XF9J2OEofCmI7AKcArwR1LgP+JWjvkNtAj0gREZGM6NCWiIhkREEiIiIZUZCIiEhGFCQiIpIRBYmIiGREQSKSJWaWbPFU2cWWxadEm9nwlk8TFulIYmEXIFJE3vL0Iy1EOhXtkYjkmKXfC/OD4P0S883shKB9mJnNCR4gOMfMjgvaB5jZk8G7KJaY2ZnBqqJm9uvg/RTPBnc8Y2afN7MVwXoeCamb0okpSESyp8thh7Y+0WLaHnefAvwC+GnQ9gvgAXc/BXgQuCNovwP4b3cfT/q9JsuD9pHAne4+BtgNfDRovwWYGKznf+emayJHpjvbRbLEzPa5e/dW2tcD57r72uBBglvdvZ+Z7SD9iI6moH2Lu/c3szqg0t0bWqxjOOlHiY8Mvn8NiLv7v5nZM8A+4PfA7/3t91iI5IX2SETyw48wfqR5WtPQYjzJ2+c4PwDcCZwKLDQznfuUvFKQiOTHJ1oM5wbj/yD9JGmATwIvBuNzgBvg0MuNeh5ppWYWAYa6+1+BrwK9gXftFYnkkv7nIpI9XYI32jV7xt2bLwEuNbN5pP/zdkXQ9nngXjO7GagDrgnavwDMMLNrSe953ED6acKtiQK/NbNepF9udLun318hkjc6RyKSY8E5kmp33xF2LSK5oENbIiKSEe2RiIhIRrRHIiIiGVGQiIhIRhQkIiKSEQWJiIhkREEiIiIZ+f/apQ8MudQRYAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history4.history).plot()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f31710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b7c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
